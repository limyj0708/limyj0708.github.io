[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2022-05-26__Jupyter Lab Server 세팅/index.html",
    "href": "posts/2022-05-26__Jupyter Lab Server 세팅/index.html",
    "title": "Jupyter Lab Server 세팅",
    "section": "",
    "text": "CentOS에 Jupyter Lab 설치가 완료되었다고 가정하자.\n\n구글에 Jupyter lab server라고 검색하면, 아래 페이지가 가장 먼저 뜨게 되는데, 이 페이지 말고\n\nhttps://jupyter-notebook.readthedocs.io/en/stable/public_server.html\n\n이 페이지를 확인하는 것이 좋다.\n\nhttps://jupyter-server.readthedocs.io/en/latest/operators/public-server.html\n\n\n\n\n0.1 1. Jupyter server configuration 파일 설정\n\njupyter server --generate-config를 하면, /home/“유저이름”/.jupyter/jupyter_server_config.py가 생성된다. 여기에서 세팅을 해야 한다.\n\nc.ServerApp.open_browser = False (브라우저 띄우지 않음)\nc.ServerApp.password = ‘argon2…’\n\nfrom jupyter_server.auth import passwd; passwd()를 실행하여 생성하는, 암호화된 비밀번호를 입력한다.\n\nc.ServerApp.port = 원하는 포트\nc.ServerApp.certfile = openssl로 만든 certfile 등록 (예: mycert.pem)\nc.ServerApp.keyfile = openssl로 만든 keyfile 등록 (예: mykey.key)\nc.ServerApp.ip = ’*’, 혹은 접근 가능하게 하고싶은 ip\nc.ServerApp.root_dir = 원하는 경로\n\nnotebook_dir is deprecated, use root_dir\n\nc.ServerApp.allow_origin = ’*’\n\nUse ’*’ to allow any origin to access your server.\n\n\n\n\n\n0.2 2. 문제점과 해결\n\nself-signed certificate 오류 메세지\n\nopenssl req -x509 -nodes -days 999 -newkey rsa:2048 -keyout mykey.key -out mycert.pem\n\n이런 식으로 만든 self-signed certificate를 쓰면 jupyter lab 실행 시, 뭘 하기만 하면 SSL Error를 띄운다.\n\n이런 식으로 : SSL Error on 13 (‘ip’, 13786): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:997)\nSafari에서는 안 뜨고, Edge에서는 뜨는 걸로 봐서 크로미움 기반 브라우저에서 접속하면 뜨는 것 같다.\n\n\nLet’s Encrypt 같은 서비스를 이용해서 인증서를 받아도 되는데, 도메인 네임도 없는, 혼자 쓰는 무료 클라우드 서버에서 그렇게까지 해야 하나 싶다.\ntmux에서 새 pane을 만들고, jupyter lab &gt; /dev/null 2&gt;&1 &으로 jupyter lab을 실행하여 콘솔 output을 없애고 백그라운드에서 jupyter lab을 실행하자."
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_05_데이터 구조 변경/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_05_데이터 구조 변경/index.html",
    "title": "Pandas_05_데이터 구조 변경",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display_html, display\n\n\ndef display_multiple_dfs(dfs:list, styles, margin=10):\n    display_target = ''\n    for each_df in dfs:\n        each_df_html = each_df[0].style.set_caption(f'&lt;b&gt;{each_df[1]}&lt;/b&gt;').set_table_styles(styles).set_table_attributes(f\"style='display:inline;margin:{margin}px'\")._repr_html_()\n        display_target += each_df_html\n    display_html(display_target, raw = True)\n\n\nstyles = [\n    {\"selector\" : \"caption\", \"props\" : \"text-align:center; font-size:16px\"}\n]\n\n\n1 Pivot : 엑셀에서 보던 그것\nDataFrame.pivot(index=None, columns=None, values=None)\n\nindex : str or object or a list of str, optional\n\n새로운 프레임의 index로 사용할 컬럼\n\ncolumns : str of object or a list of str\n\n새로운 프레임의 컬럼으로 사용할 컬럼\n\nvalues : str, object or a list of the previous, optional\n\n새로운 프레임의 값을 계산하기 위해 사용하는 컬럼\n지정하지 않으면, 남아있는 모든 컬럼을 사용한다.\n\n\n\ndf = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n                           'two'],\n                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n                   'baz': [1, 2, 3, 4, 5, 6],\n                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\ndf\n\n\n\n\n\n\n\n\nfoo\nbar\nbaz\nzoo\n\n\n\n\n0\none\nA\n1\nx\n\n\n1\none\nB\n2\ny\n\n\n2\none\nC\n3\nz\n\n\n3\ntwo\nA\n4\nq\n\n\n4\ntwo\nB\n5\nw\n\n\n5\ntwo\nC\n6\nt\n\n\n\n\n\n\n\n\ndf.pivot(index='foo', columns='bar', values='baz')\n\n\n\n\n\n\n\nbar\nA\nB\nC\n\n\nfoo\n\n\n\n\n\n\n\none\n1\n2\n3\n\n\ntwo\n4\n5\n6\n\n\n\n\n\n\n\n\ndf.pivot(index='foo', columns='bar')\n\n\n\n\n\n\n\n\nbaz\nzoo\n\n\nbar\nA\nB\nC\nA\nB\nC\n\n\nfoo\n\n\n\n\n\n\n\n\n\n\none\n1\n2\n3\nx\ny\nz\n\n\ntwo\n4\n5\n6\nq\nw\nt\n\n\n\n\n\n\n\n\ndf.pivot(index='foo', columns='bar')['baz']\n\n\n\n\n\n\n\nbar\nA\nB\nC\n\n\nfoo\n\n\n\n\n\n\n\none\n1\n2\n3\n\n\ntwo\n4\n5\n6\n\n\n\n\n\n\n\n\ndf = pd.DataFrame({\n       \"lev1\": [1, 1, 1, 2, 2, 2],\n       \"lev2\": [1, 1, 2, 1, 1, 2],\n       \"lev3\": [1, 2, 1, 2, 1, 2],\n       \"lev4\": [1, 2, 3, 4, 5, 6],\n       \"values\": [0, 1, 2, 3, 4, 5]})\ndf\n\n\n\n\n\n\n\n\nlev1\nlev2\nlev3\nlev4\nvalues\n\n\n\n\n0\n1\n1\n1\n1\n0\n\n\n1\n1\n1\n2\n2\n1\n\n\n2\n1\n2\n1\n3\n2\n\n\n3\n2\n1\n2\n4\n3\n\n\n4\n2\n1\n1\n5\n4\n\n\n5\n2\n2\n2\n6\n5\n\n\n\n\n\n\n\n\ndf.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"] ,values=\"values\")\n# Multilevel Column\n# 해당하는 조건에 맞는 값이 없으면 NaN이 들어가게 됨\n\n\n\n\n\n\n\nlev2\n1\n2\n\n\nlev3\n1\n2\n1\n2\n\n\nlev1\n\n\n\n\n\n\n\n\n1\n0.0\n1.0\n2.0\nNaN\n\n\n2\n4.0\n3.0\nNaN\n5.0\n\n\n\n\n\n\n\n\ndf.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"],values=\"values\")\n# Multiindex\n\n\n\n\n\n\n\n\nlev3\n1\n2\n\n\nlev1\nlev2\n\n\n\n\n\n\n1\n1\n0.0\n1.0\n\n\n2\n2.0\nNaN\n\n\n2\n1\n4.0\n3.0\n\n\n2\nNaN\n5.0\n\n\n\n\n\n\n\n\n#collapse-output\ndf.pivot(index=[\"lev1\"], columns=[\"lev2\"],values=\"values\")\n# 인덱스, 컬럼 쌍에 중복이 발생하면 에러가 출력됨\n# ValueError: Index contains duplicate entries, cannot reshape\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[11], line 2\n      1 #collapse-output\n----&gt; 2 df.pivot(index=[\"lev1\"], columns=[\"lev2\"],values=\"values\")\n      3 # 인덱스, 컬럼 쌍에 중복이 발생하면 에러가 출력됨\n      4 # ValueError: Index contains duplicate entries, cannot reshape\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    325 if len(args) &gt; num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--&gt; 331 return func(*args, **kwargs)\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/frame.py:8567, in DataFrame.pivot(self, index, columns, values)\n   8561 @Substitution(\"\")\n   8562 @Appender(_shared_docs[\"pivot\"])\n   8563 @deprecate_nonkeyword_arguments(version=None, allowed_args=[\"self\"])\n   8564 def pivot(self, index=None, columns=None, values=None) -&gt; DataFrame:\n   8565     from pandas.core.reshape.pivot import pivot\n-&gt; 8567     return pivot(self, index=index, columns=columns, values=values)\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    325 if len(args) &gt; num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--&gt; 331 return func(*args, **kwargs)\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/pivot.py:540, in pivot(data, index, columns, values)\n    536         indexed = data._constructor_sliced(data[values]._values, index=multiindex)\n    537 # error: Argument 1 to \"unstack\" of \"DataFrame\" has incompatible type \"Union\n    538 # [List[Any], ExtensionArray, ndarray[Any, Any], Index, Series]\"; expected\n    539 # \"Hashable\"\n--&gt; 540 return indexed.unstack(columns_listlike)\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/series.py:4455, in Series.unstack(self, level, fill_value)\n   4412 \"\"\"\n   4413 Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.\n   4414 \n   (...)\n   4451 b    2    4\n   4452 \"\"\"\n   4453 from pandas.core.reshape.reshape import unstack\n-&gt; 4455 return unstack(self, level, fill_value)\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:489, in unstack(obj, level, fill_value)\n    487 if is_1d_only_ea_dtype(obj.dtype):\n    488     return _unstack_extension_series(obj, level, fill_value)\n--&gt; 489 unstacker = _Unstacker(\n    490     obj.index, level=level, constructor=obj._constructor_expanddim\n    491 )\n    492 return unstacker.get_result(\n    493     obj._values, value_columns=None, fill_value=fill_value\n    494 )\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:137, in _Unstacker.__init__(self, index, level, constructor)\n    129 if num_cells &gt; np.iinfo(np.int32).max:\n    130     warnings.warn(\n    131         f\"The following operation may generate {num_cells} cells \"\n    132         f\"in the resulting pandas object.\",\n    133         PerformanceWarning,\n    134         stacklevel=find_stack_level(),\n    135     )\n--&gt; 137 self._make_selectors()\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/reshape.py:189, in _Unstacker._make_selectors(self)\n    186 mask.put(selector, True)\n    188 if mask.sum() &lt; len(self.index):\n--&gt; 189     raise ValueError(\"Index contains duplicate entries, cannot reshape\")\n    191 self.group_index = comp_index\n    192 self.mask = mask\n\nValueError: Index contains duplicate entries, cannot reshape\n\n\n\n\n\n2 Pivot_table : Pivot의 확장 버전\npandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True)\n\n#hide_input\ndf = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n                         \"bar\", \"bar\", \"bar\", \"bar\"],\n                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n                         \"one\", \"one\", \"two\", \"two\"],\n                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n                         \"small\", \"large\", \"small\", \"small\",\n                         \"large\"],\n                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n0\nfoo\none\nsmall\n1\n2\n\n\n1\nfoo\none\nlarge\n2\n4\n\n\n2\nfoo\none\nlarge\n2\n5\n\n\n3\nfoo\ntwo\nsmall\n3\n5\n\n\n4\nfoo\ntwo\nsmall\n3\n6\n\n\n5\nbar\none\nlarge\n4\n6\n\n\n6\nbar\none\nsmall\n5\n8\n\n\n7\nbar\ntwo\nsmall\n6\n9\n\n\n8\nbar\ntwo\nlarge\n7\n9\n\n\n\n\n\n\n\n\ntable = pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'], aggfunc=np.sum)\ntable # aggfunc에 집계함수를 넣게 된다. 여기서는 총합\n\n\n\n\n\n\n\n\nC\nlarge\nsmall\n\n\nA\nB\n\n\n\n\n\n\nbar\none\n4.0\n5.0\n\n\ntwo\n7.0\n6.0\n\n\nfoo\none\n4.0\n1.0\n\n\ntwo\nNaN\n6.0\n\n\n\n\n\n\n\n\ntable = pd.pivot_table(df, values='D', index=['A', 'B'],\n                    columns=['C'], aggfunc=np.sum, fill_value=0)\ntable # fill_value에 할당된 값으로 NaN을 대체하게 됨\n\n\n\n\n\n\n\n\nC\nlarge\nsmall\n\n\nA\nB\n\n\n\n\n\n\nbar\none\n4\n5\n\n\ntwo\n7\n6\n\n\nfoo\none\n4\n1\n\n\ntwo\n0\n6\n\n\n\n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': np.sum})\ntable # aggfunc에 Dictionary를 할당하여 값마다 집계함수를 각각 다르게 설정할 수 있다.\n\n\n\n\n\n\n\n\n\nD\nE\n\n\nA\nC\n\n\n\n\n\n\nbar\nlarge\n5.500000\n15\n\n\nsmall\n5.500000\n17\n\n\nfoo\nlarge\n2.000000\n9\n\n\nsmall\n2.333333\n13\n\n\n\n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': [min, max, np.mean]})\ntable # 한 값에 여러 개의 집계함수 할당도 가능하다.\n\n\n\n\n\n\n\n\n\nD\nE\n\n\n\n\nmean\nmax\nmean\nmin\n\n\nA\nC\n\n\n\n\n\n\n\n\nbar\nlarge\n5.500000\n9\n7.500000\n6\n\n\nsmall\n5.500000\n9\n8.500000\n8\n\n\nfoo\nlarge\n2.000000\n5\n4.500000\n4\n\n\nsmall\n2.333333\n6\n4.333333\n2\n\n\n\n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': np.mean},\n                    margins=True, margins_name=\"mean\")\ntable # Values에 적용된 집계함수를 컬럼 전체에 적용한 행을 추가한다.\n# 한 Value에 집계함수를 하나만 사용했을 때 적용 가능.\n# margins_name을 지정하지 않으면 기본적으로 행 Index 이름은 All이 된다.\n\n\n\n\n\n\n\n\n\nD\nE\n\n\nA\nC\n\n\n\n\n\n\nbar\nlarge\n5.500000\n7.500000\n\n\nsmall\n5.500000\n8.500000\n\n\nfoo\nlarge\n2.000000\n4.500000\n\n\nsmall\n2.333333\n4.333333\n\n\nmean\n\n3.666667\n6.000000\n\n\n\n\n\n\n\n\n\n3 melt : Unpivot 하기\npandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\n\nid_vars : tuple, list, or ndarray, optional\n\n식별자로 사용할 컬럼\n\nvalue_vars : tuple, list, or ndarray, optional\n\nUnpivot 할 컬럼. 지정하지 않으면, id_vars에 할당되지 않은 모든 컬럼을 사용\n\n\n\ndf = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n                   'B': {0: 1, 1: 3, 2: 5},\n                   'C': {0: 2, 1: 4, 2: 6}})\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\na\n1\n2\n\n\n1\nb\n3\n4\n\n\n2\nc\n5\n6\n\n\n\n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B'])\n\n\n\n\n\n\n\n\nA\nvariable\nvalue\n\n\n\n\n0\na\nB\n1\n\n\n1\nb\nB\n3\n\n\n2\nc\nB\n5\n\n\n\n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'])\n\n\n\n\n\n\n\n\nA\nvariable\nvalue\n\n\n\n\n0\na\nB\n1\n\n\n1\nb\nB\n3\n\n\n2\nc\nB\n5\n\n\n3\na\nC\n2\n\n\n4\nb\nC\n4\n\n\n5\nc\nC\n6\n\n\n\n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B'],\n        var_name='myVarname', value_name='myValname')\n# 이름은 커스터마이징 가능\n\n\n\n\n\n\n\n\nA\nmyVarname\nmyValname\n\n\n\n\n0\na\nB\n1\n\n\n1\nb\nB\n3\n\n\n2\nc\nB\n5\n\n\n\n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n# 원본 index 유지\n\n\n\n\n\n\n\n\nA\nvariable\nvalue\n\n\n\n\n0\na\nB\n1\n\n\n1\nb\nB\n3\n\n\n2\nc\nB\n5\n\n\n0\na\nC\n2\n\n\n1\nb\nC\n4\n\n\n2\nc\nC\n6\n\n\n\n\n\n\n\n\n\n4 sort_values : 정렬\nDataFrame.sort_values(by, *, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)\n\nby : str, 혹은 str의 리스트\naxis : {0 or ‘index’, 1 or ‘columns’}, default 0\nascending : bool, default True, True일 경우 오름차순\ninplace : bool, default False, 원본을 변경하는지\nkind : {‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}, default ‘quicksort’\n\n정렬 알고리즘 종류. 자세한 사항은 numpy.sort 참고\n\nna_position : {‘first’, ‘last’}, default ‘last’, NaN의 위치는 어디에 둘 지 선택\nignore_index : bool, default False, If True, the resulting axis will be labeled 0, 1, …, n - 1.\nkey : callable, optional\n\n정렬하기 전에 key에 할당된 함수를 값에 적용한다.\nby에 할당된 컬럼들에 각각 적용된다.\ninput과 output의 크기가 같을 것이 요구된다. (정렬을 해야 하니, 당연한 이야기지만)\n\nIt should expect a Series and return a Series with the same shape as the input.\n\n\n\n\ndf_sample = pd.DataFrame({\n    'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n    'col2': [2, 1, 9, 8, 7, 4],\n    'col3': [0, 1, 9, 4, 2, 3],\n    'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n})\ndf_sample\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\n0\nA\n2\n0\na\n\n\n1\nA\n1\n1\nB\n\n\n2\nB\n9\n9\nc\n\n\n3\nNaN\n8\n4\nD\n\n\n4\nD\n7\n2\ne\n\n\n5\nC\n4\n3\nF\n\n\n\n\n\n\n\n\ndf_sample.sort_values(by=['col1'])\n# col1 기준 정렬\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\n0\nA\n2\n0\na\n\n\n1\nA\n1\n1\nB\n\n\n2\nB\n9\n9\nc\n\n\n5\nC\n4\n3\nF\n\n\n4\nD\n7\n2\ne\n\n\n3\nNaN\n8\n4\nD\n\n\n\n\n\n\n\n\ndf_sample.sort_values(by=['col1', 'col2'])\n# col1, col2 기준 정렬\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\n1\nA\n1\n1\nB\n\n\n0\nA\n2\n0\na\n\n\n2\nB\n9\n9\nc\n\n\n5\nC\n4\n3\nF\n\n\n4\nD\n7\n2\ne\n\n\n3\nNaN\n8\n4\nD\n\n\n\n\n\n\n\n\ndf_sample.sort_values(by='col1', ascending=False, na_position='first')\n# col1 기준, 내림차순, NaN을 상단에 두고 정렬\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\n3\nNaN\n8\n4\nD\n\n\n4\nD\n7\n2\ne\n\n\n5\nC\n4\n3\nF\n\n\n2\nB\n9\n9\nc\n\n\n0\nA\n2\n0\na\n\n\n1\nA\n1\n1\nB\n\n\n\n\n\n\n\n\ncol4 = df_sample.sort_values(by='col4')\n#col4를 그냥 정렬하면, 대문자에서 소문자 순서로 정렬된다.\ncol4\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\n1\nA\n1\n1\nB\n\n\n3\nNaN\n8\n4\nD\n\n\n5\nC\n4\n3\nF\n\n\n0\nA\n2\n0\na\n\n\n2\nB\n9\n9\nc\n\n\n4\nD\n7\n2\ne\n\n\n\n\n\n\n\n\ncol4_key_lowercase = df_sample.sort_values(by='col4', key = lambda col: col.str.lower())\n# col4의 각 알파벳들을 다 소문자로 치환 후 정렬하였다.\ncol4_key_lowercase\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\n0\nA\n2\n0\na\n\n\n1\nA\n1\n1\nB\n\n\n2\nB\n9\n9\nc\n\n\n3\nNaN\n8\n4\nD\n\n\n4\nD\n7\n2\ne\n\n\n5\nC\n4\n3\nF\n\n\n\n\n\n\n\n\n\n5 shift : Bigquery의 lead, lag에 대응되는 함수\n\ndf_sample = pd.DataFrame({\n    'base_date': [  np.datetime64('2023-01-12')\n                      , np.datetime64('2023-01-12')\n                      , np.datetime64('2023-01-12')\n                      , np.datetime64('2023-01-12')\n                      , np.datetime64('2023-01-13')\n                      , np.datetime64('2023-01-13')\n                      \n    ],\n    'col2': [2, 1, 9, 8, 7, 4],\n    'col3': [0, 1, 9, 4, 2, 3],\n    'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n})\ndf_sample\n\n\n\n\n\n\n\n\nbase_date\ncol2\ncol3\ncol4\n\n\n\n\n0\n2023-01-12\n2\n0\na\n\n\n1\n2023-01-12\n1\n1\nB\n\n\n2\n2023-01-12\n9\n9\nc\n\n\n3\n2023-01-12\n8\n4\nD\n\n\n4\n2023-01-13\n7\n2\ne\n\n\n5\n2023-01-13\n4\n3\nF\n\n\n\n\n\n\n\n\ndf_sample['col2_shift_lag1'] = df_sample.groupby(['base_date'])['col2'].shift(1)\n# base_date를 기준으로, col2에 대하여 shift 1 적용\n# 즉, 이전 행의 col2 값을 출력\n\ndf_sample['col2_shift_lead1'] = df_sample.groupby(['base_date'])['col2'].shift(-1)\n# base_date를 기준으로, col2에 대하여 shift -1 적용\n# 즉, 다음 행의 col2 값을 출력\n\n\ndf_sample\n\n\n\n\n\n\n\n\nbase_date\ncol2\ncol3\ncol4\ncol2_shift_lag1\ncol2_shift_lead1\n\n\n\n\n0\n2023-01-12\n2\n0\na\nNaN\n1.0\n\n\n1\n2023-01-12\n1\n1\nB\n2.0\n9.0\n\n\n2\n2023-01-12\n9\n9\nc\n1.0\n8.0\n\n\n3\n2023-01-12\n8\n4\nD\n9.0\nNaN\n\n\n4\n2023-01-13\n7\n2\ne\nNaN\n4.0\n\n\n5\n2023-01-13\n4\n3\nF\n7.0\nNaN"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html",
    "title": "Pandas_08_파일 입출력",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display_html, display\ndef display_multiple_dfs(dfs:list, styles, margin=10):\n    display_target = ''\n    for each_df in dfs:\n        each_df_html = each_df[0].style.set_caption(f'&lt;b&gt;{each_df[1]}&lt;/b&gt;').set_table_styles(styles).set_table_attributes(f\"style='display:inline;margin:{margin}px'\")._repr_html_()\n        display_target += each_df_html\n    display_html(display_target, raw = True)\nstyles = [\n    {\"selector\" : \"caption\", \"props\" : \"text-align:center; font-size:16px\"}\n]"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html#쓰기",
    "href": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html#쓰기",
    "title": "Pandas_08_파일 입출력",
    "section": "5.1 쓰기",
    "text": "5.1 쓰기\n\ndf.to_parquet('df.parquet', engine='pyarrow', index=None)\n# index : 데이터프레임의 index 저장 유무. False, True, None을 할당할 수 있다.\n## index=False: If you set index=False, the dataframe’s index will not be written to the file.\n## index=None: If you set index=None, the dataframe’s index will be saved.\n### However, instead of being saved as values, the RangeIndex will be stored as a range in the metadata so it doesn’t require much space and is faster.\n### Other indexes will be included as columns in the file output."
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html#읽기",
    "href": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html#읽기",
    "title": "Pandas_08_파일 입출력",
    "section": "5.2 읽기",
    "text": "5.2 읽기\n\ndf = pd.read_parquet('df.parquet', engine='pyarrow')"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html#matplotlib를-이용",
    "href": "posts/2021-11-05__pandas_cheatsheet_08_파일 입출력/index.html#matplotlib를-이용",
    "title": "Pandas_08_파일 입출력",
    "section": "6.1 matplotlib를 이용",
    "text": "6.1 matplotlib를 이용\n\ndataframe-image 패키지를 이용 시, linux에서 crontab으로 실행할 경우 복잡한 권한 문제에 직면하게 됨\ndataframe-image 패키지도 matplotlib 기반이므로, 그냥 matplotlib를 사용\n\n\nimport six\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n\n# matplotlib에서 한글이 안 나오는 문제 해결\nNANUM = fm.FontProperties(fname=r'/Users/limyj0708/Library/Fonts/NanumGothic.ttf')\nNANUM_bold = fm.FontProperties(fname=r'/Users/limyj0708/Library/Fonts/NanumGothicBold.ttf')\n\n# centos라면 폰트 경로는 아래와 같음\n # /usr/share/fonts/NanumFont/NanumBarunGothic.ttf\n # /usr/share/fonts/NanumFont/NanumGothicBold.ttf\n\ndef render_mpl_table(data, col_width=3.0, row_height=0.625, font_size_header=16, font_size=14,\n                     header_color='#C2DED1', row_colors=['#f1f1f2', 'w'], edge_color='black',\n                     bbox=[0, 0, 1, 1], header_columns=0,\n                     ax=None, align_head='center', align_cell='center', **kwargs):\n    \"\"\"\n    align_head, align_cell : [ 'center' | 'right' | 'left' ] \n    \"\"\"\n    \n    if ax is None:\n        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n        fig, ax = plt.subplots(figsize=size)\n        ax.axis('off')\n\n    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n    mpl_table.auto_set_font_size(False)\n\n    for k, cell in  six.iteritems(mpl_table._cells):\n        cell.set_edgecolor(edge_color)\n        if k[0] == 0 or k[1] &lt; header_columns:\n            cell.set_facecolor(header_color)\n            cell.set_text_props(color='black', fontproperties = NANUM_bold, fontsize=font_size_header, ha=align_head)\n        else:\n            cell.set_facecolor(row_colors[k[0]%len(row_colors)])\n            cell.set_text_props(fontproperties = NANUM, fontsize=font_size, ha=align_cell)\n    return ax\n\nimage = render_mpl_table(caller, col_width=2.0, align_head='center')\nimage\nimage.figure.savefig(\"caller.png\") # 이미지 저장\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n/Users/limyj0708/Documents/personal/blog/blog/posts/2021-11-05_pandas_cheatsheet_08_파일 입출력.ipynb Cell 31 line 3\n     &lt;a href='vscode-notebook-cell:/Users/limyj0708/Documents/personal/blog/blog/posts/2021-11-05_pandas_cheatsheet_08_%ED%8C%8C%EC%9D%BC%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#X35sZmlsZQ%3D%3D?line=35'&gt;36&lt;/a&gt;             cell.set_text_props(fontproperties = NANUM, fontsize=font_size, ha=align_cell)\n     &lt;a href='vscode-notebook-cell:/Users/limyj0708/Documents/personal/blog/blog/posts/2021-11-05_pandas_cheatsheet_08_%ED%8C%8C%EC%9D%BC%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#X35sZmlsZQ%3D%3D?line=36'&gt;37&lt;/a&gt;     return ax\n---&gt; &lt;a href='vscode-notebook-cell:/Users/limyj0708/Documents/personal/blog/blog/posts/2021-11-05_pandas_cheatsheet_08_%ED%8C%8C%EC%9D%BC%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#X35sZmlsZQ%3D%3D?line=38'&gt;39&lt;/a&gt; image = render_mpl_table(caller, col_width=2.0, align_head='center')\n     &lt;a href='vscode-notebook-cell:/Users/limyj0708/Documents/personal/blog/blog/posts/2021-11-05_pandas_cheatsheet_08_%ED%8C%8C%EC%9D%BC%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#X35sZmlsZQ%3D%3D?line=39'&gt;40&lt;/a&gt; image\n     &lt;a href='vscode-notebook-cell:/Users/limyj0708/Documents/personal/blog/blog/posts/2021-11-05_pandas_cheatsheet_08_%ED%8C%8C%EC%9D%BC%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#X35sZmlsZQ%3D%3D?line=40'&gt;41&lt;/a&gt; image.figure.savefig(\"caller.png\") # 이미지 저장\n\nNameError: name 'caller' is not defined"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html",
    "href": "posts/2022-06-13__git_cheatsheet/index.html",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "",
    "text": "안 쓰면 잊어버리는, git 주요 조작법들을 정리\n교과서 : https://git-scm.com/book/ko/v2"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#상태-확인",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#상태-확인",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "2.1 상태 확인",
    "text": "2.1 상태 확인\n\ngit status\n\n  PS C:\\Users\\limyj0708\\fastpages&gt; git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        _notebooks/2022-06-13-git_cheatsheet.ipynb\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n\n2022-06-13-git_cheatsheet.ipynb 파일이 untracked 상태\nGit은 Untracked 파일을 아직 스냅샷(커밋)에 넣어지지 않은 파일이라고 본다. 파일이 Tracked 상태가 되기 전까지는 Git은 절대 그 파일을 커밋하지 않는다. 그래서 일하면서 생성하는 바이너리 파일 같은 것을 커밋하는 실수는 하지 않게 된다."
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#파일을-새로-추적하기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#파일을-새로-추적하기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "2.2 파일을 새로 추적하기",
    "text": "2.2 파일을 새로 추적하기\n\ngit add _notebooks/2022-06-13-git_cheatsheet.ipynb\n이후 다시 status를 보면\n\nPS C:\\Users\\limyj0708\\fastpages&gt; git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        new file:   _notebooks/2022-06-13-git_cheatsheet.ipynb\n\n“Changes to be committed” 에 들어 있는 파일은 Staged 상태라는 것을 의미한다. 커밋하면 git add 를 실행한 시점의 파일이 커밋되어 저장소 히스토리에 남는다.\ngit add 명령은 파일 또는 디렉토리의 경로를 argument로 받는다. 디렉토리면 아래에 있는 모든 파일들까지 재귀적으로 추가한다.\ngit add . 의 경우, .은 현재 디렉토리를 나타내므로, 현재 디렉토리와 하위 디렉토리의 모든 파일들을 Staged 상태로 만든다."
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#modified-상태의-파일을-staging-하기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#modified-상태의-파일을-staging-하기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "2.3 Modified 상태의 파일을 Staging 하기",
    "text": "2.3 Modified 상태의 파일을 Staging 하기\n\n2022-06-13-git_cheatsheet.ipynb를 수정한 후에 git status를 해 보면?\n\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        new file:   _notebooks/2022-06-13-git_cheatsheet.ipynb\n\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   _notebooks/2022-06-13-git_cheatsheet.ipynb\n\n“Changes not staged for commit” 에 있다. 이것은 수정한 파일이 Tracked 상태이지만 아직 Staged 상태는 아니라는 것이다. Staged 상태로 만들려면 git add 명령을 실행해야 한다. git add 명령은 파일을 새로 추적할 때도 사용하고 수정한 파일을 Staged 상태로 만들 때도 사용한다. Merge 할 때 충돌난 상태의 파일을 Resolve 상태로 만들때도 사용한다. add의 의미는 프로젝트에 파일을 추가한다기 보다는 다음 커밋에 추가한다고 받아들이는게 좋다.\ngit add _notebooks/2022-06-13-git_cheatsheet.ipynb후 다시 git status를 해 보자.\n\nPS C:\\Users\\limyj0708\\fastpages&gt; git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        new file:   _notebooks/2022-06-13-git_cheatsheet.ipynb\n\n“Changes to be committed”에 잘 들어갔는데, 여기서 또 수정을 하고 git status를 하면?\n\nPS C:\\Users\\limyj0708\\fastpages&gt; git status\nOn branch master\nYour branch is up to date with 'origin/master'.\n\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        new file:   _notebooks/2022-06-13-git_cheatsheet.ipynb\n\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   _notebooks/2022-06-13-git_cheatsheet.ipynb\n\nChanges to be committed / Changes not staged for commit에 둘 다 2022-06-13-git_cheatsheet.ipynb이 들어있는 이유\n\n지금 이 시점에서 커밋을 하면 git commit 명령을 실행하는 시점의 버전이 커밋되는 것이 아니라 마지막으로 git add 명령을 실행했을 때의 버전이 커밋된다. 그러니까 git add 명령을 실행한 후에 또 파일을 수정하면 git add 명령을 다시 실행해서 최신 버전을 Staged 상태로 만들어야 한다."
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#commit",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#commit",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "2.4 commit",
    "text": "2.4 commit\n\nStaged 상태가 된 파일을 저장소에 기록\n커밋 메세지를 첨부하려면 -m을 붙이고 메시지를 기재\n\ngit commit -m \"modify readme\"\n[main c524828] modify readme\n 1 file changed, 23 insertions(+), 24 deletions(-)\n\nmain branch에 기록되었으며, 체크섬은 c524828\n-a 옵션을 붙이면, add를 해서 staging area에 변경된 파일을 추가하는 작업을 자동으로 처리해 줌\n\ngit commit -a -m \"modify readme\""
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#파일-삭제",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#파일-삭제",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "2.5 파일 삭제",
    "text": "2.5 파일 삭제\n\ngit rm [파일명 or 디렉토리명]\n\n파일이 실제로 삭제된다.\n\n파일을 그냥 삭제하면, 파일이 unstaged 상태에 있다고 표시된다.\n\n파일을 그냥 삭제하였다면, git rm을 적용해 주어야 staged 상태가 된다.\n그리고 commit을 하면, 더 이상 파일을 추적하지 않는다.\n\n파일을 수정했는데 지우고 싶거나, staging area에 추가했다면, -f 옵션을 주어서 강제로 삭제해야 한다.\nStaging Area에서만 제거하고 디렉토리에 있는 파일은 지우지 않고 남겨두기\n\n–cached 옵션 사용\ngit rm --cached README\n\n한 번에 여러 파일 삭제하기\n\ngit rm log/\\*.log\n\nlog 폴더 내의, .log 확장자인 파일을 모두 삭제함\n\ngit rm \\*~\n\n이름이 ~로 끝나는 파일을 모두 삭제함"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#파일-이동-이름-바꾸기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#파일-이동-이름-바꾸기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "2.6 파일 이동, 이름 바꾸기",
    "text": "2.6 파일 이동, 이름 바꾸기\n\ngit mv README.md README\n\nREADME.md를 README로 이름 변경"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-확인하기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-확인하기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "3.1 원격 저장소 확인하기",
    "text": "3.1 원격 저장소 확인하기\n$ git remote -v\norigin  https://github.com/limyj0708/bigquery_module.git (fetch)\norigin  https://github.com/limyj0708/bigquery_module.git (push)"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-추가하기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-추가하기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "3.2 원격 저장소 추가하기",
    "text": "3.2 원격 저장소 추가하기\n\ngit remote add &lt;원격 저장소 이름&gt; &lt;url&gt;\n\nclone 시에는, 단축이름이 자동으로 origin이 된다.\ngit clone https://github.com/limyj0708/fastpages.git : 이런 식으로 할 경우\n\n현재 디렉토리에 추가된 원격 저장소가 있는데, 다른 원격 저장소로 바꾸고 싶을 경우\n\nhttps://shanepark.tistory.com/284 참조"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소에서-pull-fetch",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소에서-pull-fetch",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "3.3 원격 저장소에서 Pull, Fetch",
    "text": "3.3 원격 저장소에서 Pull, Fetch\n\ngit fetch &lt;원격 저장소 이름&gt;\n\n로컬에는 없는데, 원격 저장소에 있는 내용을 모두 가져온다.\n가져오긴 하지만 branch를 merge 하지는 않으므로, 수동으로 merge 해야 한다.\n\ngit pull &lt;원격 저장소 이름&gt;\n\n원격 저장소에 있는 내용을 모두 가져온 후, branch merge까지 알아서 진행한다.\n최초에 내용을 git clone으로 가져왔을 경우, 자동으로 로컬의 master branch가 리모트 저장소의 master branch를 추적하도록 한다(물론 리모트 저장소에 master 브랜치가 있다는 가정에서)."
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소에-push-하기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소에-push-하기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "3.4 원격 저장소에 Push 하기",
    "text": "3.4 원격 저장소에 Push 하기\n\ngit push &lt;원격 저장소 이름&gt; &lt;브랜치 이름&gt;\n\n최초에 git clone으로 가져왔을 경우, 단축이름은 origin이고 branch 이름은 master이므로 아래와 같이 된다.\ngit push origin master\n\n이 명령은 Clone 한 리모트 저장소에 쓰기 권한이 있고, Clone 하고 난 이후 아무도 Upstream 저장소에 Push 하지 않았을 때만 사용할 수 있다. 다시 말해서 Clone 한 사람이 여러 명 있을 때, 다른 사람이 Push 한 후에 Push 하려고 하면 Push 할 수 없다. 먼저 다른 사람이 작업한 것을 가져와서 Merge 한 후에 Push 할 수 있다."
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-정보-보기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-정보-보기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "3.5 원격 저장소 정보 보기",
    "text": "3.5 원격 저장소 정보 보기\n\ngit remote show &lt;원격 저장소 이름&gt;\n\n$ git remote show origin\n* remote origin\n  Fetch URL: https://github.com/schacon/ticgit\n  Push  URL: https://github.com/schacon/ticgit\n  HEAD branch: master\n  Remote branches:\n    master                               tracked\n    dev-branch                           tracked\n  Local branch configured for 'git pull':\n    master merges with remote master\n  Local ref configured for 'git push':\n    master pushes to master (up to date)\n\n원격 저장소의 URL과 추적하는 branch를 출력한다. 이 명령은 git pull 명령을 실행할 때 master branch와 Merge할 branch가 무엇인지 보여준다. git pull 명령은 원격 저장소 branch의 데이터를 모두 가져오고 나서 자동으로 Merge할 것이다."
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-이름-바꾸기-삭제하기",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#원격-저장소-이름-바꾸기-삭제하기",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "3.6 원격 저장소 이름 바꾸기, 삭제하기",
    "text": "3.6 원격 저장소 이름 바꾸기, 삭제하기\n\ngit remote rename &lt;기존 원격 저장소 이름&gt; &lt;바꿀 원격 저장소 이름&gt;\ngit remote remove &lt;원격 저장소 이름&gt;"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#config-분리",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#config-분리",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "4.1 config 분리",
    "text": "4.1 config 분리\n\n한 PC에서 업무용 repository 접근계정, 개인용 repository 접근계정을 분리해서 사용하고 싶을 때\n윈도우의 경우, C:{계정명} 에 .gitconfig가 존재한다.\n.gitconfig에 아래 항목 추가\n\n[includeIf \"gitdir/i:C:/Code/limyj0708_code_archive/\"]\n    path = .gitconfig_personal.config\n\nC:/Code/limyj0708_code_archive/ 아래에 있는 repository에 접근 시에는, .gitconfig_personal.config의 정보를 사용하겠다는 의미이다.\nC:{계정명} 에 .gitconfig_personal.config를 만들고, users 항목을 입력한다.\n\n[user]\n    email = limyj0708@gmail.com\n    name = limyj0708\n\n확인해보면, 원하는 대로 잘 된다.\n\n$ git config --show-origin user.email\nfile:C:/Users/limyj0708/.gitconfig_personal.config      limyj0708@gmail.com"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#ssh_key-등록",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#ssh_key-등록",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "4.2 ssh_key 등록",
    "text": "4.2 ssh_key 등록\n\nssh_key를 각각 분리해서 등록해주면, 원격 저장소에 push할 때 귀찮은 일이 없어진다.\n\n&gt; ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (C:\\Users\\limyj0708/.ssh/id_rsa):\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in C:\\Users\\limyj0708/.ssh/id_rsa.\nYour public key has been saved in C:\\Users\\limyj0708/.ssh/id_rsa.pub.\nThe key fingerprint is:\n\npassphrase는 설정을 권장하고 있으므로 설정해준다.\nC:\\Users\\limyj0708\\.ssh에 가서, 공개키(pub)를 열고 내용을 복사하자.\ngithub 계정 &gt; Settings &gt; SSH and GPG keys 메뉴로 이동\n\nSSH keys &gt; New SSH key\n공개키 내용을 붙여넣고, 적절히 이름을 붙여서 등록\n\nC:\\Users\\limyj0708\\.ssh\\config에 내용을 추가하자.\n\nHost github_personal\n  IdentityFile C:\\Users\\limyj0708\\.ssh\\{비밀키 파일명}\n  User git\n  HostName github.com\n\n이후, 로컬 저장소에서 원격 저장소를 어떻게 등록해주면 되냐면…\n\ngit remote add origin git@github_personal:limyj0708/blog.git\n\ngit@github.com:limyj0708/blog.git에서, github.com 부분을 github_personal으로 바꿔 준 것이다.\n\n이미 연결되어있던 원격 저장소가 있어서, 바꿔줘야 되는 상황이라면 미리 git remote remove {저장소명}을 해 주자.\n\n이제 원격 저장소로 push 할 때, passphrase만 잘 입력해 주면 추가 조치 없이 잘 진행된다.\n회사 계정은 github_work 등으로 추가할 수 있다."
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#branch-목록-확인",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#branch-목록-확인",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "5.1 Branch 목록 확인",
    "text": "5.1 Branch 목록 확인\n\ngit branch\n\n로컬 브랜치 목록을 보여준다\n현재 작업 중인 브랜치 앞에 * 표시가 붙는다\n\n\n$ git branch\n* master\n  develop\n  feature-1\n\ngit branch -v\n\n각 브랜치의 마지막 커밋 메시지도 함께 보여준다\n\n\n$ git branch -v\n* master    c524828 modify readme\n  develop   a3f2b1c add new feature\n  feature-1 d8e9f0a fix bug\n\ngit branch -a\n\n로컬 브랜치와 원격 브랜치를 모두 보여준다\n\ngit branch -r\n\n원격 브랜치만 보여준다"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#branch-생성",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#branch-생성",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "5.2 Branch 생성",
    "text": "5.2 Branch 생성\n\ngit branch &lt;브랜치명&gt;\n\n새로운 브랜치를 생성한다\n생성만 할 뿐 해당 브랜치로 전환하지는 않는다\n\n\n$ git branch develop\n$ git branch\n  develop\n* master\n\ngit checkout -b &lt;브랜치명&gt;\n\n새로운 브랜치를 생성하고 바로 전환한다\ngit branch &lt;브랜치명&gt; + git checkout &lt;브랜치명&gt;을 한 번에 실행\n\n\n$ git checkout -b feature-2\nSwitched to a new branch 'feature-2'\n\ngit switch -c &lt;브랜치명&gt;\n\nGit 2.23 버전 이후 추가된 명령어\ngit checkout -b와 동일한 기능 (브랜치 생성 + 전환)\n\n\n$ git switch -c feature-3\nSwitched to a new branch 'feature-3'"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#branch-전환",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#branch-전환",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "5.3 Branch 전환",
    "text": "5.3 Branch 전환\n\ngit checkout &lt;브랜치명&gt;\n\n지정한 브랜치로 전환한다\n워킹 디렉토리의 파일들이 해당 브랜치의 상태로 변경된다\n\n\n$ git checkout develop\nSwitched to branch 'develop'\n\ngit switch &lt;브랜치명&gt;\n\nGit 2.23 버전 이후 추가된 명령어\ngit checkout보다 명확하게 브랜치 전환 용도로 사용\n\n\n$ git switch master\nSwitched to branch 'master'\n\n주의사항\n\n브랜치를 전환하기 전에 현재 작업 중인 내용을 커밋하거나 stash 해야 한다\n그렇지 않으면 변경사항이 사라지거나 충돌이 발생할 수 있다"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#branch-삭제",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#branch-삭제",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "5.4 Branch 삭제",
    "text": "5.4 Branch 삭제\n\ngit branch -d &lt;브랜치명&gt;\n\n로컬 브랜치를 삭제한다\n병합되지 않은 브랜치는 삭제되지 않는다 (안전장치)\n\n\n$ git branch -d feature-1\nDeleted branch feature-1 (was d8e9f0a).\n\ngit branch -D &lt;브랜치명&gt;\n\n강제로 브랜치를 삭제한다\n병합되지 않은 브랜치도 삭제된다\n\n\n$ git branch -D feature-2\nDeleted branch feature-2 (was a1b2c3d).\n\n원격 브랜치 삭제\n\ngit push &lt;원격 저장소&gt; --delete &lt;브랜치명&gt;\n또는 git push &lt;원격 저장소&gt; :&lt;브랜치명&gt;\n\n\n$ git push origin --delete feature-1\nTo https://github.com/user/repo.git\n - [deleted]         feature-1"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#branch-병합-merge",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#branch-병합-merge",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "5.5 Branch 병합 (Merge)",
    "text": "5.5 Branch 병합 (Merge)\n\ngit merge &lt;브랜치명&gt;\n\n현재 브랜치에 지정한 브랜치의 내용을 병합한다\n예: develop 브랜치의 내용을 master에 병합하고 싶다면\n\n\n$ git checkout master\n$ git merge develop\nUpdating c524828..a3f2b1c\nFast-forward\n README.md | 10 ++++++++++\n 1 file changed, 10 insertions(+)\n\nFast-forward 병합\n\n현재 브랜치가 병합할 브랜치의 직접적인 조상인 경우\nGit은 단순히 포인터를 앞으로 이동시킨다\n\n3-way Merge\n\n현재 브랜치와 병합할 브랜치가 갈라진 경우\nGit은 공통 조상, 현재 브랜치, 병합할 브랜치를 비교하여 새로운 커밋을 생성\n시나리오 1 (성공):\n\nMine은 file1.txt를 수정.\nTheirs는 file2.txt를 수정.\n결과: 겹치는 부분이 없으므로, 두 변경 사항을 모두 적용한 새 커밋을 만든다.\n\n시나리오 2 (성공):\n\nMine은 file1.txt의 10번째 줄을 수정.\nTheirs는 file1.txt의 50번째 줄을 수정.\n결과: 같은 파일이지만 수정한 위치가 다르므로, 두 변경 사항을 모두 적용.\n\n시나리오 3 (실패: 병합 충돌)\n\nMine은 file1.txt의 10번째 줄을 A라고 수정.\nTheirs도 file1.txt의 10번째 줄을 B라고 수정.\n\n결과: Git은 원본(Base)과 비교해 보니 둘 다 같은 곳을 다르게 수정했음을 확인.\n\nGit은 “둘 중 뭘 선택해야 할지 모르겠어!”라며 병합 충돌(Merge Conflict)을 일으키고 사용자에게 해결을 요청함\n\n충돌이 없거나, 충돌을 모두 해결하고 나면 Git은 이 모든 변경 사항을 합친 새로운 커밋 M을 생성\n\n   A---B---C  (feature)  &lt;- 병합할 브랜치 (Theirs)\n  /\n---O---D---E       (main)     &lt;- 현재 브랜치 (Mine)\n\n    A---B---C\n   /         \\\n---O---D---E---M   (main)\n병합 충돌 해결\n\n같은 파일의 같은 부분을 수정한 경우 충돌이 발생한다\n충돌이 발생하면 Git은 해당 파일에 충돌 마커를 추가한다\n\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n현재 브랜치의 내용\n=======\n병합하려는 브랜치의 내용\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; develop\n\n수동으로 충돌을 해결한 후 git add로 해결 표시\ngit commit으로 병합 완료"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#branch-이름-변경",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#branch-이름-변경",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "5.6 Branch 이름 변경",
    "text": "5.6 Branch 이름 변경\n\ngit branch -m &lt;기존 브랜치명&gt; &lt;새 브랜치명&gt;\n\n브랜치 이름을 변경한다\n\n\n$ git branch -m old-name new-name\n\n현재 브랜치의 이름을 변경하려면\n\n$ git branch -m new-name"
  },
  {
    "objectID": "posts/2022-06-13__git_cheatsheet/index.html#commit-메시지-변경",
    "href": "posts/2022-06-13__git_cheatsheet/index.html#commit-메시지-변경",
    "title": "Git CheatSheet (지속적으로 업데이트함)",
    "section": "6.1 Commit 메시지 변경",
    "text": "6.1 Commit 메시지 변경\n\n조직의 commit 메시지 규격에 맞지 않게 commit 메시지를 입력했다가, Push가 안 되는 경우가 종종 발생한다.\n\n\n6.1.1 가장 최근의 commit 수정 (Push 하기 전)\ngit commit --amend\n\n에디터 창이 열리고, commit 메시지 수정 후 esc -&gt; :wq (저장 후 닫기) 수행하면 완료"
  },
  {
    "objectID": "posts/2025-11-03__CIDR (Classless Inter-Domain Routing)/index.html",
    "href": "posts/2025-11-03__CIDR (Classless Inter-Domain Routing)/index.html",
    "title": "CIDR (Classless Inter-Domain Routing) 이란?",
    "section": "",
    "text": "1. CIDR?\n\nCIDR (Classless Inter-Domain Routing)는 IP 주소 범위를 나타내는 표기\n표기 방식: [IP 주소]/[프리픽스 길이]\n\nIP 주소: 시작하는 IP 주소\n프리픽스 길이 (숫자): IP 주소의 32비트(IPv4 기준) 중에서 네트워크 부분을 나타내는 비트 수를 의미. 이 숫자가 작을수록 더 넓은 범위의 IP를 포함함\n\n예시:\n\n192.168.1.0/24: 앞의 24비트(192.168.1)는 고정이고, 나머지 8비트(0~255)는 변할 수 있다는 뜻\n\n즉, 192.168.1.0부터 192.168.1.255까지의 256개 IP를 의미함\n\n10.0.0.0/8: 앞의 8비트(10)만 고정이고 나머지 24비트가 변할 수 있다는 뜻\n\n훨씬 더 큰 범위(약 1,600만 개)의 IP를 포함\n\n192.0.2.1/32: 32비트 전체가 고정이라는 뜻으로, 192.0.2.1이라는 단 하나의 IP 주소를 의미\n\n\n\n\n2. 그럼 0.0.0.0/0은 무엇인지?\n\n0.0.0.0: IP 주소의 시작점.\n/0: 고정되는 비트가 0개라는 뜻. 즉, 32비트 전체가 변할 수 있음을 의미함.\n결과적으로 0.0.0.0/0은 0.0.0.0부터 255.255.255.255까지, 모든 IPv4 주소 범위 전체를 나타내는 표기법\n예를 들어, Oracle Compute Instance의 Ingress Rule의 Source CIDR (소스 CIDR)에 0.0.0.0/0을 설정하면, 인터넷상의 모든 IP 주소로부터의 접속(TCP 프로토콜)을 허용하겠다는 의미임"
  },
  {
    "objectID": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html",
    "href": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html",
    "title": "맥 OS pyenv 세팅 101",
    "section": "",
    "text": "https://brew.sh 확인하여 설치\n설치 후 ~/.zprofile에 eval \"$(/opt/homebrew/bin/brew shellenv)\" 추가\n\n다 설치하면 맨 마지막에 안내문으로 추가하라고 나오니 따라하기만 하자."
  },
  {
    "objectID": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#brew-설치",
    "href": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#brew-설치",
    "title": "맥 OS pyenv 세팅 101",
    "section": "",
    "text": "https://brew.sh 확인하여 설치\n설치 후 ~/.zprofile에 eval \"$(/opt/homebrew/bin/brew shellenv)\" 추가\n\n다 설치하면 맨 마지막에 안내문으로 추가하라고 나오니 따라하기만 하자."
  },
  {
    "objectID": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv-설치",
    "href": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv-설치",
    "title": "맥 OS pyenv 세팅 101",
    "section": "2 2. pyenv 설치",
    "text": "2 2. pyenv 설치\n\nbrew install pyenv : 설치가 끝났다면…\n\n.zshrc에 eval \"$(pyenv init -)\" 추가\n.zprofile에 eval \"$(pyenv init --path)\" 추가"
  },
  {
    "objectID": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv로-원하는-파이썬-버전-설치",
    "href": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv로-원하는-파이썬-버전-설치",
    "title": "맥 OS pyenv 세팅 101",
    "section": "3 3. pyenv로 원하는 파이썬 버전 설치",
    "text": "3 3. pyenv로 원하는 파이썬 버전 설치\n\npyenv install -list : 설치가능한 파이썬 버전 목록 확인\npyenv install 3.10.3 : 예) 3.10.3 버전 설치"
  },
  {
    "objectID": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv-virtualenv-설치",
    "href": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv-virtualenv-설치",
    "title": "맥 OS pyenv 세팅 101",
    "section": "4 4. pyenv-virtualenv 설치",
    "text": "4 4. pyenv-virtualenv 설치\n\nbrew install pyenv-virtualenv\n\n.zshrc에 eval \"$(pyenv virtualenv-init -)\" 추가"
  },
  {
    "objectID": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv로-가상환경-생성",
    "href": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#pyenv로-가상환경-생성",
    "title": "맥 OS pyenv 세팅 101",
    "section": "5 5. pyenv로 가상환경 생성",
    "text": "5 5. pyenv로 가상환경 생성\n\npyenv virtualenv [파이썬 버전] [가상환경 이름]\n\n예) pyenv virtualenv 3.10.3 requests-3.10.3\n\npyenv versions : 생성한 가상환경이 추가되었음을 알 수 있음"
  },
  {
    "objectID": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#가상환경-onoff",
    "href": "posts/2022-03-19__맥 OS pyenv 세팅 101/index.html#가상환경-onoff",
    "title": "맥 OS pyenv 세팅 101",
    "section": "6 6. 가상환경 on/off",
    "text": "6 6. 가상환경 on/off\n\n직접 on/off\n\npyenv activate requests-3.10.3\n\n실행하면 아래와 같은 메세지가 출력된다.\npyenv-virtualenv: prompt changing will be removed from future release. configure “export PYENV_VIRTUALENV_DISABLE_PROMPT=1” to simulate the behavior\n곧 이 기능은 사라질 모양이다.\n\npyenv deactivate\n\nshell의 세션이 유지되는 동안 가상환경 유지\n\npyenv shell requests-3.10.3\n\n원하는 폴더에 가서 실행하면, 이후 shell에서 해당 폴더로 가면 자동으로 원하는 가상환경이 켜지게 됨 (.python-version 파일이 해당 폴더에 생성)\n\npyenv local requests-3.10.3\npyenv local system : 다시 기본 시스템 버전으로 돌리고 싶을 때\n해당 폴더에서 나가면 자동으로 기본 환경으로 돌아가게 된다. 편리하네!\n\n전체 적용\n\npyenv global requests-3.10.3\npyenv global system : 다시 기본 시스템 버전으로 돌리고 싶을 때\n\nshell의 세션이 유지되는 동안 가상환경 유지\n\npyenv shell requests-3.10.3"
  },
  {
    "objectID": "posts/2022-11-08__Python 스크립트 Console 유저 입력 받기/index.html",
    "href": "posts/2022-11-08__Python 스크립트 Console 유저 입력 받기/index.html",
    "title": "Python 스크립트 Console 유저 입력 받기",
    "section": "",
    "text": "Python 스크립트를 실행 시, Console 창에서 유저의 입력을 받으려면?\n\n\ntext = input(\"아무거나 입력하세요 : \")\nprint(f\"메아리 : {text}\")\n\n아무거나 입력하세요 :  맛있는 거 먹고 싶다\n메아리 : 맛있는 거 먹고 싶다\n\n\n\n입력되는 값은 기본적으로 string이다.\n\n\ntext1 = input(\"아무거나 입력하세요1 : \")\ntext2 = input(\"아무거나 입력하세요2 : \")\nprint(f\"메아리 : {text1 + text2}\")\nprint(type(text1))\n\n아무거나 입력하세요1 :  1\n아무거나 입력하세요2 :  2\n메아리 : 12\n&lt;class 'str'&gt;\n\n\n\n다른 자료형으로 쓰려면 형변환을 해야 함\n\n\nint1 = int(input(\"아무거나 입력하세요1 : \"))\nint2 = int(input(\"아무거나 입력하세요2 : \"))\nprint(f\"메아리 : {int1 + int2}\")\n\n아무거나 입력하세요1 :  1\n아무거나 입력하세요2 :  2\n메아리 : 3\n\n\n\n유저가 잘못된 값을 입력할 때를 대비한 예외처리\n\n\ntry:\n    num = int(input('숫자를 입력하세요: '))\n    print('입력하신 숫자는 : ', num)\n\nexcept ValueError:\n    print('숫자를 넣으라니까?')\n\n숫자를 입력하세요:  커피\n숫자를 넣으라니까?\n\n\n\n올바른 값을 입력할 때까지 작동하는 예외처리 루프\n\n\nwhile True:\n    try:\n        num = int(input('숫자를 입력하세요: '))\n        print('입력하신 숫자는 : ', num)\n        break\n\n    except ValueError:\n        print('숫자를 넣으라니까?')\n\n숫자를 입력하세요:  커피\n숫자를 넣으라니까?\n숫자를 입력하세요:  라떼\n숫자를 넣으라니까?\n숫자를 입력하세요:  오미자\n숫자를 넣으라니까?\n숫자를 입력하세요:  11\n입력하신 숫자는 :  11\n\n\n\n한 줄에 여러 값 입력받기\n\n\nname, age, position = input(\"이름, 나이, 직급을 입력하세요.\").split() \n    # 입력값을 쪼갬, 입력값은 스페이스로 구분되어야 함\nprint(\"이름 :\", name)\nprint(\"나이 :\", age)\nprint(\"직급 :\", position)\n\n이름, 나이, 직급을 입력하세요. 홍길돌 35 과장\n이름 : 홍길돌\n나이 : 35\n직급 : 과장\n\n\n\n리스트를 입력받는다면\n\n\nentered_list = input(\"직원들의 나이를 입력하세요 : \").split()\nprint('직원들이 나이 리스트_문자열 : ',entered_list)\n\nnum_list = list(map(int,entered_list))\n    # map 함수로 리스트의 모든 원소에 대해 int 형변환 시행\nprint('직원들의 나이 리스트_숫자변환: ',num_list)\nprint('평균 나이:', sum(num_list)/len(num_list))\n\n직원들의 나이를 입력하세요 :  24 45 34 37 33 29\n직원들이 나이 리스트_문자열 :  ['24', '45', '34', '37', '33', '29']\n직원들의 나이 리스트_숫자변환:  [24, 45, 34, 37, 33, 29]\n평균 나이: 33.666666666666664\n\n\n\n여러 줄로 입력받기\n\n\ntotal_input = []\nprint(\"직원들의 이름을 쓰세요 : \")\n\nwhile True:\n    name = input()\n    if name:\n        total_input.append(name)\n    else:\n        break\n        # 아무것도 입력하지 않고 엔터를 누르면 if문에서 false로 처리되어\n        # break를 만나게 됨\n\nprint('입력된 직원들의 이름 목록 :')\nprint(total_input)\n\n직원들의 이름을 쓰세요 : \n 홍길동\n 둘리\n 마이콜\n \n입력된 직원들의 이름 목록 :\n['홍길동', '둘리', '마이콜']"
  },
  {
    "objectID": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html",
    "href": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html",
    "title": "리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab",
    "section": "",
    "text": "회사에 업무를 위한 소형 개인 서버로 쓰는 NUC가 있다.\n\nssh로 연결하여 사용\n\n사내 와이파이에 연결되어 있는데, 아주 가끔씩 할당된 IP가 바뀐다.\n이럴 때마다 모니터를 연결해서 ifconfig로 ip 주소를 확인할 수는 없는 노릇이다.\n일주일에 한 번씩, 서버가 나에게 현재 자신의 ip가 뭔지 보내줬으면 좋겠다."
  },
  {
    "objectID": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html#배경",
    "href": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html#배경",
    "title": "리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab",
    "section": "",
    "text": "회사에 업무를 위한 소형 개인 서버로 쓰는 NUC가 있다.\n\nssh로 연결하여 사용\n\n사내 와이파이에 연결되어 있는데, 아주 가끔씩 할당된 IP가 바뀐다.\n이럴 때마다 모니터를 연결해서 ifconfig로 ip 주소를 확인할 수는 없는 노릇이다.\n일주일에 한 번씩, 서버가 나에게 현재 자신의 ip가 뭔지 보내줬으면 좋겠다."
  },
  {
    "objectID": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html#실행",
    "href": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html#실행",
    "title": "리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab",
    "section": "2 2. 실행",
    "text": "2 2. 실행\n\n2.1 1. Shell 명령어\nifconfig [원하는 네트워크 인터페이스명] | grep -Eo '([0-9]{1,3}[\\.]){3}[0-9]{1,3}'\n\ngrep\n\n-E : 표현을 확장 정규 표현식으로 해석\n-o : 매칭되는 문자열만 표시\n\n\n\n\n2.2 2. Python 스크립트에서\nimport subprocess\nimport requests\n\nregex_ipv4 = '([0-9]{1,3}[\\.]){3}[0-9]{1,3}' #ipv4를 추출하는 정규식\nps = subprocess.Popen((\"ifconfig\", \"원하는 네트워크 인터페이스명\"), stdout=subprocess.PIPE)\noutput = subprocess.check_output((\"grep\", \"-Eo\", regex_ipv4), stdin=ps.stdout)\nps.wait()\nipv4_internal = str(output).split('\\\\n')[0][2:]\n# 사내에서 접근 가능한 IP주소만 추출함\n\nTARGET_URL = 'https://notify-api.line.me/api/notify'\nTOKEN = '라인 Notify에서 발급받은 토큰 입력'\n# 요청합니다.\nresponse = requests.post(\n    TARGET_URL,\n    headers={\n    'Authorization': 'Bearer ' + TOKEN\n    },\n    data={\n    'message': f'NUC IP : {ipv4_internal}'\n    }\n)\n\nShell에서처럼 Pipe(|)를 쓸 수 없다.\n\nPopen에 shell=True를 넘겨주면 되긴 하는데, 일반적으로 shell에서 명령을 내리는 것 처럼 별도의 유효성 검사 없이 실행이 되기 때문에 shell injection에 취약하게 된다.\n\n그래서 쪼개서 실행시켜야 한다. Popen으로 ifconfig를 실행시키고, 그 출력값을 check_output에 연결하여 최종 출력값을 만든다.\n추출한 IP를 Line Notify를 통해 라인으로 받는다.\n\n\n\n2.3 3. Crontab에서\n PATH=/usr/bin:/usr/sbin:/sbin:/usr/local/bin\n # ifconfig, grep을 잘 실행시키기 위한 환경 지정\n \n # ssh 접속용 사내 Wifi ipv4 전송용\n # 매주 월요일 오전 10시에 전송 \n00 10 * * 1 /usr/bin/python3.9 /home/limyj0708/Code/ipv4_internal_alarm/ipv4_internal_alarm.py &gt;&gt; /home/limyj0708/Code/ipv4_internal_alarm/cron_log.log 2&gt;&1\n\n\n2.4 4. 결과\n\n지정한 Line Notify 봇을 통해 IP가 잘 날아온다."
  },
  {
    "objectID": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html#reference",
    "href": "posts/2022-11-17__리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab/index.html#reference",
    "title": "리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab",
    "section": "3 Reference",
    "text": "3 Reference\n\nShell=True는 Shell Injection에 취약\nPopen 클래스 개괄\nSubprocess 모듈 사용법"
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_Array, Struct 실전사용/index.html",
    "href": "posts/2022-10-29__Bigquery_Array, Struct 실전사용/index.html",
    "title": "Bigquery_Array, Struct 조합 사용과 Cartesian Product",
    "section": "",
    "text": "이런 일을 한 이유\n\n지역 던전 별, 이탈 유무 별, 누적과금대 별 지역 던전 클리어 유저 수를 구해야 함\n던전 로그에서 지역 던전 도달 유저 수를 그냥 구하면 도달하지 못한 지역 던전은 아예 출력이 되질 않음. 도달 로그 자체가 없을 것이므로.\n\n해당 유저 세그먼트에서 아무도 도달하지 못한 지역 던전이 있으면, 테이블이 쥐가 파먹은 것 처럼 중간이 비게 된다.\n아무도 도달하지 못한 지역 던전은 값이 0으로 뜨게 하고 싶다.\n\n그래서 생각한 것이, 미리 모든 카테고리를 곱집합(cartesian product)한 결과물을 기반 테이블로 만들어 두고, 지역 던전 도달 유저 수를 LEFT JOIN으로 기반 테이블에 붙이는 방법임.\n\n\nDECLARE leaving_check ARRAY&lt;INT64&gt;;\nDECLARE acc_sales ARRAY&lt;STRING&gt;;\nDECLARE region_quest ARRAY&lt;STRUCT&lt;map_key INT64, map_name STRING, quest_act INT64, quest_chapter INT64, quest_id INT64, quest_name STRING&gt;&gt;;\n-- STRUCT 정의 할 때 Alias를 붙여주지 않으면 supertype 에러가 발생함\n\nSET leaving_check = [0,1];\nSET acc_sales = [\n  '1. 무과금 (0원)'\n  ,'2. 베이직 (1200원)'\n  ,'3. 소과금' \n  ,'4. 중과금'\n  ,'5. 중고과금'\n  ,'6. 고과금'\n  ,'7. VIP'\n  ,'8. VVIP'\n  ,'9. 고래유저'\n];\nSET region_quest = [ -- SET에서는 alias를 붙여주지 않아도 되지만, 붙여주면 쿼리 속도가 훨씬 빨라졌음.\n    STRUCT(dummy_key_1111 AS map_key, \"dummy_name_1111\" AS map_name, 1 AS quest_act, 13 AS quest_chapter, dummy_id_1111 AS quest_id, \"dummy_q_name_1111\" AS quest_name)\n    ,STRUCT(dummy_key_1112 AS map_key, \"dummy_name_1112\" AS map_name, 1 AS quest_act, 24 AS quest_chapter, dummy_id_1112 AS quest_id, \"dummy_q_name_1112\" AS quest_name)\n    ,STRUCT(dummy_key_1113 AS map_key, \"dummy_name_1113\" AS map_name, 1 AS quest_act, 29 AS quest_chapter, dummy_id_1113 AS quest_id, \"dummy_q_name_1113\" AS quest_name)\n    ,STRUCT(dummy_key_1114 AS map_key, \"dummy_name_1114\" AS map_name, 1 AS quest_act, 37 AS quest_chapter, dummy_id_1114 AS quest_id, \"dummy_q_name_1114\" AS quest_name)\n    ,STRUCT(dummy_key_1115 AS map_key, \"dummy_name_1115\" AS map_name, 1 AS quest_act, 33 AS quest_chapter, dummy_id_1115 AS quest_id, \"dummy_q_name_1115\" AS quest_name)\n    ,STRUCT(dummy_key_1116 AS map_key, \"dummy_name_1116\" AS map_name, 2 AS quest_act, 5 AS quest_chapter, dummy_id_1116 AS quest_id, \"dummy_q_name_1116\" AS quest_name)\n    ,STRUCT(dummy_key_1117 AS map_key, \"dummy_name_1117\" AS map_name, 2 AS quest_act, 11 AS quest_chapter, dummy_id_1117 AS quest_id, \"dummy_q_name_1117\" AS quest_name)\n    ,STRUCT(dummy_key_1118 AS map_key, \"dummy_name_1118\" AS map_name, 2 AS quest_act, 16 AS quest_chapter, dummy_id_1118 AS quest_id, \"dummy_q_name_1118\" AS quest_name)\n    ,STRUCT(dummy_key_1119 AS map_key, \"dummy_name_1119\" AS map_name, 2 AS quest_act, 20 AS quest_chapter, dummy_id_1119 AS quest_id, \"dummy_q_name_1119\" AS quest_name)\n    ,STRUCT(dummy_key_1120 AS map_key, \"dummy_name_1120\" AS map_name, 2 AS quest_act, 23 AS quest_chapter, dummy_id_1120 AS quest_id, \"dummy_q_name_1120\" AS quest_name)\n    ,STRUCT(dummy_key_1121 AS map_key, \"dummy_name_1121\" AS map_name, 3 AS quest_act, 20 AS quest_chapter, dummy_id_1121 AS quest_id, \"dummy_q_name_1121\" AS quest_name)\n    ,STRUCT(dummy_key_1122 AS map_key, \"dummy_name_1122\" AS map_name, 3 AS quest_act, 25 AS quest_chapter, dummy_id_1122 AS quest_id, \"dummy_q_name_1122\" AS quest_name)\n    ,STRUCT(dummy_key_1123 AS map_key, \"dummy_name_1123\" AS map_name, 3 AS quest_act, 5 AS quest_chapter, dummy_id_1123 AS quest_id, \"dummy_q_name_1123\" AS quest_name)\n    ,STRUCT(dummy_key_1124 AS map_key, \"dummy_name_1124\" AS map_name, 3 AS quest_act, 10 AS quest_chapter, dummy_id_1124 AS quest_id, \"dummy_q_name_1124\" AS quest_name)\n    ,STRUCT(dummy_key_1125 AS map_key, \"dummy_name_1125\" AS map_name, 3 AS quest_act, 29 AS quest_chapter, dummy_id_1125 AS quest_id, \"dummy_q_name_1125\" AS quest_name)\n    ,STRUCT(dummy_key_1126 AS map_key, \"dummy_name_1126\" AS map_name, 3 AS quest_act, 32 AS quest_chapter, dummy_id_1126 AS quest_id, \"dummy_q_name_1126\" AS quest_name)\n    ,STRUCT(dummy_key_1127 AS map_key, \"dummy_name_1127\" AS map_name, 3 AS quest_act, 35 AS quest_chapter, dummy_id_1127 AS quest_id, \"dummy_q_name_1127\" AS quest_name)\n    ,STRUCT(dummy_key_1128 AS map_key, \"dummy_name_1128\" AS map_name, 4 AS quest_act, 6 AS quest_chapter, dummy_id_1128 AS quest_id, \"dummy_q_name_1128\" AS quest_name)\n    ,STRUCT(dummy_key_1129 AS map_key, \"dummy_name_1129\" AS map_name, 4 AS quest_act, 12 AS quest_chapter, dummy_id_1129 AS quest_id, \"dummy_q_name_1129\" AS quest_name)\n    ,STRUCT(dummy_key_1130 AS map_key, \"dummy_name_1130\" AS map_name, 4 AS quest_act, 19 AS quest_chapter, dummy_id_1130 AS quest_id, \"dummy_q_name_1130\" AS quest_name)\n    ,STRUCT(dummy_key_1131 AS map_key, \"dummy_name_1131\" AS map_name, 4 AS quest_act, 24 AS quest_chapter, dummy_id_1131 AS quest_id, \"dummy_q_name_1131\" AS quest_name)\n    ,STRUCT(dummy_key_1132 AS map_key, \"dummy_name_1132\" AS map_name, 4 AS quest_act, 31 AS quest_chapter, dummy_id_1132 AS quest_id, \"dummy_q_name_1132\" AS quest_name)\n    ,STRUCT(dummy_key_1133 AS map_key, \"dummy_name_1133\" AS map_name, 4 AS quest_act, 37 AS quest_chapter, dummy_id_1133 AS quest_id, \"dummy_q_name_1133\" AS quest_name)\n    ,STRUCT(dummy_key_1134 AS map_key, \"dummy_name_1134\" AS map_name, 4 AS quest_act, 42 AS quest_chapter, dummy_id_1134 AS quest_id, \"dummy_q_name_1134\" AS quest_name)\n    ,STRUCT(dummy_key_1135 AS map_key, \"dummy_name_1135\" AS map_name, 4 AS quest_act, 45 AS quest_chapter, dummy_id_1135 AS quest_id, \"dummy_q_name_1135\" AS quest_name)\n    ,STRUCT(dummy_key_1136 AS map_key, \"dummy_name_1136\" AS map_name, 4 AS quest_act, 48 AS quest_chapter, dummy_id_1136 AS quest_id, \"dummy_q_name_1136\" AS quest_name)\n    ,STRUCT(dummy_key_1137 AS map_key, \"dummy_name_1137\" AS map_name, 5 AS quest_act, 6 AS quest_chapter, dummy_id_1137 AS quest_id, \"dummy_q_name_1137\" AS quest_name)\n    ,STRUCT(dummy_key_1138 AS map_key, \"dummy_name_1138\" AS map_name, 5 AS quest_act, 10 AS quest_chapter, dummy_id_1138 AS quest_id, \"dummy_q_name_1138\" AS quest_name)\n    ,STRUCT(dummy_key_1139 AS map_key, \"dummy_name_1139\" AS map_name, 5 AS quest_act, 15 AS quest_chapter, dummy_id_1139 AS quest_id, \"dummy_q_name_1139\" AS quest_name)\n    ,STRUCT(dummy_key_1140 AS map_key, \"dummy_name_1140\" AS map_name, 5 AS quest_act, 19 AS quest_chapter, dummy_id_1140 AS quest_id, \"dummy_q_name_1140\" AS quest_name)\n    ,STRUCT(dummy_key_1141 AS map_key, \"dummy_name_1141\" AS map_name, 5 AS quest_act, 25 AS quest_chapter, dummy_id_1141 AS quest_id, \"dummy_q_name_1141\" AS quest_name)\n    ,STRUCT(dummy_key_1142 AS map_key, \"dummy_name_1142\" AS map_name, 5 AS quest_act, 30 AS quest_chapter, dummy_id_1142 AS quest_id, \"dummy_q_name_1142\" AS quest_name)\n    ,STRUCT(dummy_key_1143 AS map_key, \"dummy_name_1143\" AS map_name, 5 AS quest_act, 35 AS quest_chapter, dummy_id_1143 AS quest_id, \"dummy_q_name_1143\" AS quest_name)\n    ,STRUCT(dummy_key_1144 AS map_key, \"dummy_name_1144\" AS map_name, 5 AS quest_act, 38 AS quest_chapter, dummy_id_1144 AS quest_id, \"dummy_q_name_1144\" AS quest_name)\n    ,STRUCT(dummy_key_1145 AS map_key, \"dummy_name_1145\" AS map_name, 5 AS quest_act, 41 AS quest_chapter, dummy_id_1145 AS quest_id, \"dummy_q_name_1145\" AS quest_name)\n  ];\n\nWITH base_df AS ( -- 이탈유저유무, 누적과금액별 지역던전 베이스 테이블\n  SELECT map.*, leaving, acc_sales_cate\n  FROM UNNEST(region_quest) AS map, UNNEST(leaving_check) AS leaving, UNNEST(acc_sales) AS acc_sales_cate\n)\n\nSELECT * FROM base_df\n\n아래와 같이 합집합 테이블이 출력된다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRow\nmap_key\nmap_name\nquest_act\nquest_chapter\nquest_id\nquest_name\nleaving\nacc_sales_cate\n\n\n\n\n1\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n1. 무과금 (0원)\n\n\n2\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n2. 베이직 (1200원)\n\n\n3\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n3. 소과금\n\n\n4\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n4. 중과금\n\n\n5\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n5. 중고과금\n\n\n6\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n6. 고과금\n\n\n7\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n7. VIP\n\n\n8\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n8. VVIP\n\n\n9\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n0\n9. 고래유저\n\n\n10\ndummy_key_1111\ndummy_name_1111\n1\n13\ndummy_id_1111\ndummy_q_name_1111\n1\n1. 무과금 (0원)\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\n\n잘 join해서 사용하면 된다.\n\nSELECT bd.map_key, bd.map_name, bd.quest_act, bd.quest_chapter, bd.quest_id, bd.quest_name, bd.not_leaving\n  ,bd.acc_sales_cate, IFNULL(ar.total_cnt,0) AS total_cnt, IFNULL(ar.success_cnt,0) AS success_cnt\nFROM base_df bd\nLEFT JOIN agg_result ar ON \n  (ar.map_key = bd.map_key)\n  AND (ar.last_7_day_login = bd.not_leaving)\n  AND (ar.total_sales_cate = bd.acc_sales_cate)\nORDER BY quest_act, quest_chapter"
  },
  {
    "objectID": "posts/2022-10-25__Bigquery_7일 연속 미접속 시작일 쉽게 추출하기/index.html",
    "href": "posts/2022-10-25__Bigquery_7일 연속 미접속 시작일 쉽게 추출하기/index.html",
    "title": "Bigquery_7일 연속 미접속 시작일 쉽게 추출하기",
    "section": "",
    "text": "7일 연속 미접속 유저를 이탈 유저라고 하자.\n최초의 7일 연속 미접속 시작일을 구해야, 이탈일을 알 수 있다.\n기본 아이디어는 아래와 같다.\n\n접속한 날은 1, 접속하지 않은 날은 0으로 세팅한 정수 배열 생성\narray_to_string으로 정수 배열을 문자열로 변환\nSTRPOS(\"대상 문자열\", '0000000') 으로 0이 연속 7개가 등장하는 최초의 위치 찾음\n\n\nDECLARE date_array_base ARRAY&lt;DATE&gt;;\nDECLARE power_array_base ARRAY&lt;INT64&gt;;\nSET date_array_base = GENERATE_DATE_ARRAY(DATE('2022-08-16'), DATE('2022-10-23'), INTERVAL 1 DAY);\nSET power_array_base = GENERATE_ARRAY(0, 340000, 20000);\n\nwith abuse_list as ( --어뷰징 유저 목록\n  SELECT accountId\n  FROM `___`\n  WHERE acc_buy_krw IS NULL OR acc_buy_krw &lt; power(10,5)\n\n), raw_sum_sales as ( #누적과금액\n  SELECT accountId, sum(won) as total_sales\n  FROM `___`\n  WHERE b_date &lt; DATE(2022, 10, 23)\n    AND accountId NOT IN (SELECT accountId FROM abuse_list)\n  group by accountId\n\n), max_power_daily as ( --일자별 누적 최고전투력\n  SELECT b_date, accountId, max_power\n  FROM `___`\n  WHERE accountId NOT IN (SELECT accountId FROM abuse_list)\n\n), acc_created_date as ( --계정 생성일\n  SELECT accountId, EXTRACT(DATE FROM created_date) AS c_date\n  FROM `___`\n  WHERE b_date = DATE(2022, 10, 23)\n    AND accountId NOT IN (SELECT accountId FROM abuse_list)\n\n), total_logs_score_connect AS ( --로비 커넥트 로그\n  SELECT * FROM (\n    SELECT EXTRACT(DATE FROM date_time) AS b_date, account_id\n    FROM `___`\n  ) WHERE b_date &gt; DATE(2022, 08, 15)\n    AND account_id NOT IN (SELECT accountId FROM abuse_list)\n\n), account_id_connect_date_array AS ( --유저 별 접속일자 array 만들고, c_date(계정 생성일) 붙임\n  SELECT account_id, date_array, acd.c_date\n  FROM (\n    SELECT account_id, ARRAY_AGG(b_date ORDER BY b_date) AS date_array\n    FROM (\n      SELECT DISTINCT b_date, account_id\n      FROM total_logs_score_connect\n    )\n    GROUP BY account_id\n  ) base\n  LEFT JOIN acc_created_date acd ON acd.accountId = base.account_id\n\n), connect_date_max_power AS ( --접속한 날의 누적 최고전투력\n  SELECT base.account_id, days, mpd.max_power\n  FROM (\n    SELECT account_id, days\n    FROM account_id_connect_date_array, UNNEST(date_array) AS days\n    WHERE ARRAY_LENGTH(date_array) &gt; 14 --14일 초과 접속한 유저 대상\n  ) base\n  LEFT JOIN max_power_daily mpd ON (mpd.accountId = base.account_id AND mpd.b_date = base.days)\n  WHERE days &lt; DATE(2022, 10, 24)\n  ORDER BY account_id, days\n\n), add_gap_day_3_avg_last AS ( --접속일 기준, 3일 전투력 이동평균과 3일 전투력 이동평균의 일자별 변화량 계산\n  SELECT account_id, days, max_power, day_3_avg\n    ,(day_3_avg - LAG(day_3_avg) over(partition by account_id order by days)) AS gap_day_3_avg_last\n  FROM (\n    SELECT account_id, days, max_power\n      ,avg(max_power) over(partition by account_id order by days rows between 3 preceding and current row) as day_3_avg\n    FROM connect_date_max_power\n  )\n  ORDER BY account_id, days\n\n), get_first_stag_start_date AS ( --최초로 4접속일 연속 전투력이 같은 날\n  SELECT account_id, days, max_power, day_3_avg, gap_day_3_avg_last\n  FROM (\n    SELECT account_id, days, max_power, day_3_avg, gap_day_3_avg_last\n      ,ROW_NUMBER() OVER(PARTITION BY account_id ORDER BY days) num\n    FROM (\n      SELECT account_id, days, max_power, day_3_avg, gap_day_3_avg_last\n      FROM add_gap_day_3_avg_last\n      WHERE gap_day_3_avg_last = 0\n    )\n  ) WHERE num = 1\n  ORDER BY account_id, days\n  \n), add_connect_check_array AS (\n  SELECT cda.account_id, ssd.days\n    ,(\n      SELECT ARRAY (\n        SELECT\n          CASE\n            WHEN day &lt; ssd.days THEN \"3\" --최초 4접속일 연속 전투력 같은 날 보다 이전 날짜는 3 \n            WHEN day IN UNNEST(date_array) THEN \"1\" --접속일은 1\n            WHEN day &lt; c_date THEN \"2\" --계정 생성일보다 이전날짜는 2\n            ELSE \"0\" --접속 안했으면 0\n            END AS element\n        FROM UNNEST(date_array_base) as day\n      )\n    ) AS connect_check_array\n    ,date_array\n  FROM account_id_connect_date_array cda\n  LEFT JOIN get_first_stag_start_date ssd ON ssd.account_id = cda.account_id\n  WHERE ARRAY_LENGTH(date_array) &gt; 14 --14일 초과 접속한 유저 대상\n\n), add_leaving_position AS (\n  SELECT account_id, array_string, STRPOS(array_string, '0000000') AS leaving_pos --7일 연속 최초 미접속 확인부분\n  FROM (\n    SELECT account_id, connect_check_array, array_to_string(connect_check_array, '') AS array_string\n    FROM add_connect_check_array\n  )\n\n), get_leaving_date AS (\n  SELECT account_id, DATE_ADD(DATE(2022,08,16), INTERVAL leaving_pos-1 DAY) AS leaving_date --8/16이 위치 1이기 때문에, leaving_pos에서 1을 빼줌\n  FROM add_leaving_position\n  WHERE leaving_pos != 0 --7일 연속 미접속이 없는 계정은 제외\n\n)\n\nSELECT ssd.account_id, days, max_power, day_3_avg, gap_day_3_avg_last, gld.leaving_date, DATE_DIFF(gld.leaving_date, days, DAY) AS gap,\n  CASE\n    WHEN max_power BETWEEN power_array_base[OFFSET(0)] AND power_array_base[OFFSET(1)] THEN \"01. 0 ~ 20000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(1)]+1 AND power_array_base[OFFSET(2)] THEN \"02. 20001 ~ 40000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(2)]+1 AND power_array_base[OFFSET(3)] THEN \"03. 40001 ~ 60000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(3)]+1 AND power_array_base[OFFSET(4)] THEN \"04. 60001 ~ 80000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(4)]+1 AND power_array_base[OFFSET(5)] THEN \"05. 80001 ~ 100000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(5)]+1 AND power_array_base[OFFSET(6)] THEN \"06. 100001 ~ 120000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(6)]+1 AND power_array_base[OFFSET(7)] THEN \"07. 120001 ~ 140000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(7)]+1 AND power_array_base[OFFSET(8)] THEN \"08. 140001 ~ 160000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(8)]+1 AND power_array_base[OFFSET(9)] THEN \"09. 160001 ~ 180000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(9)]+1 AND power_array_base[OFFSET(10)] THEN \"10. 180001 ~ 200000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(10)]+1 AND power_array_base[OFFSET(11)] THEN \"11. 200001 ~ 220000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(11)]+1 AND power_array_base[OFFSET(12)] THEN \"12. 220001 ~ 240000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(12)]+1 AND power_array_base[OFFSET(13)] THEN \"13. 240001 ~ 260000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(13)]+1 AND power_array_base[OFFSET(14)] THEN \"14. 260001 ~ 280000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(14)]+1 AND power_array_base[OFFSET(15)] THEN \"15. 280001 ~ 300000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(15)]+1 AND power_array_base[OFFSET(16)] THEN \"16. 300001 ~ 320000\"\n    WHEN max_power BETWEEN power_array_base[OFFSET(16)]+1 AND power_array_base[OFFSET(17)] THEN \"17. 320001 ~ 340000\"\n    WHEN max_power &gt; power_array_base[OFFSET(17)] THEN \"18. 340001 ~ \"\n    ELSE \"None\"\n  END AS end_power_cate\n  ,CASE\n    WHEN total_sales IS NULL THEN '1. 무과금 (0원)'\n    WHEN total_sales &gt; 0 AND total_sales &lt; 1300 THEN '2. 베이직 (1200원)'\n    WHEN total_sales BETWEEN 1301 AND 22000 THEN '3. 소과금' \n    WHEN total_sales BETWEEN 22001 AND 60000 THEN '4. 중과금'\n    WHEN total_sales BETWEEN 60001 AND 240000 THEN '5. 중고과금'\n    WHEN total_sales BETWEEN 240001 AND 500000 THEN '6. 고과금'\n    WHEN total_sales BETWEEN 500001 AND 1000000 THEN '7. VIP'\n    WHEN total_sales BETWEEN 1000001 AND 10000000 THEN '8. VVIP'\n    WHEN total_sales &gt; 10000000 THEN '9. 고래유저'\n    ELSE \"None\"\n  END AS total_sales_cate\nFROM get_first_stag_start_date ssd\nLEFT JOIN get_leaving_date gld ON gld.account_id = ssd.account_id\nLEFT JOIN raw_sum_sales rss ON rss.accountId = ssd.account_id\nWHERE leaving_date IS NOT NULL"
  },
  {
    "objectID": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html",
    "href": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html",
    "title": "Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2",
    "section": "",
    "text": "차라리 로컬 DB에서 연산한 후, S3에 올리고 COPY로 집어넣는 것이 훨씬 빠르다.\nRedshift에서 직접 SELECT, INSERT 처리를 하면 : 300만행 추가에 예상 완료시간 4일\n로컬 DB에서 연산 후 COPY로 업로드하면 : 300만 행 연산시간 3.5시간, COPY 업로드 시간 5분\nAWS DW 설명 문서의 말을 들었어야 했는데.\n\n# 같은 코드를 로컬 DB에서 돌리면 3.5시간, Redshift에 연결해서 돌리면 4일\n\nwith psycopg2.connect(**connect_param_local) as con:\n    cur_2 = con.cursor()\n    # fetchall을 사용해서 커서를 재활용하지 않고 커서를 두 개 두는 이유는, redshift의 single-node cluster에서는 fetchall이 지원되지 않기 떄문이다.\n        # InternalError_: Fetch ALL is not supported on single-node clusters.\n        # Please specify the fetch size (maximum 1000 for single-node clusters) \n        # or upgrade to a multi node installation.\n    # 로컬 머신에서 연산하면 fetchall을 사용할 수 있으므로 이렇게 안 해도 되지만,\n    # 코드 수정이 더 번거로웠으므로 그냥 사용하였다.\n    \n    get_companylist_sql = '''select * from target_company_list;'''\n    target_company_list = sqlio.read_sql_query(get_companylist_sql, con)\n    # 1mb도 안되는 작은 테이블이라서 데이터프레임으로 한 번에 받아옴\n\n    for each_code in target_company_list['stock_code']:\n        cur_1 = con.cursor('ss_cursor') # server side cursor\n        # cur_1.itersize = 1000 # redshift single-node cluster에서의 server side cursor의 최대 제한값\n        \n        print(each_code,'_start')\n        predict_start = target_company_list[target_company_list['stock_code'] == each_code]['pre_6m'].values[0] - datetime.timedelta(days=1)\n        predict_end = predict_start - datetime.timedelta(days=1096)\n\n        cur_1.execute(\n            \"\"\"\n            select * from stock_data_2000_2020_raw\n            where (date between %(predict_end)s and %(predict_start)s) and (stock_code = %(stock_code)s);\n            \"\"\",\n            {'predict_end':predict_end.strftime(\"%Y-%m-%d\"),'predict_start':predict_start.strftime(\"%Y-%m-%d\"),'stock_code': each_code}\n        )\n\n        for each_row in cur_1: \n            # next(cur_1)로 한줄씩 불러와서 insert\n            cur_2.execute(\"\"\"insert into stock_data_3years_raw_6m values %s\"\"\", [each_row])\n            # each_row는 tuple이다.\n        con.commit()\n        print(each_code,'_commit complete')\n    cur_2.close()"
  },
  {
    "objectID": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#대량의-데이터를-insert로-넣을-생각은-하지-말-것",
    "href": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#대량의-데이터를-insert로-넣을-생각은-하지-말-것",
    "title": "Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2",
    "section": "",
    "text": "차라리 로컬 DB에서 연산한 후, S3에 올리고 COPY로 집어넣는 것이 훨씬 빠르다.\nRedshift에서 직접 SELECT, INSERT 처리를 하면 : 300만행 추가에 예상 완료시간 4일\n로컬 DB에서 연산 후 COPY로 업로드하면 : 300만 행 연산시간 3.5시간, COPY 업로드 시간 5분\nAWS DW 설명 문서의 말을 들었어야 했는데.\n\n# 같은 코드를 로컬 DB에서 돌리면 3.5시간, Redshift에 연결해서 돌리면 4일\n\nwith psycopg2.connect(**connect_param_local) as con:\n    cur_2 = con.cursor()\n    # fetchall을 사용해서 커서를 재활용하지 않고 커서를 두 개 두는 이유는, redshift의 single-node cluster에서는 fetchall이 지원되지 않기 떄문이다.\n        # InternalError_: Fetch ALL is not supported on single-node clusters.\n        # Please specify the fetch size (maximum 1000 for single-node clusters) \n        # or upgrade to a multi node installation.\n    # 로컬 머신에서 연산하면 fetchall을 사용할 수 있으므로 이렇게 안 해도 되지만,\n    # 코드 수정이 더 번거로웠으므로 그냥 사용하였다.\n    \n    get_companylist_sql = '''select * from target_company_list;'''\n    target_company_list = sqlio.read_sql_query(get_companylist_sql, con)\n    # 1mb도 안되는 작은 테이블이라서 데이터프레임으로 한 번에 받아옴\n\n    for each_code in target_company_list['stock_code']:\n        cur_1 = con.cursor('ss_cursor') # server side cursor\n        # cur_1.itersize = 1000 # redshift single-node cluster에서의 server side cursor의 최대 제한값\n        \n        print(each_code,'_start')\n        predict_start = target_company_list[target_company_list['stock_code'] == each_code]['pre_6m'].values[0] - datetime.timedelta(days=1)\n        predict_end = predict_start - datetime.timedelta(days=1096)\n\n        cur_1.execute(\n            \"\"\"\n            select * from stock_data_2000_2020_raw\n            where (date between %(predict_end)s and %(predict_start)s) and (stock_code = %(stock_code)s);\n            \"\"\",\n            {'predict_end':predict_end.strftime(\"%Y-%m-%d\"),'predict_start':predict_start.strftime(\"%Y-%m-%d\"),'stock_code': each_code}\n        )\n\n        for each_row in cur_1: \n            # next(cur_1)로 한줄씩 불러와서 insert\n            cur_2.execute(\"\"\"insert into stock_data_3years_raw_6m values %s\"\"\", [each_row])\n            # each_row는 tuple이다.\n        con.commit()\n        print(each_code,'_commit complete')\n    cur_2.close()"
  },
  {
    "objectID": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#query-parameter-전달-시의-유의점",
    "href": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#query-parameter-전달-시의-유의점",
    "title": "Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2",
    "section": "2.1 Query parameter 전달 시의 유의점",
    "text": "2.1 Query parameter 전달 시의 유의점\n\npsycopg2 document에는, 빨간색으로 엄청 잘 보이게 써 있는 경고문이 있다.\n\n\nWarning: Never, never, NEVER use Python string concatenation (+) or string parameters interpolation (%) to pass variables to a SQL query string. Not even at gunpoint.\n\n\nSQL Injection의 위험이 있기 때문인데, 어떻게 위험한지는 여기를 참고하자.\n그럼 어떻게 하라는 걸까?\n\n최종적으로 사용한 형식은 아래와 같다.\n\nimport psycopg2\nfrom psycopg2 import sql\n\ncredentials = 'aws_access_key_id=**************;aws_secret_access_key=**************'\ns3_bucket_param = 's3://BUCKET-NAME/FILE-NAME'\n\ncopy_query = sql.SQL(\"\"\"\n        copy {table_name}\n        from %(s3_bucket_param)s\n        credentials %(credentials)s\n        IGNOREHEADER 1\n        CSV;\n    \"\"\").format(table_name = sql.Identifier('TABLE-NAME'))\n\ncur.execute(copy_query, {'s3_bucket_param':s3_bucket_param, 'credentials':credentials})\n\n{} : 테이블 이름 등의 identifier를 받는다. %s 형식으로 identifier를 받으려고 하면, 제대로 인식이 안 되기 때문에 번거롭지만 .foramt(table_name = sql.Identifier('TABLE-NAME'))형식으로 인자를 넘겨야 한다. keyword parameter로 안 해도 되지만, 어떤 자리에 무엇이 들어가는 지 명확하게 정의하는 것을 좋아하므로 몽땅 keyword parameter로 진행하였다.\n\nsql 모듈 설명\n같은 문제로 고통받던 사람의 이슈제기\n\n%(keyword)s : value를 받는다. execute 함수 내부에서 인자로 전달하면 된다. keyword parameter로 정의했을 경우 dictionary로 전달하자."
  },
  {
    "objectID": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#server-side-cursor",
    "href": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#server-side-cursor",
    "title": "Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2",
    "section": "2.2 Server Side Cursor",
    "text": "2.2 Server Side Cursor\n\nClient Side Cursor를 사용하면, 일단 데이터를 클라이언트의 메모리에 저장한 후 거기서 결과값을 계산하게 된다.\n엄청 큰 테이블의 일부를 select 하려고 하면 반드시 메모리 부족으로 문제가 생기게 된다.\nServer Side Cursor를 사용하면, 서버에서 연산 처리 후 결과값만 반환해주기 때문에, 클라이언트 메모리 문제에서 좀 자유로워진다.\n서버 리소스는 더 쓰게 되고, 네트워크 부하는 줄어들게 된다.\n\n# 편리하게도 커서에 이름만 지정해주면 된다!\ncur_1 = con.cursor('ss_cursor')"
  },
  {
    "objectID": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#copy-시의-권한-문제",
    "href": "posts/2020-02-11__Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2/index.html#copy-시의-권한-문제",
    "title": "Redshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2",
    "section": "3.1 COPY 시의 권한 문제",
    "text": "3.1 COPY 시의 권한 문제\n\n작업 폴더 내에 있는 CSV 파일을 그대로 COPY하려고 하면, 무조건 permission error가 발생한다.\nDB 서버 사용자가 해당 파일에 접근할 권한이 없기 때문에 발생하는 문제로, 파일이나 폴더의 권한설정을 만져주면 해결된다. 그런데 권한 설정하는 것 보다는 DB 서버 사용자가 접근할 수 있는 폴더에 CSV 파일을 옮기는 것이 더 빠르지 않을까?\n\npostgreSQL을 Mac에서 Homebrew로 설치했다면, /usr/local/var/postgres\n예시\n\n\nwith psycopg2.connect(**connect_param_local) as con:\n    with con.cursor() as cur:\n        cur.execute(\n            \"\"\"\n            COPY stock_data_2000_2020_raw\n            from '/usr/local/var/postgres/stock_data_raw_2.csv'\n            DELIMITER ','\n            CSV HEADER;\n            \"\"\")\ncon.commit()"
  },
  {
    "objectID": "posts/2022-05-26__Python Google Drive API v3로 파일 업로드/index.html",
    "href": "posts/2022-05-26__Python Google Drive API v3로 파일 업로드/index.html",
    "title": "Python Google Drive API v3로 파일 업로드",
    "section": "",
    "text": "0.1 1. google api 패키지 설치\n\n!pip3 install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\n\n\n0.2 2. Credential 세팅 후 실행\n\nhttps://console.cloud.google.com/ 접속\n원하는 프로젝트 선택\nAPI & Services\n\nEnabled APIs & Services에서 Google Drive API 활성화\nCredentials\n\nCreate Credentials -&gt; OAuth client ID 생성\n\nservice account를 사용하고 싶었으나, 대상 폴더가 회사 조직 내 계정이 아니면 공유가 되지 않는 폴더여서 service account 사용이 불가능\n가능한 상황이면, service account를 대상 폴더의 편집자로 추가하는 편이, 더 보안상 좋다.\n\nDownload OAuth Client\n\nclinet-secret JSON 파일이 받아진다.\n\n\n\nhttps://developers.google.com/drive/api/quickstart/python\n\nquickstart 스크립트를 적절하게 바꾸어서 실행한다.\n최초로 실행하면 로그인 과정 후에 token.json이 생성되고, 이후에는 token.json을 읽어서 실행된다.\n아래 스크립트는 xlsx 파일 하나를 원하는 폴더에 업로드 하는 스크립트이다.\n\n\n\nimport os.path\n\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\n# If modifying these scopes, delete the file token.json.\n# \nSCOPES = ['https://www.googleapis.com/auth/drive.file']\n\n\ndef main():\n    \"\"\"Shows basic usage of the Drive v3 API.\n    Prints the names and ids of the first 10 files the user has access to.\n    \"\"\"\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists('token.json'):\n        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file('Download OAuth Clinet에서 받은 client-secret JSON 파일', SCOPES)\n            creds = flow.run_local_server(port=0)\n        # Save the credentials for the next run\n        with open('token.json', 'w') as token:\n            token.write(creds.to_json())\n\n    try:\n        # 원하는 작업 코드 작성\n        # 이 경우에는, xlsx 파일 하나를 원하는 폴더에 업로드        \n        folder_id = '원하는 폴더 ID'\n        service = build('drive', 'v3', credentials=creds)\n        file_metadata = {'name': 'quest_main_join_string_name.xlsx','parents': [folder_id]}\n        media = MediaFileUpload('quest_main_join_string_name.xlsx',\n                            mimetype=None, resumable=True)\n        # 파일이 커질 것 같으면 resumable을 켜 주는 것이 좋다.\n        file = service.files().create(body=file_metadata,media_body=media,fields='id').execute\n        \n        except HttpError as error:\n            # TODO(developer) - Handle errors from drive API.\n            print(f'An error occurred: {error}')\n\nif __name__ == '__main__':\n    main()"
  },
  {
    "objectID": "posts/2025-10-08__Cloud Compute Instance 사용 시 알아두면 좋은 사용법들/index.html",
    "href": "posts/2025-10-08__Cloud Compute Instance 사용 시 알아두면 좋은 사용법들/index.html",
    "title": "Cloud Compute Instance 사용 시 알아두면 좋은 사용법들",
    "section": "",
    "text": "1. Oracle Compute Instance에 고정 IP 할당하기\n\n2025-10-08 기준 내용\n\n\nHamburger 메뉴 버튼 클릭\nNetworking\nIP management\nReserved public IPs\nReserve public IP address 버튼 클릭\n내용 작성하여 등록\n고정 IP 할당 결과 \n\n\n\n2. ~.ssh/config에서 간단 접속 설정\n\n터미널에서 nano ~/.ssh/config 실행하여 config 편집\n\nHost 사용할_호스트_이름\n    # Public IP\n    HostName 000.000.000.000\n    Port 00000\n    # 서버 유저\n    User user_account_name\n    # Private key 경로\n    IdentityFile /Users/..../private.key\n\n    # 연결 유지 (끊김 방지)\n    ## 60초마다 null packet을 보내서 연결이 끊기지 않게 유지\n    ServerAliveInterval 60\n    ## ServerAliveInterval에 설정된 간격으로 신호를 보냈는데 서버로부터 응답이 없을 경우, 몇 번까지 더 시도할지를 결정\n    ServerAliveCountMax 3\n\n    # 연결 재사용 (속도 향상)\n    ControlMaster auto\n    ControlPath ~/.ssh/controlmasters/%r@%h:%p\n    ControlPersist 10m\n\n    # 접속 시도 타임아웃\n    ConnectTimeout 10\n\n    # 보안 관련 옵션\n    ## X11 Forwarding(GUI 프로그램 실행) 기능을 비활성화. 서버에서 GUI 애플리케이션을 사용할 일이 없다면 꺼두는 것이 보안에 좋음\n    ForwardX11 no\n    ## 내 PC → Bastion 서버 (Public IP) → Private 서버 (Private IP) 이런 접속 구조가 필요할 때에는 SSH Agent Forwarding이 필요\n    ## 하지만 저런 구조에서 사용할 일이 없으므로 끈다.\n    ForwardAgent no\n\n각 항목에 대한 설명\n\n\n연결 유지\n\nServerAliveInterval 60 : 60초마다 null packet을 보내서 연결이 끊기지 않게 유지\nServerAliveCountMax 3 : ServerAliveInterval에 설정된 간격으로 신호를 보냈는데 서버로부터 응답이 없을 경우, 몇 번까지 더 시도할지를 결정. 3번의 시도에도 서버가 응답하지 않으면, 클라이언트는 서버에 문제가 생겼거나 네트워크 연결이 끊어졌다고 판단하고 SSH 접속을 스스로 종료.\n\n연결 재사용 (속도 향상)\n\nControlMaster auto : 특정 호스트에 대한 첫 SSH 연결이 “마스터(Master)” 연결이 되어, 이후의 연결들이 이 마스터 연결을 공유하도록 허용\n\nssh를 실행하면, ControlMaster는 지정된 ControlPath에 연결을 제어하는 소켓(통신 통로) 파일이 있는지 확인. 파일이 없으면 새로 연결을 맺고 마스터가 되어 소켓을 생성. 파일이 있으면, 새로 인증 절차를 밟는 대신 기존 소켓을 통해 즉시 통신을 시작.\n\nControlPath ~/.ssh/controlmasters/%r@%h:%p\n\nControlMaster가 생성하는 제어용 소켓 파일을 어디에 어떤 이름으로 만들지 지정\n이 경우에는 아래와 같음\n\n%r: 원격 서버의 사용자 이름 (remote username)\n%h: 원격 서버의 호스트 이름 (remote hostname)\n%p: 원격 서버의 포트 번호 (port)\n\n\n\n접속 시도 타임아웃\n\nConnectTimeout 10\n\n10초 내에 TCP 연결이 수립되지 않으면 즉시 접속을 실패 처리하고 명령을 종료\n\n\n보안 관련 옵션\n\nForwardX11 no\n\nX11 Forwarding은 원격 서버에서 실행한 GUI(그래픽 인터페이스) 프로그램의 화면을 내 로컬 PC 모니터에 표시해주는 기능\nX11 Forwarding을 활성화하면(ForwardX11 yes), SSH 연결을 통해 원격 서버와 내 PC 사이에 특수한 “그래픽용 통신 채널”이 열림. 만약 접속한 원격 서버가 해킹당했다면, 공격자는 이 채널을 악용할 수 있음\n\nForwardAgent no\n\nSSH Agent Forwarding은 내 로컬 PC의 SSH 개인 키를 다른 서버로 직접 복사하지 않고, 원격 서버가 내 키를 잠시 빌려서 또 다른 서버에 접속할 수 있게 해주는 기능\nSSH Agent Forwarding은 주로 Bastion Host (또는 Jump Server) 환경에서 사용\nBastion Host는 내부망을 보호하기 위해 외부에서 내부 서버로 접근하기 위한 유일한 관문 역할을 하는 서버\n내 PC → Bastion 서버 (Public IP) → Private 서버 (Private IP)\n\nAgent Forwarding이 없다면\n\n내 PC에서 Bastion 서버로 접속\nBastion 서버에서 Private 서버로 또 접속해야 하므로, Bastion 서버에 Private 서버 접속용 개인 키를 복사해둬야 함\n\nAgent Forwarding을 사용한다면\n\n내 PC에서 Agent Forwarding 옵션을 켜고 Bastion 서버에 접속\nBastion 서버에서 Private 서버로 접속을 시도하면, 인증 요청이 내 PC의 SSH Agent로 전달\n내 PC의 Agent가 인증을 대신 처리해 주므로, Private 서버로 바로 접속\nBastion 서버에는 어떠한 개인 키 파일도 남지 않아 훨씬 안전\n\n편리함에도 불구하고 ForwardAgent no를 권장하는 이유는, 중간 서버(Bastion)가 해킹당했을 때 심각한 보안 위협이 될 수 있기 때문\n\n\n\n\n\n\n3. Oracle Compute Instance 포트 오픈\n\nNetworking\nSubnet\nSecurity\n\n\nSecurity List에서 수정 원하는 항목 클릭 \n\n\nSecurity Rules\n\n\n여기까지 왔으면 이제 Ingress Rule과 Egress Rule을 수정할 수 있다. \n\n\nIngress Rule 설정 시 사용하는 CIDR (Classless Inter-Domain Routing)에 대한 설명은 다음 포스트를 참조\n\n\nCIDR\n\n\n\n4. Oracle Compute Instance SSH 포트 변경\n\n3. Oracle Compute Instance 포트 오픈을 참고하여 원하는 포트를 연다.\nssh 설정 수정 : sudo vi /etc/ssh/sshd_config\n\n\n포트 정보를 추가한다. 예를 들면 아래와 같다.\n\n# Port 22  (기존 줄을 주석 처리하지 말고 일단 유지)\nPort 00000 (새로운 줄 추가)\n\nssh.socket 비활성화\n\n\nssh.socket이 포트를 22번만 리스닝 하게 고정시키므로, 비활성화한다.\n\nsystemd가 포트 22 리스닝 → sshd_config 무시\ncat /lib/systemd/system/ssh.socket\n\n[Socket]\nListenStream=22\nAccept=no\nssh.socket의 역할 : 시스템 부팅 → systemd가 포트만 리스닝 → 연결 요청 오면 → sshd 자동 시작\n\nsystemd가 포트 22번만 리스닝 (하드코딩됨)\nSSH 연결이 없으면 sshd는 실행되지 않음\n연결 요청이 오면 그때 sshd를 시작\n메모리 절약 및 on-demand 실행을 위한 최적화\n\n전통적인 방식 : 시스템 부팅 → sshd 데몬 시작 → 계속 실행 중 → 연결 대기\n\nSSH 데몬이 항상 메모리에 상주\n/etc/ssh/sshd_config의 Port 설정을 사용\n\nssh.socket을 왜 꺼도 되는가?\n\nSSH 서비스는 여전히 작동\n서버에서 SSH는 자주 사용되므로 on-demand 실행의 이점이 적음\nsshd 데몬의 메모리 사용량은 매우 적음 (몇 MB)\n\n/lib/systemd/system/ssh.socket의 ListenStream 값을 바꿔도 되긴 하는데..\n\nopenssh-server 패키지가 업데이트되면 설정이 덮어씌워짐\noverride 메커니즘을 사용하면 되지만 관리가 복잡함\n\n이제 비활성화 하자\n# 1. SSH 소켓 비활성화 및 중지\nsudo systemctl stop ssh.socket\nsudo systemctl disable ssh.socket\n\n# 2. SSH 서비스만 활성화 (소켓 없이)\nsudo systemctl enable ssh.service\nsudo systemctl restart ssh\n\n# 3. 포트 확인\nsudo ss -tlnp | grep ssh\n\n\niptables 규칙 추가\n\n기본적으로 UFW가 없음. iptables로 관리\n규칙 추가 예시\nsudo iptables -I INPUT 5 -p tcp --dport 00000 -m state --state NEW -j ACCEPT\n규칙 확인\nsudo iptables -L INPUT -n -v --line-numbers\n규칙 저장\n# iptables-persistent 설치 (없다면)\nsudo apt-get update\nsudo apt-get install iptables-persistent\n\n# 규칙 저장. 재부팅 후에도 유지\nsudo netfilter-persistent save \n\n여기까지 진행했다면 이제 로컬 머신에서 SSH 접속 테스트를 하고, 성공적으로 접속되었다면 22번 포트는 막자.\n\n\n\n5. vscode, cursor 등으로 원격 서버에 SSH로 접속하여 스크립트를 만든 후, 스크립트 실행 시 권한 문제 발생\n\n-rw-rw-r-- 권한으로 스크립트가 생성되는데, 실행 권한이 없다. 보안 문제가 발생할 수 있어서 기본 설정이 이렇다.\nchmod +x /스크립트/경로 수행하면 해결"
  },
  {
    "objectID": "posts/2024-01-12__Quarto 사용하기/index.html",
    "href": "posts/2024-01-12__Quarto 사용하기/index.html",
    "title": "Quarto 101",
    "section": "",
    "text": "Quarto로 만든 블로그에 Quarto 사용법을 이제야 정리하다니.."
  },
  {
    "objectID": "posts/2024-01-12__Quarto 사용하기/index.html#소스코드가-변경된-문서만-렌더링-하기",
    "href": "posts/2024-01-12__Quarto 사용하기/index.html#소스코드가-변경된-문서만-렌더링-하기",
    "title": "Quarto 101",
    "section": "2.1 소스코드가 변경된 문서만 렌더링 하기",
    "text": "2.1 소스코드가 변경된 문서만 렌더링 하기\n\n_quarto.yml 파일에서 아래와 같은 옵션을 추가하자. 공식 문서 설명\n\nexecute:\n  freeze: auto  # re-render only when source changes"
  },
  {
    "objectID": "posts/2019-10-11__Python_Parameters, Arguments 정의와 차이점/index.html",
    "href": "posts/2019-10-11__Python_Parameters, Arguments 정의와 차이점/index.html",
    "title": "Python_Parameters, Arguments 정의와 차이점",
    "section": "",
    "text": "Parameters are defined by the names that appear in a function definition, whereas arguments are the values actually passed to a function when calling it. Parameters define what types of arguments a function can accept. For example, given the function definition:\n\ndef func(foo, bar=None, **kwargs):\n    pass\n\nfoo, bar and kwargs are parameters of func. However, when calling func, for example:\n\nfunc(42, bar=314, extra=somevar)\n\nthe values 42, 314, and somevar are argument\nPython FAQ\nParameter와 Argument의 차이는 알았다. 그럼 각각의 자세한 정의는 어떻게 될까?\n\n1 parameter\n\nGlossary &gt; Parameter\nA named entity in a function (or method) definition that specifies an argument (or in some cases, arguments) that the function can accept. There are five kinds of parameter:\npositional-or-keyword: specifies an argument that can be passed either positionally or as a keyword argument. This is the default kind of parameter, for example foo and bar in the following:\n\n\ndef func(foo, bar=None): ...\n\n두 형태로 다 받아도 상관이 없는 형태의 예시\n\ndef sum(a, b=10):\n    print(a+b)\nsum(1,2)\nsum(1,b=2)\n# 출력값은 둘 다 3으로 잘 나온다.\n# b는 keyword parameter지만, positional처럼 값을 넣어도 잘 작동한다.\n\n3\n3\n\n\n\npositional-only: specifies an argument that can be supplied only by position. Python has no syntax for defining positional-only parameters. However, some built-in functions have positional-only parameters (e.g. abs()).\nabs()에 keyword argument를 넣으려고 하면, 시원하게 에러가 뜬다.\n\n\nabs(foo=10)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nInput In [4], in &lt;cell line: 1&gt;()\n----&gt; 1 abs(foo=10)\n\nTypeError: abs() takes no keyword arguments\n\n\n\n\nkeyword-only: specifies an argument that can be supplied only by keyword. Keyword-only parameters can be defined by including a single var-positional parameter or bare * in the parameter list of the function definition before them, for example kw_only1 and kw_only2 in the following:\n\n\ndef func(*arg, *, kw_only1, kw_only2): ...\n\n\n단일 Asterisk 뒤에 오는 parameter들은 무조건 keyword parameter여야 한다. PEP-3102\nvar-positional parameter 뒤에 오는 parameter들은 무조건 keyword parameter여야 한다.\n\n\ndef print1(a, b, *, kw_only1=None, kw_only2=None, positional):\n    return print(a,b,kw_only1, kw_only2, positional)\n\nprint1(3,4,kw_only1=1, kw_only2=2, 3)\n# 장렬한 에러 메세지\n\n\n  Input In [5]\n    print1(3,4,kw_only1=1, kw_only2=2, 3)\n                                        ^\nSyntaxError: positional argument follows keyword argument\n\n\n\n\n\nvar-positional: specifies that an arbitrary sequence of positional arguments can be provided (in addition to any positional arguments already accepted by other parameters). Such a parameter can be defined by prepending the parameter name with *, for example args in the following:\n\n\ndef func(*args, **kwargs): ...\n\n\nvar-keyword: specifies that arbitrarily many keyword arguments can be provided (in addition to any keyword arguments already accepted by other parameters). Such a parameter can be defined by prepending the parameter name with, for example kwargs in the example above. Parameters can specify both optional and required arguments, as well as default values for some optional arguments.\n\n직접 임의의(arbitrary) argument들을 마음껏 넣어보자.\n\ndef print1(*args, **kwargs):\n    print(args)\n    print(kwargs)\n\nprint1(1,2,3,4,5, kw1='a', kw2='b', kw3='hoho')\n\n(1, 2, 3, 4, 5)\n{'kw1': 'a', 'kw2': 'b', 'kw3': 'hoho'}\n\n\nSee also the argument glossary entry, the FAQ question on the difference between arguments and parameters, the inspect.Parameter class, the Function definitions section, and PEP 362.\n\n\n2 argument\n\nGlossary &gt; Argument\n\nA value passed to a function (or method) when calling the function. There are two kinds of argument:\n\nkeyword argument: an argument preceded by an identifier (e.g. name=) in a function call or passed as a value in a dictionary preceded by **. For example, 3 and 5 are both keyword arguments in the following calls to complex():\n\n\ncomplex(real=3, imag=5)\ncomplex(**{'real': 3, 'imag': 5})\n# 복소수를 출력하는 함수. 출력값은 (3+5j) 가 된다.\n# Asterisk가 data structure를 해체하여 전달하는 역할을 하는데, \n# 자세한 내용은 다른 포스트에서 다뤄보자.\n\n(3+5j)\n\n\n\npositional argument: an argument that is not a keyword argument. Positional arguments can appear at the beginning of an argument list and/or be passed as elements of an iterable preceded by *. For example, 3 and 5 are both positional arguments in the following calls:\n\n\ncomplex(3, 5)\n\n(3+5j)\n\n\n\ncomplex(*(3, 5))\n\n(3+5j)\n\n\nArguments are assigned to the named local variables in a function body. See the Calls section for the rules governing this assignment. Syntactically, any expression can be used to represent an argument; the evaluated value is assigned to the local variable.\nSee also the parameter glossary entry, the FAQ question on the difference between arguments and parameters, and PEP 362."
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_04_Dataframe 결합/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_04_Dataframe 결합/index.html",
    "title": "Pandas_04_Dataframe 결합",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display_html, display"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_04_Dataframe 결합/index.html#concat",
    "href": "posts/2021-11-05__pandas_cheatsheet_04_Dataframe 결합/index.html#concat",
    "title": "Pandas_04_Dataframe 결합",
    "section": "1.1 concat",
    "text": "1.1 concat\npandas.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=True)\n\ns1 = pd.Series(['a', 'b'])\ns2 = pd.Series(['c', 'd'])\npd.concat([s1, s2]) # Series 두 개 합치기\n\n0    a\n1    b\n0    c\n1    d\ndtype: object\n\n\n\npd.concat([s1, s2], ignore_index=True) # 합치면서 index 새로 만들어줌\n\n0    a\n1    b\n2    c\n3    d\ndtype: object\n\n\n\ns3 = pd.concat([s1, s2], keys=['s1', 's2']) # 최외각 레벨에 새로운 index를 만들어줌\nprint(s3)\nprint(s3['s1']) \nprint(s3['s2'][0]) # 이렇게 조회가능\n\ns1  0    a\n    1    b\ns2  0    c\n    1    d\ndtype: object\n0    a\n1    b\ndtype: object\nc\n\n\n\ns3 = pd.concat([s1, s2], keys=['s1', 's2'], names=['Series name', 'Row ID'])\n# index에 이름 붙이기\nprint(s3)\nprint(s3.index)\nprint(s3.index.names)\n\nSeries name  Row ID\ns1           0         a\n             1         b\ns2           0         c\n             1         d\ndtype: object\nMultiIndex([('s1', 0),\n            ('s1', 1),\n            ('s2', 0),\n            ('s2', 1)],\n           names=['Series name', 'Row ID'])\n['Series name', 'Row ID']\n\n\n\ndf1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\nprint(df1)\ndf2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number'])\nprint(df2)\npd.concat([df1, df2]) # Dataframe 합치기\n\n  letter  number\n0      a       1\n1      b       2\n  letter  number\n0      c       3\n1      d       4\n\n\n\n\n\n\n\n\n\nletter\nnumber\n\n\n\n\n0\na\n1\n\n\n1\nb\n2\n\n\n0\nc\n3\n\n\n1\nd\n4\n\n\n\n\n\n\n\n\ndf3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n                   columns=['letter', 'number', 'animal'])\nprint(df3)\npd.concat([df1, df3], sort=False) # 한 쪽에 없는 컬럼의 값은 NaN으로 삽입됨\n\n  letter  number animal\n0      c       3    cat\n1      d       4    dog\n\n\n\n\n\n\n\n\n\nletter\nnumber\nanimal\n\n\n\n\n0\na\n1\nNaN\n\n\n1\nb\n2\nNaN\n\n\n0\nc\n3\ncat\n\n\n1\nd\n4\ndog\n\n\n\n\n\n\n\n\npd.concat([df1, df3], join=\"inner\") # join=\"inner\"로 하면 양쪽에 다 있는 컬럼만 합쳐서 반환함\n\n\n\n\n\n\n\n\nletter\nnumber\n\n\n\n\n0\na\n1\n\n\n1\nb\n2\n\n\n0\nc\n3\n\n\n1\nd\n4\n\n\n\n\n\n\n\n\ndf4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n                   columns=['animal', 'name'])\npd.concat([df1, df4], axis=1) # axis=1이면 컬럼을 붙임\n\n\n\n\n\n\n\n\nletter\nnumber\nanimal\nname\n\n\n\n\n0\na\n1\nbird\npolly\n\n\n1\nb\n2\nmonkey\ngeorge\n\n\n\n\n\n\n\n\ndf4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george'], ['dog', 'sam']],\n                   columns=['animal', 'name'])\npd.concat([df1, df4], axis=1) \n# axis=1이면 컬럼을 붙임\n# 행의 수가 다르면, 행이 적은 쪽에 NaN이 삽입된 행이 추가됨\n\n\n\n\n\n\n\n\nletter\nnumber\nanimal\nname\n\n\n\n\n0\na\n1.0\nbird\npolly\n\n\n1\nb\n2.0\nmonkey\ngeorge\n\n\n2\nNaN\nNaN\ndog\nsam\n\n\n\n\n\n\n\n\ndf5 = pd.DataFrame([1], index=['a'])\ndf6 = pd.DataFrame([2], index=['a'])\npd.concat([df5, df6], verify_integrity=True)\n# verify_integrity=True를 하면, index가 같은 것을 허용하지 않음.\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[14], line 3\n      1 df5 = pd.DataFrame([1], index=['a'])\n      2 df6 = pd.DataFrame([2], index=['a'])\n----&gt; 3 pd.concat([df5, df6], verify_integrity=True)\n      4 # verify_integrity=True를 하면, index가 같은 것을 허용하지 않음.\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    325 if len(args) &gt; num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--&gt; 331 return func(*args, **kwargs)\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:368, in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\n    146 @deprecate_nonkeyword_arguments(version=None, allowed_args=[\"objs\"])\n    147 def concat(\n    148     objs: Iterable[NDFrame] | Mapping[HashableT, NDFrame],\n   (...)\n    157     copy: bool = True,\n    158 ) -&gt; DataFrame | Series:\n    159     \"\"\"\n    160     Concatenate pandas objects along a particular axis.\n    161 \n   (...)\n    366     1   3   4\n    367     \"\"\"\n--&gt; 368     op = _Concatenator(\n    369         objs,\n    370         axis=axis,\n    371         ignore_index=ignore_index,\n    372         join=join,\n    373         keys=keys,\n    374         levels=levels,\n    375         names=names,\n    376         verify_integrity=verify_integrity,\n    377         copy=copy,\n    378         sort=sort,\n    379     )\n    381     return op.get_result()\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:563, in _Concatenator.__init__(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\n    560 self.verify_integrity = verify_integrity\n    561 self.copy = copy\n--&gt; 563 self.new_axes = self._get_new_axes()\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:633, in _Concatenator._get_new_axes(self)\n    631 def _get_new_axes(self) -&gt; list[Index]:\n    632     ndim = self._get_result_dim()\n--&gt; 633     return [\n    634         self._get_concat_axis if i == self.bm_axis else self._get_comb_axis(i)\n    635         for i in range(ndim)\n    636     ]\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:634, in &lt;listcomp&gt;(.0)\n    631 def _get_new_axes(self) -&gt; list[Index]:\n    632     ndim = self._get_result_dim()\n    633     return [\n--&gt; 634         self._get_concat_axis if i == self.bm_axis else self._get_comb_axis(i)\n    635         for i in range(ndim)\n    636     ]\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36, in pandas._libs.properties.CachedProperty.__get__()\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:697, in _Concatenator._get_concat_axis(self)\n    692 else:\n    693     concat_axis = _make_concat_multiindex(\n    694         indexes, self.keys, self.levels, self.names\n    695     )\n--&gt; 697 self._maybe_check_integrity(concat_axis)\n    699 return concat_axis\n\nFile ~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/reshape/concat.py:705, in _Concatenator._maybe_check_integrity(self, concat_index)\n    703 if not concat_index.is_unique:\n    704     overlap = concat_index[concat_index.duplicated()].unique()\n--&gt; 705     raise ValueError(f\"Indexes have overlapping values: {overlap}\")\n\nValueError: Indexes have overlapping values: Index(['a'], dtype='object')"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_04_Dataframe 결합/index.html#dataframe-join의-속도를-향상시키기-위해서는",
    "href": "posts/2021-11-05__pandas_cheatsheet_04_Dataframe 결합/index.html#dataframe-join의-속도를-향상시키기-위해서는",
    "title": "Pandas_04_Dataframe 결합",
    "section": "2.1 Dataframe Join의 속도를 향상시키기 위해서는?",
    "text": "2.1 Dataframe Join의 속도를 향상시키기 위해서는?\n\nhttps://stackoverflow.com/questions/40860457/improve-pandas-merge-performance\nkey를 index로 사용한다.\n\nindex 검색 시에는 hash table을 이용하기 때문\nA short explanation why it is faster to merge by index instead of by a “normal” column: Indices have a hash table. Meaning you can look them up in amortized O(1). For a normal column you need O(n) in worst case, meaning merging two dfs with len n takes O(n^2) in worst case.\n\njoin을 쓴다.\nconcat을 쓴다.\n\n여기서의 결론 : key를 index로 사용한 후 join을 쓴다.\n\nimport random\ndf1 = pd.DataFrame({'uid_sample': random.sample(range(100000), 80000), 'value': random.sample(range(10000000), 80000)})\ndf2 = pd.DataFrame({'userId_sample2': random.sample(range(100000), 80000), 'value': random.sample(range(10000000), 80000)})\n# 80000명의 정보를 담고 있는 두 Dataframe이 있다고 하자.\n# uid_sample, userId_sample2를 key로 조인하고 싶다.\n\n\n%%timeit\ndf1.merge(df2, how='left', left_on='uid_sample', right_on='userId_sample2')\n\n7.02 ms ± 478 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\n# key로 사용하려는 컬럼을 index로 할당\n# 10%정도 빨라졌다.\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\ndf3.merge(df4, right_index=True, left_index=True)\n\n6.3 ms ± 195 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\n# key로 사용하려는 컬럼을 index로 할당\n# join 함수 사용\n# 여기서 이미 3배 빨라졌다\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\ndf3.join(df4, how='left', lsuffix='left', rsuffix='right')\n\n2.08 ms ± 88.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\n# inner, outer밖에 안 되는데 join보다 느리다.\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\npd.concat([df3, df4], axis=1, join='inner')\n\n6.12 ms ± 87 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
  },
  {
    "objectID": "posts/2025-10-08__uv init으로 시작하는 프로젝트 환경 세팅/index.html",
    "href": "posts/2025-10-08__uv init으로 시작하는 프로젝트 환경 세팅/index.html",
    "title": "uv init으로 시작하는 프로젝트 환경 세팅",
    "section": "",
    "text": "1. 프로젝트 디렉토리로 이동\n\ncd /path/to/project\n\n\n\n2. uv로 가상환경 생성\n\n특정 python 버전으로 생성\n\n# Python 3.12로 가상환경 생성\nuv venv --python 3.12\n\nuv 프로젝트로 초기화\n\n# 프로젝트 초기화 (pyproject.toml 생성)\nuv init\n\n.python-version 파일이 생성되는데, 여기서 가상환경에 사용될 python 버전을 설정할 수 있음\n2025-10-09 시점에는 3.12로 생성됨\n\n# pyproject.toml 의존성 설치\nuv sync\n\n\n3. 가상환경 활성화\n# 가상환경 활성화\nsource .venv/bin/activate\n\n# 특정 이름으로 생성한 경우\nsource .venv_some_project/bin/activate\n\n\n4. 가상환경 비활성화\ndeactivate"
  },
  {
    "objectID": "posts/2019-11-11__Asynchronous, Synchronous, Blocking, Non-Blocking/index.html",
    "href": "posts/2019-11-11__Asynchronous, Synchronous, Blocking, Non-Blocking/index.html",
    "title": "Asynchronous, Synchronous, Blocking, Non-Blocking",
    "section": "",
    "text": "많은 자료의 산 중에서, 가장 알기 쉽고 직관적으로 설명한 자료는 https://stackoverflow.com/questions/2625493/asynchronous-vs-non-blocking 이 질문의 세 번째 답변이라는 결론을 내렸다. 이 답변의 번역 + 보충 설명을 위한 다른 자료들 + 사족을 섞어서 정리하였다.\n\nsynchronous / asynchronous : 두 모듈 사이의 관계에 대한 표현\nblocking / non-blocking : 모듈 하나의 상태에 대한 표현\n예를 들어,\n\n모듈 X : 나\n모듈 Y : 서점\nX가 Y에게 질문 : C++ primer 책 있나요?\n\n\n1. Blocking\n\nY가 X에게 답하기 전까지, X는 기다린다. X는 Blocking 상태에 빠진 것이다.\n\n2. Non-Blocking\n\nY가 X에게 답하기 전에, X는 다른 일을 할 수 있다.\nX가 2분마다 Y가 일을 끝냈는지 확인할까?(Synchronous라면 이렇게 될 것 같다.) 아니면 Y가 다 됐다고 부르면 확인할까?(Asynchronous라면 이렇게 될 것 같다.) 모른다.(= 상관이 없다.)\n우리가 아는 건 X가 Y가 일을 끝내기 전에 다른 일을 할 수 있다는 것 뿐이다. X는 Non-Blocking이다.\n\n3. Synchronous\n\nY가 X에게 답하기 전에는, X는 다른 일을 진행하지 않는다 - 라고 설명하고 있는데, 이러면 Blocking과 정의가 같다. 좀 다르게 생각해 보자.\nSynchronous에는 중요한 두 가지 키워드가 있다.\n\n작업의 순서를 맞추는 것. 왜 순서를 맞추냐고? 여러 작업이 동시에(Concurrently) Critical section에 진입하는것을 막기 위해서이기도 하고, 특정 순서에 맞게 작업들을 실행해야 할 필요가 있기(표를 사지도 않고 비행기에 탈 수는 없다) 때문이기도 하다. 작업 순서를 맞출 때 Blocking으로 처리하면 편하기 때문에 Blocking의 개념이 섞여서 등장하는 것 뿐이다.\n\n작업 순서의 관점에서 설명하는 글 두 개\n\nhttps://jins-dev.tistory.com/entry/동기Synchronous-작업과-비동기Asynchronous-작업-그리고-블락Blocking-과-넌블락NonBlocking-의-개념 (이 글의 경우 blocking 부분은 보면 더 헷갈리니 위에만 보자.)\nhttps://medium.com/from-the-scratch/wtf-is-synchronous-and-asynchronous-1a75afd039df\n\n\nCaller가 Callee의 완료 상태를 확인하는 것. Callee의 완료 여부가 Caller의 다음 작업에 영향을 미치기 때문으로, 작업의 순서를 맞추는 것의 하위 개념이다.\n\n좋은 예시 : 상사가 와서 어떤 일을 처리하라고 말한다. 그리고 내 등 뒤에서 시체를 노리는 독수리마냥 나를 쳐다보고 있다. “자네가 일을 다 끝낼 때까지 여기서 기다릴 걸세.”\n상태 확인의 관점에서 설명하는 글 : https://homoefficio.github.io/2017/02/19/Blocking-NonBlocking-Synchronous-Asynchronous/\n\n\n이 X,Y 예에서는, Synchronous는 X가 Y에게 책 찾았냐고 물어보고,(caller가 callee의 상태 확인) Y가 책이 있는지 없는지 X에게 알려 준 이후에야, X가 Y에게 “그래서 이 책 얼마죠?” 라고 물어보던가, “그 책 주문 좀 해주세요” 라고 요청할 수 있는 상황인 것이다.(작업 순서) 책이 있는지 확인한 다음에 가격을 물어보던지 주문을 요청하던지 할 수 있으니까. X가 Y가 책 찾는 동안 다른 무언가를 하는 건 상관이 없다. 서점 앞에서 줄넘기를 할 수도 있지 않은가? 책에 관련된 다음 일을 못하는 것 뿐.\n이렇게 봐도 상당히 헷갈리기 때문에, 코드를 보자. 아래의 코드는 Synchronous & Non-Blocking 한 간단한 코드이다.\n\n# thread X\nwhile (true)\n{\n    msg = recv(Y, NON_BLOCKING_FLAG);\n    if (msg is not empty)\n    {\n        break;\n    }\n    # 이 루프 안에서 다른 작업을 할 수 있다.\n    sleep(2000); // 2 sec\n}\n\n# thread Y\n# prepare the book for X\nsend(X, book);\n\nX가 2초마다 Y가 답을 줬는지 아닌지 확인한다.\nY가 결과를 반환하기 위해 준비 중이어도, X의 while 루프는 계속 돌아가고 그 안에서 다른 작업을 진행할 수 있다. 그래서 Non-Blocking이다.\n하지만, while문을 빠져나가서 다른 작업을 할 수는 없다. 그래서 Synchronous다.\n코드의 예시까지 보면, X가 서점을 떠나지 못한다고 해석할 수 있다. Y가 책을 찾아줘서 서점과 관련된 일을 마치기 전에는, 서점을 떠나서 다른 걸 할 수 없다. 서점 앞에서 줄넘기는 가능해도.(while문 안에서 뭔가 다른 작업)\nBlocking이었다면, X는 아무것도 못하고 기다려야 했겠지만.\n\n4. Asychronous\n\nY가 X에게 답하기 전에, X는 다른 곳에 가서 다른 일을 할 수 있다. X는 Y가 부르기 전까지 돌아오지 않는다. 이 때 X와 Y는 Asychronous 하다고 말한다.\n여기서도 Synchronous와 같은 두 가지 키워드로 살펴보자.\n\n작업의 순서가 보장되지 않음 : Asynchronous는 엄밀히 말하면, 작업들이 공통적으로 사용하는 global clock이 없고, 신호나 메세지의 도착 시간이 작업의 신뢰성에 영향을 미치지 않음을 뜻한다. 즉 작업의 순서가 보장되지 않는다.(A,B,C 순서로 실행되었으나 완료도 A,B,C 순서일 것이라 보장할 수 없음)\n\n신호나 메세지의 도착 시간이 작업의 신뢰성에 영향을 미치지 않음, 즉, 각 작업이 서로 연관되지 않아서 분리될 수 있으며, 작업 지연시간이 큰 경우에 잘 활용될 수 있다. (DB 접근, Http 요청, File I/O 등)\n\nCallee가 자신의 완료 상태를 확인하며, callback으로 Caller에게 자신의 완료를 알림\n\n근데 사실 완료 통보를 해도 되고 안해도 된다. 완료 통보가 caller에게 의미가 있느냐 없느냐의 문제이다.(내가 한 질문이다 :D)\n좋은 예시 : 상사가 와서 어떤 일을 처리하라고 말한다. 그리고 다른 일 하러 가버림. 일을 다 끝내면, 나는 상사에게 “나 다함!” 이라고 말한다.\n\n\nY에게 책 있냐고 물어본 후에 X가 카페에 가서 커피를 마시기 시작했지만, 책 찾기보다 커피 마시기가 더 빨리 끝날 수도 있다. 이 둘은 완전히 별개의 작업이며, 작업의 순서가 보장되지 않는다.(Asynchronous & Non-Blocking이라면.) 그리고 X는 Y가 X를 부를 때 서점으로 돌아간다.\n\n각 2개씩의 개념이 있으니, 총 4개의 조합이 나올 것이다.\n\nSynchronous - Blocking\nAsynchronous - Blocking\nSynchronous - Non-Blocking\nAsynchronous - Non-Blocking 이 조합들에 대해서는 여기를 참고하자. 아래 사진이 핵심인데, 출처의 글에서 가져온 사진이다.\n\n 출처 : https://homoefficio.github.io/2017/02/19/Blocking-NonBlocking-Synchronous-Asynchronous/\n\n번외 내용 : 정리하다 보니 핵심 개념을 직관적으로 알기에는 너무 응용에 가깝다고 생각되었던 내용. 지우기는 아까워서 넘겨두었다.\n\nBlocking I/O : application이 kernal에 I/O 해줘~ 라고 system call을 날린다. kernal이 I/O를 수행하는 동안, application은 아무것도 못 하고 기다린다. I/O가 완료되면 call에 대한 return값으로 원하던 데이터를 받는다. \nNon-Blocking I/O : application이 kernal에 I/O 해줘~ 라고 system call을 날린다. 그림의 recvfrom 함수는, 바로 결과를 return 하는데, 아직 I/O가 완료되지 않았으므로 에러인 EWOULDBLOCK을 return한다. 프로세스는 계속 recvfrom을 call 하게 되고, 데이터가 완료되었으면 그 때 데이터가 return된다. 이렇게 계속 요청하는 걸 polling 이라 한다. \n\ncall에 대한 return을 바로 받아서, application이 제어권을 넘겨받고 다른 일을 진행할 수 있는 것이 중요하다. Blocking I/O와는 정 반대로.\n\nNon-Blocking Algorithm : 어떤 쓰레드의 실패(failure)나 멈춤(suspension)이 다른 쓰레드에 영향을 미치지 않게 하는 알고리즘. 몇몇 상황에서는 이런 알고리즘이 전통적인 Blocking 적용(Lock)의 유용한 대안이 된다.\n\n\n\n0.1 마치며\n정확한 용어의 정의를 알아보려고 했다. 하지만 일반적으로는 아래의 대략적인 의미로 사용되는 듯하다. 나는 정확하게 쓰도록 노력해야겠다.\n\nAsynchronous Programming(비동기 프로그래밍): 하나의 요청을 시작한 후, 완료를 기다리지 않고 제어권을 다음 요청으로 넘기는 방식.(Non-Blocking의 의미를 포함)\nSynchronous Programming(동기 프로그래밍): 하나의 요청이 처리되는 동안 다른 요청이 처리되지 못하는 방식. 전 요청이 완료되어야 다음 요청 처리가 가능함.(Blocking의 의미를 포함) 참고\n\n\n\n0.2 References\n\nhttps://en.wikipedia.org/wiki/Synchronization_(computer_science)\nhttps://en.wikipedia.org/wiki/Synchronous_circuit\nhttps://en.wikipedia.org/wiki/Asynchronous_system\nhttps://jins-dev.tistory.com/entry/동기Synchronous-작업과-비동기Asynchronous-작업-그리고-블락Blocking-과-넌블락NonBlocking-의-개념\nhttps://medium.com/from-the-scratch/wtf-is-synchronous-and-asynchronous-1a75afd039df\nhttps://homoefficio.github.io/2017/02/19/Blocking-NonBlocking-Synchronous-Asynchronous/\nhttps://ozt88.tistory.com/20\nhttp://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/ch06lev1sec2.html\nhttps://en.wikipedia.org/wiki/Blocking_(computing)\nhttps://developer.ibm.com/articles/l-async/\n\nhttps://airflow-dev.woowa.in/limyj0708/"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_01_Dataframe 생성/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_01_Dataframe 생성/index.html",
    "title": "Pandas_01_Dataframe 생성",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display_html, display\n\n\n1 Dictionary에서 Dataframe 생성\nclassmethod DataFrame.from_dict(data, orient='columns', dtype=None, columns=None)\n\ndata : {field : array-like} or {field : dict}\norient : {‘columns’, ‘index’, ‘tight’}, default ‘columns’\n\n데이터의 방향. dict의 key가 컬럼이어야 하는 경우, columns를 넘긴다.\nkey가 row여야 한다면, index를 넘긴다.\ntight라면, key가 [‘index’, ‘columns’, ‘data’, ‘index_names’, ‘column_names’]인 dict라고 가정하고 처리한다.\n\ndtype : dtype, default None\n\n데이터 프레임 구성 후, 강제로 적용할 변수 타입.\n\ncolumns : list, default None\n\norient에 index를 넘겼을 때 사용할 컬럼 라벨.\norient가 index가 아니면, ValueError가 반환된다.\n\n\n\ndata = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\npd.DataFrame.from_dict(data)\n# key가 컬럼으로 변환되었따. value로 들어간 리스트가 컬럼의 row 하나하나가 된다.\n\n\n\n\n\n\n\n\ncol_1\ncol_2\n\n\n\n\n0\n3\na\n\n\n1\n2\nb\n\n\n2\n1\nc\n\n\n3\n0\nd\n\n\n\n\n\n\n\n\ndict_list = [\n    { \"id\" : 1001001, \"address\" : \"AABCC\"}\n    ,{ \"id\" : 2101001, \"address\" : \"BBBDD\"}\n    ,{ \"id\" : 3201001, \"address\" : \"백두산\"}\n    ,{ \"id\" : 4301001, \"address\" : \"한라산\"}\n    ,{ \"id\" : 5401001, \"address\" : \"몰디브\"}\n] # 같은 key들을 가진 딕셔너리들이 담긴 리스트\npd.DataFrame.from_dict(dict_list) # 이렇게 넣어도, key들이 컬럼이 되어 데이터프레임이 만들어진다.\n# 실무적으로는 이 형태를 더 많이 쓰게 된다.\n\n\n\n\n\n\n\n\nid\naddress\n\n\n\n\n0\n1001001\nAABCC\n\n\n1\n2101001\nBBBDD\n\n\n2\n3201001\n백두산\n\n\n3\n4301001\n한라산\n\n\n4\n5401001\n몰디브\n\n\n\n\n\n\n\n\n\n2 from Nested Dictionary\n\nuser_dict = {12: {'Category 1': {'att_1': 1, 'att_2': 'whatever'},\n                  'Category 2': {'att_1': 23, 'att_2': 'another'}},\n             15: {'Category 1': {'att_1': 10, 'att_2': 'foo'},\n                  'Category 2': {'att_1': 30, 'att_2': 'bar'}}}\n\n\ndictionary comprehension으로 (인덱스 1, 인덱스 2) : (컬럼명1 : 값1, 컬럼명2 : 값2) 구조의 dictionary를 만든다.\npandas의 multiindex는 tuple로 구성되어있어서, 이렇게 변환하고 dataframe을 만들면, multiindex를 가진 dataframe이 만들어진다.\norient = index로 dataframa을 생성할 수 있다.\n\n\n{(i,j): user_dict[i][j] for i in user_dict.keys() for j in user_dict[i].keys()}\n\n{(12, 'Category 1'): {'att_1': 1, 'att_2': 'whatever'},\n (12, 'Category 2'): {'att_1': 23, 'att_2': 'another'},\n (15, 'Category 1'): {'att_1': 10, 'att_2': 'foo'},\n (15, 'Category 2'): {'att_1': 30, 'att_2': 'bar'}}\n\n\n\npd.DataFrame.from_dict({(i,j): user_dict[i][j] for i in user_dict.keys() for j in user_dict[i].keys()}, orient='index')\n\n\n\n\n\n\n\n\n\natt_1\natt_2\n\n\n\n\n12\nCategory 1\n1\nwhatever\n\n\nCategory 2\n23\nanother\n\n\n15\nCategory 1\n10\nfoo\n\n\nCategory 2\n30\nbar\n\n\n\n\n\n\n\n\n\n3 Column만 존재하는 빈 Dataframe을 만들고, 내용 채워 넣기\n\ndf = pd.DataFrame(columns=['A','B','BB','C','D'])\n# 컬럼들이 될 리스트를 columns parameter에 argument로 넘김\ndf\n\n\n\n\n\n\n\n\nA\nB\nBB\nC\nD\n\n\n\n\n\n\n\n\n\n\ndf['A'] = [1,3,1]\ndf\n\n\n\n\n\n\n\n\nA\nB\nBB\nC\nD\n\n\n\n\n0\n1\nNaN\nNaN\nNaN\nNaN\n\n\n1\n3\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\ndf['B'] = [4,4,6]\ndf\n\n\n\n\n\n\n\n\nA\nB\nBB\nC\nD\n\n\n\n\n0\n1\n4\nNaN\nNaN\nNaN\n\n\n1\n3\n4\nNaN\nNaN\nNaN\n\n\n2\n1\n6\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\ndf.loc[((df['A'] == 1) & (df['B'] == 4)), 'C'] = 444\ndf\n# 컬럼 값 조건을 걸고 값을 변경\n\n\n\n\n\n\n\n\nA\nB\nBB\nC\nD\n\n\n\n\n0\n1\n4\nNaN\n444\nNaN\n\n\n1\n3\n4\nNaN\nNaN\nNaN\n\n\n2\n1\n6\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\ndf.loc[(df['B'] == 4), 'C'] = 0\ndf\n# 컬럼 값 조건을 걸고 값을 변경 2\n\n\n\n\n\n\n\n\nA\nB\nBB\nC\nD\n\n\n\n\n0\n1\n4\nNaN\n0\nNaN\n\n\n1\n3\n4\nNaN\n0\nNaN\n\n\n2\n1\n6\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nsample_list = [1,2,3,4,5]\n# 해당 데이터프레임 가장 아래에 리스트를 row로 넣음\ndf.loc[len(df)] = sample_list\n# 이 방식은 좀 느린 편이며, 데이터프레임에 행을 추가해야 한다면\n# 자료를 dictionary로 관리하다가 모든 데이터 추가가 다 끝나고 데이터프레임으로 변환하는 것이 빠름\ndf\n\n\n\n\n\n\n\n\nA\nB\nBB\nC\nD\n\n\n\n\n0\n1\n4\nNaN\n0\nNaN\n\n\n1\n3\n4\nNaN\n0\nNaN\n\n\n2\n1\n6\nNaN\nNaN\nNaN\n\n\n3\n1\n2\n3\n4\n5\n\n\n\n\n\n\n\n\ndf.to_parquet('df.parquet', engine='pyarrow', index=None)"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html",
    "href": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html",
    "title": "FastAPI_02 Routing, URL prefix 지정",
    "section": "",
    "text": "fastAPI/\n  ├── docker-compose.yaml\n  ├── dockerfile\n  ├── main.py\n  ├── pyproject.toml\n  ├── poetry.lock\n  └── router/\n      ├── hello_world.py\n      └── greetings.py\n\nrouter 폴더 내에 각 모듈들을 생성한다.\n\n\n\nfrom fastapi import FastAPI\nfrom router import hello_world, greetings\n\napp = FastAPI(\n    title=\"FastAPI sample\"\n  , version=\"1.0.0\"\n  #, docs_url=\"/api/docs\"             # API root URL을 0.0.0.0/api 로 사용하고 싶다면\n  #, openapi_url=\"/api/openapi.json\"  # OpenAPI schema 경로도 지정해주어야 함\n)\n\napp.include_router(\n    hello_world.router\n  # , prefix=\"/api\"  # API root URL을 0.0.0.0/api 로 사용하고 싶다면\n  , tags=[\"hello_world\"])\napp.include_router(greetings.router, tags=[\"greetings\"])\n\n# @app.get(\"/api\") # API root URL을 0.0.0.0/api 로 사용하고 싶다면\n@app.get(\"/\")\nasync def read_root():\n    return {\"Readme\": \"Welcome to FastAPI sample!\"}\n\n\n\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.get(\"/hello_world\")  # http://0.0.0.0:8000/hello_world URL로 접근\nasync def hello_world():\n    return {\"message\": \"Hello World, with Routing!\"}\n\n\n\nfrom fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.get(\"/greetings\")  # http://0.0.0.0:8000/greetings URL로 접근\nasync def greetings():\n    return {\"message\": \"Greetings, Traveller!\"}"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#main.py",
    "href": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#main.py",
    "title": "FastAPI_02 Routing, URL prefix 지정",
    "section": "",
    "text": "from fastapi import FastAPI\nfrom router import hello_world, greetings\n\napp = FastAPI(\n    title=\"FastAPI sample\"\n  , version=\"1.0.0\"\n  #, docs_url=\"/api/docs\"             # API root URL을 0.0.0.0/api 로 사용하고 싶다면\n  #, openapi_url=\"/api/openapi.json\"  # OpenAPI schema 경로도 지정해주어야 함\n)\n\napp.include_router(\n    hello_world.router\n  # , prefix=\"/api\"  # API root URL을 0.0.0.0/api 로 사용하고 싶다면\n  , tags=[\"hello_world\"])\napp.include_router(greetings.router, tags=[\"greetings\"])\n\n# @app.get(\"/api\") # API root URL을 0.0.0.0/api 로 사용하고 싶다면\n@app.get(\"/\")\nasync def read_root():\n    return {\"Readme\": \"Welcome to FastAPI sample!\"}"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#hello_world.py",
    "href": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#hello_world.py",
    "title": "FastAPI_02 Routing, URL prefix 지정",
    "section": "",
    "text": "from fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.get(\"/hello_world\")  # http://0.0.0.0:8000/hello_world URL로 접근\nasync def hello_world():\n    return {\"message\": \"Hello World, with Routing!\"}"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#greetings.py",
    "href": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#greetings.py",
    "title": "FastAPI_02 Routing, URL prefix 지정",
    "section": "",
    "text": "from fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.get(\"/greetings\")  # http://0.0.0.0:8000/greetings URL로 접근\nasync def greetings():\n    return {\"message\": \"Greetings, Traveller!\"}"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#prefix-api를-세팅한-경우",
    "href": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#prefix-api를-세팅한-경우",
    "title": "FastAPI_02 Routing, URL prefix 지정",
    "section": "2.1 prefix “/api”를 세팅한 경우",
    "text": "2.1 prefix “/api”를 세팅한 경우\n\nhttp://0.0.0.0:8000/api/hello_world\nhttp://0.0.0.0:8000/api/greetings"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#prefix-api를-세팅하지-않은-경우",
    "href": "posts/2025-02-02__FastAPI_02_Routing, URL prefix 설정/index.html#prefix-api를-세팅하지-않은-경우",
    "title": "FastAPI_02 Routing, URL prefix 지정",
    "section": "2.2 prefix “/api”를 세팅하지 않은 경우",
    "text": "2.2 prefix “/api”를 세팅하지 않은 경우\n\nhttp://0.0.0.0:8000/hello_world\nhttp://0.0.0.0:8000/greetings"
  },
  {
    "objectID": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html",
    "href": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html",
    "title": "Bigquery_Window 함수의 window_frame_clause 정리",
    "section": "",
    "text": "정리해두지 않으면 항상 헷갈린다."
  },
  {
    "objectID": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html#rows",
    "href": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html#rows",
    "title": "Bigquery_Window 함수의 window_frame_clause 정리",
    "section": "1 1. ROWS",
    "text": "1 1. ROWS\n\n현재 행의 OFFSET 기반으로 윈도우 프레임을 정의함.\n\nOFFSET 기반이므로, 현재 행은 index 0. 범위 2을 잡으면, 0~2이므로, 현재 행을 포함하여 행 3개를 프레임으로 잡게 됨\n\n\n\n1.1 1-1. UNBOUNDED PRECEDING\n\nPARTITION BY의 시작 부분을 참조\n즉, ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW 라면, 윈도우 프레임의 범위는 PARTITION BY의 시작부터 현재 행까지임\n예시 쿼리\n\nSELECT\n    employee_number\n  , last_name\n  , first_name\n  , salary\n  , dept_id\n  , SUM(salary) OVER(PARTITION BY dept_id\n                     ORDER BY salary\n                     ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS sum_salary\nFROM `bigquery-personal.test_ground.test_emp`\n\n결과\n\nPARTITON BY dept_id의 시작부터 현재 행까지 누적으로 SUM(salary)가 되고 있음을 알 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n행\nemployee_number\nlast_name\nfirst_name\nsalary\ndept_id\nsum_salary\n\n\n\n\n1\n1004\nHorvath\nJack\n42000\n501\n42000\n\n\n2\n1003\nEverest\nBrad\n71000\n501\n113000\n\n\n3\n1005\nKate\nSmith\n72000\n501\n185000\n\n\n4\n1006\nblank\nPencil\n80000\n501\n265000\n\n\n5\n1007\nmobile\nphone\n100000\n501\n365000\n\n\n6\n1002\nAnderson\nJane\n57500\n500\n57500\n\n\n7\n1008\nLim\nSmith\n58000\n500\n115500\n\n\n8\n1011\nJohnson\nSally\n58000\n500\n173500\n\n\n9\n1001\nSmith\nJohn\n62000\n500\n235500\n\n\n10\n1010\nNakamura\nShin\n62000\n500\n297500\n\n\n11\n1009\nWaterman\nPencil\n80000\n500\n377500\n\n\n12\n1012\nJohnson\nEmily\n80000\n500\n457500\n\n\n\n\n\n1.2 1-2. UNBOUNDED FOLLOWING\n\nPARTITION BY의 끝 부분을 참조\n즉, ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING 이라면, 윈도우 프레임의 범위는 현재 행부터 PARITION BY의 끝까지임\n예시 쿼리\n\nSELECT\n    employee_number\n  , last_name\n  , first_name\n  , salary\n  , dept_id\n  , SUM(salary) OVER(PARTITION BY dept_id\n                     ORDER BY salary\n                     ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS sum_salary\nFROM `bigquery-personal.test_ground.test_emp`\n\n결과\n\n현재 행부터 PARTITON BY dept_id의 끝까지 누적으로 SUM(salary)가 되고 있음을 알 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n행\nemployee_number\nlast_name\nfirst_name\nsalary\ndept_id\nsum_salary\n\n\n\n\n1\n1002\nAnderson\nJane\n57500\n500\n457500\n\n\n2\n1008\nLim\nSmith\n58000\n500\n400000\n\n\n3\n1011\nJohnson\nSally\n58000\n500\n342000\n\n\n4\n1001\nSmith\nJohn\n62000\n500\n284000\n\n\n5\n1010\nNakamura\nShin\n62000\n500\n222000\n\n\n6\n1009\nWaterman\nPencil\n80000\n500\n160000\n\n\n7\n1012\nJohnson\nEmily\n80000\n500\n80000\n\n\n8\n1004\nHorvath\nJack\n42000\n501\n365000\n\n\n9\n1003\nEverest\nBrad\n71000\n501\n323000\n\n\n10\n1005\nKate\nSmith\n72000\n501\n252000\n\n\n11\n1006\nblank\nPencil\n80000\n501\n180000\n\n\n12\n1007\nmobile\nphone\n100000\n501\n100000"
  },
  {
    "objectID": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html#numeric-preceding-numeric-following",
    "href": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html#numeric-preceding-numeric-following",
    "title": "Bigquery_Window 함수의 window_frame_clause 정리",
    "section": "2 1-3. NUMERIC PRECEDING, NUMERIC FOLLOWING",
    "text": "2 1-3. NUMERIC PRECEDING, NUMERIC FOLLOWING\n\nNUMERIC PRECEDING : 현재 행부터 N만큼 위에 있는 행을 참조\nNUMERIC FOLLOWING : 현재 행부터 N만큼 아래에 있는 행을 참조\n예시 쿼리\n\nSELECT\n    employee_number\n  , last_name\n  , first_name\n  , salary\n  , dept_id\n  , SUM(salary) OVER(PARTITION BY dept_id\n                     ORDER BY salary\n                     ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS sum_salary\nFROM `bigquery-personal.test_ground.test_emp`\n\n결과\n\n윈도우 프레임의 범위 : 현재 행보다 1행 위에 있는 행 ~ 현재 행 ~ 현재 행보다 1행 아래에 있는 행\n1행이면 1,2행 / 2행이면 1,2,3행의 값이 더해지게 된다.\n적절히 숫자를 바꾸면 된다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n행\nemployee_number\nlast_name\nfirst_name\nsalary\ndept_id\nsum_salary\n\n\n\n\n1\n1004\nHorvath\nJack\n42000\n501\n42000\n\n\n2\n1003\nEverest\nBrad\n71000\n501\n113000\n\n\n3\n1005\nKate\nSmith\n72000\n501\n185000\n\n\n4\n1006\nblank\nPencil\n80000\n501\n223000\n\n\n5\n1007\nmobile\nphone\n100000\n501\n252000\n\n\n6\n1002\nAnderson\nJane\n57500\n500\n57500\n\n\n7\n1011\nJohnson\nSally\n58000\n500\n115500\n\n\n8\n1008\nLim\nSmith\n58000\n500\n173500\n\n\n9\n1010\nNakamura\nShin\n62000\n500\n178000\n\n\n10\n1001\nSmith\nJohn\n62000\n500\n182000\n\n\n11\n1009\nWaterman\nPencil\n80000\n500\n204000\n\n\n12\n1012\nJohnson\nEmily\n80000\n500\n222000"
  },
  {
    "objectID": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html#range",
    "href": "posts/2023-01-12__Window 함수의 window_frame_clause 정리/index.html#range",
    "title": "Bigquery_Window 함수의 window_frame_clause 정리",
    "section": "3 2. RANGE",
    "text": "3 2. RANGE\n\nORDER BY {sum_value}로 정렬했을 때, 같은 {sum_value}를 가지는 행들을 논리적으로 같은 행 범위라고 정의한다.\n\n\n3.1 2-1. UNBOUNDED PRECEDING\n\n예시 코드\n\nSELECT\n    employee_number\n  , last_name\n  , first_name\n  , salary\n  , dept_id\n  , SUM(salary) OVER(PARTITION BY dept_id\n                  ORDER BY salary\n                  RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS sum_salary\nFROM `bigquery-personal.test_ground.test_emp`\n\n결과\n\nORDER BY salary 이므로, 같은 salary인 행들은 전체가 한 번에 더해진다.\nsalary가 80000인 행이 행 6,7인데, 160000이 한 번에 더해지는 것을 볼 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n행\nemployee_number\nlast_name\nfirst_name\nsalary\ndept_id\nsum_salary\n\n\n\n\n1\n1002\nAnderson\nJane\n57500\n500\n57500\n\n\n2\n1008\nLim\nSmith\n58000\n500\n173500\n\n\n3\n1011\nJohnson\nSally\n58000\n500\n173500\n\n\n4\n1001\nSmith\nJohn\n62000\n500\n297500\n\n\n5\n1010\nNakamura\nShin\n62000\n500\n297500\n\n\n6\n1009\nWaterman\nPencil\n80000\n500\n457500\n\n\n7\n1012\nJohnson\nEmily\n80000\n500\n457500\n\n\n8\n1004\nHorvath\nJack\n42000\n501\n42000\n\n\n9\n1003\nEverest\nBrad\n71000\n501\n113000\n\n\n10\n1005\nKate\nSmith\n72000\n501\n185000\n\n\n11\n1006\nblank\nPencil\n80000\n501\n265000\n\n\n12\n1007\nmobile\nphone\n100000\n501\n36500"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html",
    "title": "Pandas_03_값 삭제, 대체",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display_html, display\ndef display_multiple_dfs(dfs:list, styles, margin=10):\n    display_target = ''\n    for each_df in dfs:\n        each_df_html = each_df[0].style.set_caption(f'&lt;b&gt;{each_df[1]}&lt;/b&gt;').set_table_styles(styles).set_table_attributes(f\"style='display:inline;margin:{margin}px'\")._repr_html_()\n        display_target += each_df_html\n    display_html(display_target, raw = True)\nstyles = [\n    {\"selector\" : \"caption\", \"props\" : \"text-align:center; font-size:16px\"}\n]\ndf = pd.read_parquet('df.parquet', engine='pyarrow')"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html#isna-nan인지-각-값에-대해-확인",
    "href": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html#isna-nan인지-각-값에-대해-확인",
    "title": "Pandas_03_값 삭제, 대체",
    "section": "2.1 isna : NaN인지 각 값에 대해 확인",
    "text": "2.1 isna : NaN인지 각 값에 대해 확인\n\nNaN인지 각 값에 대해 확인하여 boolean으로 표현\nisnull() 도 완전히 같은 기능을 한다.\n왜 같은 기능을 하는 함수가 두 개나 있는지는 아래 링크를 참조\n\nhttps://datascience.stackexchange.com/questions/37878/difference-between-isna-and-isnull-in-pandas\nThis is because pandas’ DataFrames are based on R’s DataFrames. In R na and null are two separate things. Read this post for more information. However, in python, pandas is built on top of numpy, which has neither na nor null values. Instead numpy has NaN values (which stands for “Not a Number”). Consequently, pandas also uses NaN values.\n\n완전히 반대의 기능을 하는 함수로 notnull()이 있다.\n\npandas.notnull(obj)\n\n\n\ndf.isna()\n# 특정 컬럼, 행에 대해서도 사용 가능\n\n\n\n\n\n\n\n\n가\n나\n다\n라\n마\n바\n사\n아\n\n\n\n\n1\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nFalse\nTrue\n\n\n2\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nFalse\nTrue\n\n\n3\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\nFalse\nTrue\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n5\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html#dropna-na-드랍",
    "href": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html#dropna-na-드랍",
    "title": "Pandas_03_값 삭제, 대체",
    "section": "2.2 dropna : NA 드랍",
    "text": "2.2 dropna : NA 드랍\nDataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n\naxis\n\n0 혹은 ‘index’ : missing value가 있는 행을 드랍\n1 혹은 ‘columns’ : missing value가 있는 열을 드랍\n\nhow\n\nany : missing value가 하나라도 있으면 드랍\nall : 전체 값이 다 missing value여야 드랍\n\nthresh : 문턱값. 정수를 입력 시, 정상값이 해당 정수 갯수만큼은 있어야 제거 안 함\nsubset : list-like 오브젝트를 넣으면, 해당 index나 컬럼에서만 missing value 체크\ninplace : 원본 변경 할 건가요?\n\n\ndf\n\n\n\n\n\n\n\n\n가\n나\n다\n라\n마\n바\n사\n아\n\n\n\n\n1\n1\n4\nNaN\n0\nNaN\n2.000000\n2.000000\nNaN\n\n\n2\n100\n4\nNaN\n0\nNaN\n20.000000\n2.000000\nNaN\n\n\n3\n1\n6\nNaN\nNaN\nNaN\n2.449490\n2.449490\nNaN\n\n\n4\n1\n2\n3\n4\n5\n1.414214\n1.414214\n2.44949\n\n\n5\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n6\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n7\n22\n22\n22\n22\n22\n22.000000\n4.690416\n22.00000\n\n\n\n\n\n\n\n\ndf.dropna() # 기본적으로 행 드랍\n\n\n\n\n\n\n\n\n가\n나\n다\n라\n마\n바\n사\n아\n\n\n\n\n4\n1\n2\n3\n4\n5\n1.414214\n1.414214\n2.44949\n\n\n5\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n6\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n7\n22\n22\n22\n22\n22\n22.000000\n4.690416\n22.00000\n\n\n\n\n\n\n\n\ndf.dropna(axis=1) # 열 드랍\n\n\n\n\n\n\n\n\n가\n나\n바\n사\n\n\n\n\n1\n1\n4\n2.000000\n2.000000\n\n\n2\n100\n4\n20.000000\n2.000000\n\n\n3\n1\n6\n2.449490\n2.449490\n\n\n4\n1\n2\n1.414214\n1.414214\n\n\n5\n1\n1\n1.000000\n1.000000\n\n\n6\n1\n1\n1.000000\n1.000000\n\n\n7\n22\n22\n22.000000\n4.690416\n\n\n\n\n\n\n\n\ndf.dropna(thresh=5) # index 3인 행은 정상값이 4개였음\n\n\n\n\n\n\n\n\n가\n나\n다\n라\n마\n바\n사\n아\n\n\n\n\n1\n1\n4\nNaN\n0\nNaN\n2.000000\n2.000000\nNaN\n\n\n2\n100\n4\nNaN\n0\nNaN\n20.000000\n2.000000\nNaN\n\n\n4\n1\n2\n3\n4\n5\n1.414214\n1.414214\n2.44949\n\n\n5\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n6\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n7\n22\n22\n22\n22\n22\n22.000000\n4.690416\n22.00000\n\n\n\n\n\n\n\n\ndf.dropna(axis=0, subset=['라']) # '라'열만 검사해서 NaN이 있는 행을 제거함\n\n\n\n\n\n\n\n\n가\n나\n다\n라\n마\n바\n사\n아\n\n\n\n\n1\n1\n4\nNaN\n0\nNaN\n2.000000\n2.000000\nNaN\n\n\n2\n100\n4\nNaN\n0\nNaN\n20.000000\n2.000000\nNaN\n\n\n4\n1\n2\n3\n4\n5\n1.414214\n1.414214\n2.44949\n\n\n5\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n6\n1\n1\n1\n1\n1\n1.000000\n1.000000\n1.00000\n\n\n7\n22\n22\n22\n22\n22\n22.000000\n4.690416\n22.00000"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html#fillna-nan-데이터-대체하기",
    "href": "posts/2021-11-05__pandas_cheatsheet_03_값 삭제, 대체/index.html#fillna-nan-데이터-대체하기",
    "title": "Pandas_03_값 삭제, 대체",
    "section": "2.3 fillna : NaN 데이터 대체하기",
    "text": "2.3 fillna : NaN 데이터 대체하기\nDataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n\nvalue : NaN을 무엇으로 채울 것인가?\n\nscalar : 0, 1 따위의 값을 넣음\ndict : {“A”: 0, “B”: 1, “C”: 2, “D”: 3}\n\n컬럼 A의 NaN은 0으로, 컬럼 B의 NaN은 1로, 컬럼 C의 NaN은 2로, 컬럼 D의 NaN은 3으로 대체\n\ndataframe : 대체 대상 dataframe와 같은 크기의 dataframe을 준비한 후, value에 dataframe을 넣으면 NaN 값만 넣은 dataframe의 값으로 대체된다. 컬럼명이나 인덱스는 원본 dataframe의 것이 유지된다.\n\nmethod : 어떤 방법으로 채울까? (value와 같이 사용할 수 없음)\n\nbackfill, bfill : NaN의 다음 값으로 NaN 채우기.\nffill, pad : NaN의 직전 값으로 NaN 채우기.\n\naxis\n\n0 혹은 ‘index’\n1 혹은 ‘columns’\n\ninplace : 원본 변경 할 건가요?\nlimit : 위에서부터 NaN 몇 개만 바꿀래? 기본값 None이면 모든 NaN을 바꾸는 것.\n\n\ndf = pd.DataFrame([[np.nan, 2, np.nan, 0],\n                   [3, 4, np.nan, 1],\n                   [np.nan, np.nan, np.nan, 5],\n                   [np.nan, 3, np.nan, 4]],\n                  columns=list(\"ABCD\"))\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\nNaN\n2.0\nNaN\n0\n\n\n1\n3.0\n4.0\nNaN\n1\n\n\n2\nNaN\nNaN\nNaN\n5\n\n\n3\nNaN\n3.0\nNaN\n4\n\n\n\n\n\n\n\n\ndf.fillna(value=0) # 0으로 NaN 채우기\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n0.0\n2.0\n0.0\n0\n\n\n1\n3.0\n4.0\n0.0\n1\n\n\n2\n0.0\n0.0\n0.0\n5\n\n\n3\n0.0\n3.0\n0.0\n4\n\n\n\n\n\n\n\n\ndf.fillna(method='ffill') # NaN의 직전 값으로 NaN 채우기. 'pad'를 써도 마찬가지\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\nNaN\n2.0\nNaN\n0\n\n\n1\n3.0\n4.0\nNaN\n1\n\n\n2\n3.0\n4.0\nNaN\n5\n\n\n3\n3.0\n3.0\nNaN\n4\n\n\n\n\n\n\n\n\ndf.fillna(method='bfill') # NaN의 다음 값으로 NaN 채우기. 'backfill'을 써도 마찬가지\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n3.0\n2.0\nNaN\n0\n\n\n1\n3.0\n4.0\nNaN\n1\n\n\n2\nNaN\n3.0\nNaN\n5\n\n\n3\nNaN\n3.0\nNaN\n4\n\n\n\n\n\n\n\n\nvalues = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\ndf.fillna(value=values) # values에 dictionary를 넣어서 컬럼마다 NaN을 다른 값으로 대체\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n0.0\n2.0\n2.0\n0\n\n\n1\n3.0\n4.0\n2.0\n1\n\n\n2\n0.0\n1.0\n2.0\n5\n\n\n3\n0.0\n3.0\n2.0\n4\n\n\n\n\n\n\n\n\ndf.fillna(value=values, limit=1) # limit=1이어서, 최초의 NaN 하나만 대체\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n0.0\n2.0\n2.0\n0\n\n\n1\n3.0\n4.0\nNaN\n1\n\n\n2\nNaN\n1.0\nNaN\n5\n\n\n3\nNaN\n3.0\nNaN\n4\n\n\n\n\n\n\n\n\ndf2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\ndf2 # 4 by 4 영행렬을 만들어 보자\n\n\n\n\n\n\n\n\nA\nB\nC\nE\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\ndf.fillna(df2) #원본 df의 컬럼이 유지됨\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n0.0\n2.0\n0.0\n0\n\n\n1\n3.0\n4.0\n0.0\n1\n\n\n2\n0.0\n0.0\n0.0\n5\n\n\n3\n0.0\n3.0\n0.0\n4\n\n\n\n\n\n\n\n\ndf.loc[:,'A'].fillna(df.loc[:,'A'].mean()) # A열의 NaN 값을 A열의 평균으로 채움\n\n0    3.0\n1    3.0\n2    3.0\n3    3.0\nName: A, dtype: float64"
  },
  {
    "objectID": "posts/2021-09-07__Crontab으로 Python 스크립트 주기적으로 실행하기/index.html",
    "href": "posts/2021-09-07__Crontab으로 Python 스크립트 주기적으로 실행하기/index.html",
    "title": "Crontab으로 Python 스크립트 주기적으로 실행하기",
    "section": "",
    "text": "주기적으로 외부 API를 통해 데이터를 수집하여, Bigquery에 적재하고 싶다. CentOS 서버에서, 주기적으로 Python 스크립트를 실행하여 해결해 보자.\n\nsudo crontab -e : crontab 설정 오픈. 자동으로 root가 작업하는 것으로 인지됨\n설정\n\n경로는 절대경로를 입력해야 제대로 작동\n\nPython 경로도 절대경로로 입력해 줘야 함\n\n시간설정은 아래 링크에서 직관적으로 확인 가능\n\nCrontab.guru - The cron schedule expression editor\n\n\n\n30 8 * * * /usr/local/bin/python3.9 /home/limyj0708/cw_daily_bigquery/cw_daily.py\n\ncron 재시작\n\n재시작해야 적용됨\nservice cron restart\nCentOS일 경우, service crond restart"
  },
  {
    "objectID": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html",
    "href": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html",
    "title": "Ubuntu에서 메인 Python 버전 새로 설치하기 (with uv)",
    "section": "",
    "text": "기본으로 설치되어 있는 버전은 그대로 두고, 새로운 버전을 설치, 해당 버전을 기반으로 개발을 진행하려고 함\n\n\n\n# PPA 추가 및 패키지 목록 업데이트\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\n\n# Python 3.13 및 관련 개발 도구 설치\nsudo apt install python3.13 python3.13-venv python3.13-dev\n\n\n\n# macOS / Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n\n\nuv venv -p 3.13 main\n\n해당 가상환경 활성화\n\nsource main/bin/activate"
  },
  {
    "objectID": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html#deadsnakes-ppa-추가-및-원하는-버전의-python-설치",
    "href": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html#deadsnakes-ppa-추가-및-원하는-버전의-python-설치",
    "title": "Ubuntu에서 메인 Python 버전 새로 설치하기 (with uv)",
    "section": "",
    "text": "# PPA 추가 및 패키지 목록 업데이트\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\n\n# Python 3.13 및 관련 개발 도구 설치\nsudo apt install python3.13 python3.13-venv python3.13-dev"
  },
  {
    "objectID": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html#uv-설치",
    "href": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html#uv-설치",
    "title": "Ubuntu에서 메인 Python 버전 새로 설치하기 (with uv)",
    "section": "",
    "text": "# macOS / Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh"
  },
  {
    "objectID": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html#uv를-사용하여-원하는-python-버전-기반-메인-가상환경-생성",
    "href": "posts/2025-08-07__Ubuntu에서 실사용 Python 버전 교체/index.html#uv를-사용하여-원하는-python-버전-기반-메인-가상환경-생성",
    "title": "Ubuntu에서 메인 Python 버전 새로 설치하기 (with uv)",
    "section": "",
    "text": "uv venv -p 3.13 main\n\n해당 가상환경 활성화\n\nsource main/bin/activate"
  },
  {
    "objectID": "posts/2025-10-28__Airflow_DockerOperator를 사용해 보자/index.html",
    "href": "posts/2025-10-28__Airflow_DockerOperator를 사용해 보자/index.html",
    "title": "Airflow_DockerOperator를 사용해 보자",
    "section": "",
    "text": "Airflow : Docker Container에서 실행 중\n실행해야 할 대상 : 다른 Docker Image로 관리 중\n\n\n이런 경우, 임시 Docker Container를 생성한 후 대상을 실행함\n그리고 임시 Docker Container를 제거"
  },
  {
    "objectID": "posts/2025-10-28__Airflow_DockerOperator를 사용해 보자/index.html#docker-socket",
    "href": "posts/2025-10-28__Airflow_DockerOperator를 사용해 보자/index.html#docker-socket",
    "title": "Airflow_DockerOperator를 사용해 보자",
    "section": "Docker Socket",
    "text": "Docker Socket\n\ndocker_url='unix://var/run/docker.sock'\n\nunix:// 프로토콜은 같은 머신 내에서 통신할 때 사용\n/var/run/docker.sock는 Unix 도메인 소켓 파일로, Docker 클라이언트가 Docker 데몬(dockerd)과 통신하기 위한 통로\n\ndocker.sock 파일의 권한을 확인해 보면\n\nls -l /var/run/docker.sock\nsrw-rw---- 1 root docker 0 Oct  9 14:31 /var/run/docker.sock"
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html",
    "href": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html",
    "title": "Bigquery_사분위수 구하기",
    "section": "",
    "text": "사분위수를 Bigquery에서 미리 구해서 시각화하고 싶을 떄가 있다.\n두 가지 방법이 있는데, 아래와 같다."
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html#approx_quantiles",
    "href": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html#approx_quantiles",
    "title": "Bigquery_사분위수 구하기",
    "section": "1 APPROX_QUANTILES",
    "text": "1 APPROX_QUANTILES\n\n근사치 집계 함수\n\n근사치 집계 함수는 메모리 사용량과 시간 면에서 확장 가능하지만 정확한 결과가 아닌 근사치 결과를 산출합니다. 이러한 함수는 일반적으로 COUNT(DISTINCT …)와 같은 정확한 집계 함수보다 적은 메모리를 사용하지만 통계상의 불확실성 또한 존재합니다. 따라서 근사치 집계는 선형 메모리 사용량이 비효율적이거나 데이터가 이미 근사치인 대용량 데이터 스트림에 적합합니다.\n\n예를 들어, skill_score라는 수치 컬럼의 사분위수를 구한다고 해 보자.\n\nmin(skill_enhance_score_sum) as score_min\n,APPROX_QUANTILES(skill_enhance_score_sum, 100)[OFFSET(25)] AS q_1 -- 100조각 내서 25번째, Q1\n,APPROX_QUANTILES(skill_enhance_score_sum, 100)[OFFSET(50)] AS median\n,APPROX_QUANTILES(skill_enhance_score_sum, 100)[OFFSET(75)] AS q_3\n,max(skill_enhance_score_sum) as score_max"
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html#percentile_cont",
    "href": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html#percentile_cont",
    "title": "Bigquery_사분위수 구하기",
    "section": "2 PERCENTILE_CONT",
    "text": "2 PERCENTILE_CONT\n\n탐색 함수\nvalue_expression의 지정된 백분위수 값을 선형 보간으로 계산합니다.\n예를 들어, skill_score라는 수치 컬럼의 사분위수를 구한다고 해 보자.\n\nPERCENTILE_CONT(skill_enhance_score_sum, 0) OVER() as score_min\n,PERCENTILE_CONT(skill_enhance_score_sum, 0.25) OVER() AS q_1\n,PERCENTILE_CONT(skill_enhance_score_sum, 0.5) OVER() AS median\n,PERCENTILE_CONT(skill_enhance_score_sum, 0.75) OVER() AS q_3\n,PERCENTILE_CONT(skill_enhance_score_sum, 1) OVER() as score_max\n\nOVER 절은 윈도우 함수 사용법을 참고하자."
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html#데이터에-null이-있는-경우에는",
    "href": "posts/2022-10-29__Bigquery_사분위수 구하기/index.html#데이터에-null이-있는-경우에는",
    "title": "Bigquery_사분위수 구하기",
    "section": "3 데이터에 NULL이 있는 경우에는?",
    "text": "3 데이터에 NULL이 있는 경우에는?\n\n각 함수 설명에 NULL이 있는 경우 어떻게 되는지 예시가 나와 있으므로, 참고하여 사용하자.\n근사치 집계 함수\n탐색 함수"
  },
  {
    "objectID": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html",
    "href": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html",
    "title": "Python_Decorator가 뭐지? with Scope, Namespace",
    "section": "",
    "text": "Decorator : 오브젝트의 구조를 변경하지 않고 새 기능을 추가 할 수 있게 해 주는 디자인 패턴. Python에서는 @를 키워드로 사용한다.\nDecorator의 간단한 예시와 실행결과를 보자.\n\n\ndef print_line(func): # Decorator가 될 함수\n    def wrapper_mine():\n        print('-'*30) # func의 사전작업이라 할 수 있다.\n        func()\n        print('#'*30) # func의 사후작업이라 할 수 있다.\n    return wrapper_mine # wrapper_mine을 호출한 게 아니고, 함수 객체를 그냥 반환한 거다.\n\n\ndef my_function():\n    print(\"my_function 실행\")\n\nm = print_line(my_function) # print_line에 직접 argument를 전달하여 실행해 보자\nm()\n\n------------------------------\nmy_function 실행\n##############################\n\n\n\n@print_line # decorator를 사용하자\ndef my_function2():\n    print(\"my_function2 실행2\")\n\nmy_function2()\n\n------------------------------\nmy_function2 실행2\n##############################\n\n\n여기서 몇 가지 궁금한 점이 생긴다. 1. function(여기서는 wrapper_mine)을 value처럼 막 return 하네? 2. wrapper_mine이 어떻게 print_line의 argument에 접근할 수 있지? - 그게 그냥 된대~ 하고 사용해 왔지만 정확한 철학을 알고 싶다\n일단 1번부터 알아 보자. 왜 함수를 return이 가능하죠?"
  },
  {
    "objectID": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#decorator",
    "href": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#decorator",
    "title": "Python_Decorator가 뭐지? with Scope, Namespace",
    "section": "",
    "text": "Decorator : 오브젝트의 구조를 변경하지 않고 새 기능을 추가 할 수 있게 해 주는 디자인 패턴. Python에서는 @를 키워드로 사용한다.\nDecorator의 간단한 예시와 실행결과를 보자.\n\n\ndef print_line(func): # Decorator가 될 함수\n    def wrapper_mine():\n        print('-'*30) # func의 사전작업이라 할 수 있다.\n        func()\n        print('#'*30) # func의 사후작업이라 할 수 있다.\n    return wrapper_mine # wrapper_mine을 호출한 게 아니고, 함수 객체를 그냥 반환한 거다.\n\n\ndef my_function():\n    print(\"my_function 실행\")\n\nm = print_line(my_function) # print_line에 직접 argument를 전달하여 실행해 보자\nm()\n\n------------------------------\nmy_function 실행\n##############################\n\n\n\n@print_line # decorator를 사용하자\ndef my_function2():\n    print(\"my_function2 실행2\")\n\nmy_function2()\n\n------------------------------\nmy_function2 실행2\n##############################\n\n\n여기서 몇 가지 궁금한 점이 생긴다. 1. function(여기서는 wrapper_mine)을 value처럼 막 return 하네? 2. wrapper_mine이 어떻게 print_line의 argument에 접근할 수 있지? - 그게 그냥 된대~ 하고 사용해 왔지만 정확한 철학을 알고 싶다\n일단 1번부터 알아 보자. 왜 함수를 return이 가능하죠?"
  },
  {
    "objectID": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#first-class-citizen",
    "href": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#first-class-citizen",
    "title": "Python_Decorator가 뭐지? with Scope, Namespace",
    "section": "2 First class citizen",
    "text": "2 First class citizen\nWikipedia의 친절한 설명을 보자. Python first class citizen 이라고 검색하면 나오는 포스트들 다 여기서 내용 가져온 거다.\n\nWikipedia - First-class citizen\n\nIn programming language design, a first-class citizen (also type, object, entity, or value) in a given programming language is an entity which supports all the operations generally available to other entities. These operations typically include being passed as an argument, returned from a function, modified, and assigned to a variable.\nFirst Class Citizen은 Argument로 넘기기, 함수에서 return되기, 조작되기, 변수에 할당되기와 같은, 다른 독립체들과 상호작용 할 수 있는 연산을 지원한다.\n\n\n그리고 Python에서는 함수도 first class object다.\n“function을 value처럼 막 return 하네?” 해결. 그럼 다음 문제, wrapper_mine이 어떻게 print_line의 argument에 접근할 수 있지?"
  },
  {
    "objectID": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#namespace-scope---legb",
    "href": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#namespace-scope---legb",
    "title": "Python_Decorator가 뭐지? with Scope, Namespace",
    "section": "3 Namespace, Scope - LEGB",
    "text": "3 Namespace, Scope - LEGB\n\n3.1 Namespace\n\nNamespace? : 객체와 이름이 매핑된 공간. 대부분의 네임스페이스는 딕셔너리로 적용된다.\n\n네임스페이스의 예시\n\nbuilt-in된 이름들 : abs()같은 함수명이나, 예외명들.\n모듈 내의 전역 이름들 (global names in module)\n함수 내의 지역 이름들 (local names)\ne.g) zzz.real과 ddd.real은 real이라는 attribute 이름은 같을지라도, 전혀 다른 네임스페이스에서 가져온 것이기 때문에 아무런 연관도 없다.\n\n네임스페이스의 수명주기(lifetime)\n\n각각 다른 시기에 생겨나며, 각각 다른 수명을 가짐\nbuilt-in name을 보유한 네임스페이스는 인터프리터가 시작할 때 생겨나고, 인터프리터가 꺼질 때까지 사라지지 않음.\n모듈의 글로벌 네임스페이스는 모듈의 정의가 읽혀질 때 생겨나며, 인터프리터가 꺼질 때까지 사라지지 않음.\n함수의 지역 네임스페이스는 함수가 호출될 때 생겨나고, 함수가 결과를 반환하거나 함수 내부에서 처리되지 않는 에러를 내보낼 때 사라진다.\n\n\n\n\n\n3.2 Scope\n\nScope? : 네임스페이스가 ’직접 접근’할 수 있는 구문 영역. ’직접 접근’이라는 건, unqualified reference(비-제한 참조라고 하면 좋을까?)로 네임스페이스 안의 이름을 찾을 수 있는 것을 말한다.\n\nunqualified reference? : someclass.target 처럼 ’나 어디 있소’라고 someclass. 를 앞에 붙이지 않고, 바로 target으로 이름을 찾는 참조법.\n\nLEGB : Python Scope 탐색 규칙\n\nLocal : 함수 안에 정의된 이름 중 Global로 정의되지 않은 것\nEnclosing-function : 함수를 내포하고 있는 함수(enclosing function)의 영역 안에 있는 것\nGlobal (module) : 모듈 파일의 가장 상위 레벨에서 정의되었거나(어디 클래스나 함수 안에서 정의된 것 아니고) 함수 내부에서 global키워드로 실행된 것\nBuilt-in (Python) : Python에서 기본으로 정의하고 있는 것\n\n\n아래 코드를 살펴보자.\n\nx1 = -1 # Global\nclass spam:    \n    x2 = -2 # class body\n    def ham(self, bar):\n        # enclosing function\n        x3 = -3\n        print(f'print global x1 : {x1}') # global에서 받아옴\n        def egg():\n            x4 = -4\n            x1 = 'local x1'\n            print(f'print local x1 : {x1}') # local에서 정의된 x1을 먼저 받아옴\n            print(f'print class body x2 : {self.x2}') # class body에 정의된 객체를 가져오려면 self 키워드 필요.\n            # 여기서 그냥 x2로 가져오려고 하면, local에도 없고 enclosing에도 없으니\n            # global에서 찾게 된다 : print(f'print x2 : {x2}') 그리고 못 찾아서 에러를 낸다.\n            print(f'print enclosing x3 : {x3}') # enclosing function 영역에서 받아옴\n            print(f'print abs of x4 : {abs(x4)}') # Built-in에서 print, abs를 찾는다. local에서 x4를 찾는다.\n            print(bar) # enclosing-function의 argument를 받는다.\n        egg()\n\nspam = spam()\nspam.ham('foo')\n\nprint global x1 : -1\nprint local x1 : local x1\nprint class body x2 : -2\nprint enclosing x3 : -3\nprint abs of x4 : 4\nfoo\n\n\nClass body 영역은 scope에서 enclosing-function도 아니고 global도 아닌 독특한 위치를 차지하고 있는데, 이 StackOverFlow 답변을 참고하자.\n다시 원점으로 돌아오면,\n\ndef print_line(func): # Decorator가 될 함수\n    def wrapper_mine():\n        print('-'*30) # func의 사전작업이라 할 수 있다.\n        func()\n        print('#'*30) # func의 사후작업이라 할 수 있다.\n    return wrapper_mine # wrapper_mine을 호출한 게 아니고, 함수 객체를 그냥 반환한 거다\n\n“wrapper_mine이 어떻게 print_line의 argument에 접근할 수 있지?” 도 해결되었다."
  },
  {
    "objectID": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#어디다-쓰지",
    "href": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#어디다-쓰지",
    "title": "Python_Decorator가 뭐지? with Scope, Namespace",
    "section": "4 어디다 쓰지?",
    "text": "4 어디다 쓰지?\n말 그대로, 이걸 어디다 쓸까? 간단한 예제를 살펴보자.\n코드 출처 : https://khanrc.tistory.com/entry/decorator%EC%99%80-closure\n\ndef verbose(func): \n    def new_func(*args, **kwargs):\n        print(\"Begin\", func.__name__)\n        func(*args, **kwargs)\n        print(\"End\", func.__name__)\n    return new_func\n\n함수 호출의 시작과 끝을 print 출력으로 알리는 함수다. 아무 함수나 들어올 수 있게 parameter가 설정되어 있다.\n\n@verbose\ndef simple_sum(x,y):\n    print(x+y)\n    return x+y\n\nsimple_sum(1,2)\n\nBegin simple_sum\n3\nEnd simple_sum\n\n\n어떤 함수를 집어넣어도 호출 시에, 연산 끝났을 시에 함수 이름과 함께 알려주는 재미있는 Decorator다."
  },
  {
    "objectID": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#chaining-decorators-in-python",
    "href": "posts/2019-10-30__Decorator가 뭐지 with Scope, Namespace/index.html#chaining-decorators-in-python",
    "title": "Python_Decorator가 뭐지? with Scope, Namespace",
    "section": "5 Chaining Decorators in Python",
    "text": "5 Chaining Decorators in Python\n이 글을 보다보니, 재미있는 예제를 찾을 수 있었다. Decorator가 중첩되어 있으면 어떤 것 부터 적용될까? 아래 코드를 보자.\n\ndef star(func):\n    def inner(*args, **kwargs):\n        print(\"*\" * 30)\n        func(*args, **kwargs)\n        print(\"*\" * 30)\n    return inner\n\ndef percent(func):\n    def inner(*args, **kwargs):\n        print(\"%\" * 30)\n        func(*args, **kwargs)\n        print(\"%\" * 30)\n    return inner\n\n@star\n@percent\ndef printer(msg):\n    print(msg)\nprinter(\"Hello\")\n\n******************************\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nHello\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n******************************\n\n\n더 위쪽에 적혀진 Decorator부터 적용됨을 알 수 있다.\n\n5.1 Reference\n\nhttps://dbader.org/blog/python-first-class-functions\nhttps://docs.python.org/3/tutorial/classes.html\nhttps://stackoverflow.com/questions/291978/short-description-of-the-scoping-rules\nhttps://blog.mozilla.org/webdev/2011/01/31/python-scoping-understanding-legb/\nhttps://khanrc.tistory.com/entry/decorator%EC%99%80-closure\nhttps://www.programiz.com/python-programming/decorator"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_02_Indexing, 값 변경, 추가/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_02_Indexing, 값 변경, 추가/index.html",
    "title": "Pandas_02_Indexing, 값 변경, 추가",
    "section": "",
    "text": "import codes\nimport pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display, HTML, display_html\n\ndf = pd.read_parquet('df.parquet', engine='pyarrow') \n\ndef display_multiple_dfs(dfs:list, styles, margin=10):\n    display_target = f\"\"\"&lt;div&gt;\"\"\"\n    for each_df in dfs:\n        each_df_html = each_df[0].style.set_table_attributes(f\"style='display:inline;margin:{margin}px'\").to_html()\n        in_div = f\"\"\"\n        &lt;div style=\"float: left; padding-right: 20px\"&gt;\n            &lt;p&gt;&lt;b&gt;{each_df[1]}&lt;/b&gt;&lt;/p&gt;\n            {each_df_html}\n        &lt;/div&gt;\n        \"\"\"\n        display_target += in_div\n    #print(display_target)\n    display_html(display_target, raw = True)"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_02_Indexing, 값 변경, 추가/index.html#한-레벨의-index만-가져와서-활용하기",
    "href": "posts/2021-11-05__pandas_cheatsheet_02_Indexing, 값 변경, 추가/index.html#한-레벨의-index만-가져와서-활용하기",
    "title": "Pandas_02_Indexing, 값 변경, 추가",
    "section": "12.1 한 레벨의 index만 가져와서 활용하기",
    "text": "12.1 한 레벨의 index만 가져와서 활용하기\n\nprint(df2.index.get_level_values(0))\nprint(df2.index.get_level_values(1))\n\nInt64Index([1, 1, 1, 1, 1, 22, 100], dtype='int64', name='가')\nInt64Index([1, 1, 2, 4, 6, 22, 4], dtype='int64', name='나')\n\n\n\n# 첫 번째 레벨의 index가 1인 행을 가져옴\ndf2.loc[df2.index.get_level_values(0) == 1]\n\n\n\n\n\n\n\n\n\n다\n라\n마\n바\n사\n아\n\n\n가\n나\n\n\n\n\n\n\n\n\n\n\n1\n1\n1.0\n1.0\n1.0\n1.000000\n1.000000\n1.00000\n\n\n1\n1.0\n1.0\n1.0\n1.000000\n1.000000\n1.00000\n\n\n2\n3.0\n4.0\n5.0\n1.414214\n1.414214\n2.44949\n\n\n4\nNaN\n0.0\nNaN\n2.000000\n2.000000\nNaN\n\n\n6\nNaN\nNaN\nNaN\n2.449490\n2.449490\nNaN"
  },
  {
    "objectID": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html",
    "href": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html",
    "title": "Linux_비밀번호 만료 안 되게 하기",
    "section": "",
    "text": "chage -E -1 -M 99999 계정명"
  },
  {
    "objectID": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html#빠른-결론",
    "href": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html#빠른-결론",
    "title": "Linux_비밀번호 만료 안 되게 하기",
    "section": "",
    "text": "chage -E -1 -M 99999 계정명"
  },
  {
    "objectID": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html#각-명령어-구성품의-의미",
    "href": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html#각-명령어-구성품의-의미",
    "title": "Linux_비밀번호 만료 안 되게 하기",
    "section": "2 2. 각 명령어 구성품의 의미",
    "text": "2 2. 각 명령어 구성품의 의미\n\nchage : 사용자의 패스워드 정보를 관리하는 명령어\n\n-E : 계정의 만료일 설정\n-l : 지정한 계정의 정보를 보여 줌\n-M : 패스워드 최종 변경일로부터 패스워드 변경 없이 사용할 수 있는 최대 일수를 설정\n\n-E에는 -1을 할당 : 영원히 계정을 만료시키지 않음\n-M에는 99999를 할당 : 패스워드 변경 이후 99999일 동안 변경 없이 사용 가능\n위의 명령어 입력 후, sudo chage -l 계정명 으로 계정/패스워드 정보를 확인해 보면 아래와 같다.\nLast password change              : Aug 23, 2021\nPassword expires                  : never\nPassword inactive                 : never\nAccount expires                       : never\nMinimum number of days between password change        : 5\nMaximum number of days between password change        : 99999\nNumber of days of warning before password expires : 7"
  },
  {
    "objectID": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html#reference",
    "href": "posts/2021-09-06__Linux_비밀번호 만료 안 되게 하기/index.html#reference",
    "title": "Linux_비밀번호 만료 안 되게 하기",
    "section": "3 3. Reference",
    "text": "3 3. Reference\n\n리눅스 패스워드 만료 안되게 하기 - 제타위키 (zetawiki.com)\n[Linux] chage 명령어 (사용자 패스워드 만기 정보 관리) (tistory.com)"
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_사용자 정의 함수(UDF)/index.html",
    "href": "posts/2022-10-29__Bigquery_사용자 정의 함수(UDF)/index.html",
    "title": "Bigquery_사용자 정의 함수(UDF)",
    "section": "",
    "text": "다른 언어에서 함수를 정의, 사용하는 과정과 동일하다.\n엄청 긴 CASE WHEN 구문 같은 것을 등록해 두면, 두고두고 편하게 사용할 수 있다."
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_사용자 정의 함수(UDF)/index.html#함수-등록하기",
    "href": "posts/2022-10-29__Bigquery_사용자 정의 함수(UDF)/index.html#함수-등록하기",
    "title": "Bigquery_사용자 정의 함수(UDF)",
    "section": "1 함수 등록하기",
    "text": "1 함수 등록하기\nCREATE OR REPLACE FUNCTION `project_id.dataset.function_name` -- 이 위치에 만들 것\n(money_enum INT64) RETURNS STRING -- 정수 parameter를 받아서 문자열을 반환함\nOPTIONS (description=\"money_enum을 인자로 받아서 money_name 값을 반환하는 함수\") AS (\n    CASE money_enum\n      WHEN 1 THEN \"재화 1\"\n      WHEN 2 THEN \"재화 2\"\n      WHEN 3 THEN \"재화 3\"\n      WHEN 4 THEN \"재화 4\"\n      WHEN 5 THEN \"재화 5\"\n      WHEN 6 THEN \"재화 6\"\n      WHEN 7 THEN \"재화 7\"\n      WHEN 8 THEN \"재화 8\"\n      WHEN 9 THEN \"재화 9\"\n      WHEN 10 THEN \"재화 10\"\n      WHEN 11 THEN \"재화 11\"\n      WHEN 12 THEN \"재화 12\"\n      WHEN 13 THEN \"재화 13\"\n      WHEN 14 THEN \"재화 14\"\n      WHEN 15 THEN \"재화 15\"\n      WHEN 16 THEN \"재화 16\"\n      WHEN 17 THEN \"재화 17\"\n      WHEN 18 THEN \"재화 18\"\n      WHEN 19 THEN \"재화 19\"\n      WHEN 20 THEN \"재화 20\"\n      ELSE \"대응되는 money enum 없음\"\n    END\n);"
  },
  {
    "objectID": "posts/2022-10-29__Bigquery_사용자 정의 함수(UDF)/index.html#함수-사용하기",
    "href": "posts/2022-10-29__Bigquery_사용자 정의 함수(UDF)/index.html#함수-사용하기",
    "title": "Bigquery_사용자 정의 함수(UDF)",
    "section": "2 함수 사용하기",
    "text": "2 함수 사용하기\n SELECT b_date, accountId, money_type, amount,\n    `project_id.dataset.function_name`(money_type) AS money_name -- money_type을 넣으면 money_name을 반환하는 UDF\n    FROM `-` \n    where b_date = start_date\n    and money_type NOT IN (3,4,5)\n위와 같이 함수를 호출하여 불러오면 된다."
  },
  {
    "objectID": "posts/2025-05-03__Unity_matchWidthOrHeight_해상도 변경 시 UI 스케일링 기준 조정/index.html",
    "href": "posts/2025-05-03__Unity_matchWidthOrHeight_해상도 변경 시 UI 스케일링 기준 조정/index.html",
    "title": "Unity - matchWidthOrHeight - 해상도 변경 시 UI 스케일링 기준을 조정",
    "section": "",
    "text": "Unity UI의 CanvasScaler 컴포넌트의 matchWidthOrHeight 속성은, 화면 해상도가 다양한 기기에서 UI 요소들이 어떻게 스케일링될지를 결정함.\n\n\n\n아래 코드에서는 Awake() 함수에서 match 변수를 scaler.matchWidthOrHeight에 적용함.\n\n[Tooltip(\"Match width or height\")]\n[Range(0, 1)]\npublic float match = 0.5f; // 0 = width, 1 = height, 0.5 = balanced\nvoid Awake() {\n    ApplyScreenSettings();\n    var scaler = GetComponent&lt;CanvasScaler&gt;();\n    if (scaler != null) {\n            scaler.referenceResolution = referenceResolution;\n            scaler.matchWidthOrHeight = match;\n        }\n}\n\n\n\nUI가 화면 너비에 맞춰 스케일링됨\n모든 기기에서 UI 요소의 가로 크기가 일정하게 유지됨\n세로가 긴 기기에서는 UI 요소가 위아래로 늘어날 수 있음\n가로 방향 게임에 적합\n\n\n\n\n\nUI가 화면 높이에 맞춰 스케일링됨\n모든 기기에서 UI 요소의 세로 크기가 일정하게 유지됨\n가로가 넓은 기기에서는 UI 요소가 좌우로 늘어날 수 있음\n세로 방향 게임에 적합\n\n\n\n\n\n너비와 높이의 중간값으로 스케일링됨\n다양한 화면 비율에서 UI 요소의 크기가 적절히 조정됨\n여러 해상도를 지원해야 할 때 권장되는 값\n\n\n\n\n\n예를 들어 referenceResolution = (1080, 1920)인 경우:\n\niPhone SE (750x1334) 에서:\n\nmatch = 0: 너비 750에 맞추므로 UI가 전체적으로 작아짐\nmatch = 1: 높이 1334에 맞추므로 UI 요소가 약간 작아지지만 세로 비율은 유지됨\nmatch = 0.5: 양쪽을 모두 고려해 균형있게 조정됨\n\niPad (1024x768) 에서:\n\nmatch = 0: 너비 1024에 맞추므로 UI 요소가 가로로 약간 늘어나고 세로로는 매우 압축됨\nmatch = 1: 높이 768에 맞추므로 UI 요소가 세로로 압축되지만 가로로는 많이 늘어남\nmatch = 0.5: 양쪽에서 각각 절충된 형태로 UI가 표시됨\n\n\n세로 모드 게임은 1에 가깝게, 가로 모드 게임은 0에 가깝게 설정하는 것이 일반적임"
  },
  {
    "objectID": "posts/2025-05-03__Unity_matchWidthOrHeight_해상도 변경 시 UI 스케일링 기준 조정/index.html#matchwidthorheight-값의-의미",
    "href": "posts/2025-05-03__Unity_matchWidthOrHeight_해상도 변경 시 UI 스케일링 기준 조정/index.html#matchwidthorheight-값의-의미",
    "title": "Unity - matchWidthOrHeight - 해상도 변경 시 UI 스케일링 기준을 조정",
    "section": "",
    "text": "아래 코드에서는 Awake() 함수에서 match 변수를 scaler.matchWidthOrHeight에 적용함.\n\n[Tooltip(\"Match width or height\")]\n[Range(0, 1)]\npublic float match = 0.5f; // 0 = width, 1 = height, 0.5 = balanced\nvoid Awake() {\n    ApplyScreenSettings();\n    var scaler = GetComponent&lt;CanvasScaler&gt;();\n    if (scaler != null) {\n            scaler.referenceResolution = referenceResolution;\n            scaler.matchWidthOrHeight = match;\n        }\n}\n\n\n\nUI가 화면 너비에 맞춰 스케일링됨\n모든 기기에서 UI 요소의 가로 크기가 일정하게 유지됨\n세로가 긴 기기에서는 UI 요소가 위아래로 늘어날 수 있음\n가로 방향 게임에 적합\n\n\n\n\n\nUI가 화면 높이에 맞춰 스케일링됨\n모든 기기에서 UI 요소의 세로 크기가 일정하게 유지됨\n가로가 넓은 기기에서는 UI 요소가 좌우로 늘어날 수 있음\n세로 방향 게임에 적합\n\n\n\n\n\n너비와 높이의 중간값으로 스케일링됨\n다양한 화면 비율에서 UI 요소의 크기가 적절히 조정됨\n여러 해상도를 지원해야 할 때 권장되는 값"
  },
  {
    "objectID": "posts/2025-05-03__Unity_matchWidthOrHeight_해상도 변경 시 UI 스케일링 기준 조정/index.html#실제-동작",
    "href": "posts/2025-05-03__Unity_matchWidthOrHeight_해상도 변경 시 UI 스케일링 기준 조정/index.html#실제-동작",
    "title": "Unity - matchWidthOrHeight - 해상도 변경 시 UI 스케일링 기준을 조정",
    "section": "",
    "text": "예를 들어 referenceResolution = (1080, 1920)인 경우:\n\niPhone SE (750x1334) 에서:\n\nmatch = 0: 너비 750에 맞추므로 UI가 전체적으로 작아짐\nmatch = 1: 높이 1334에 맞추므로 UI 요소가 약간 작아지지만 세로 비율은 유지됨\nmatch = 0.5: 양쪽을 모두 고려해 균형있게 조정됨\n\niPad (1024x768) 에서:\n\nmatch = 0: 너비 1024에 맞추므로 UI 요소가 가로로 약간 늘어나고 세로로는 매우 압축됨\nmatch = 1: 높이 768에 맞추므로 UI 요소가 세로로 압축되지만 가로로는 많이 늘어남\nmatch = 0.5: 양쪽에서 각각 절충된 형태로 UI가 표시됨\n\n\n세로 모드 게임은 1에 가깝게, 가로 모드 게임은 0에 가깝게 설정하는 것이 일반적임"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_01_Docker 세팅과 Hello World/index.html",
    "href": "posts/2025-02-02__FastAPI_01_Docker 세팅과 Hello World/index.html",
    "title": "FastAPI_01 Docker 세팅과 Hello World",
    "section": "",
    "text": "Docker Desktop의 유료화 이후로 여러 대체품들이 나왔지만, 그냥 Docker Desktop을 사용하는 것이 시간과 정신건강에 좋다.\nhttps://www.docker.com/products/docker-desktop/\n터미널에서 docker-compose --version으로 버전을 확인하자."
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_01_Docker 세팅과 Hello World/index.html#dockerfile",
    "href": "posts/2025-02-02__FastAPI_01_Docker 세팅과 Hello World/index.html#dockerfile",
    "title": "FastAPI_01 Docker 세팅과 Hello World",
    "section": "2.1 Dockerfile",
    "text": "2.1 Dockerfile\n# 이 dockerfile은 로컬의 fastAPI 폴더 안에 존재\n# python:3.12-slim image를 base image로 사용. alias 'builder'는 향후 밑에서 사용 예정.\nFROM python:3.12-slim AS builder\n\n# python 사용을 위한 패키지를 직접 컴파일 할 필요가 있을 경우를 대비하여 패키지 설치 및 업데이트\nRUN apt-get update && apt-get install -y --no-install-recommends build-essential\n\nFROM builder\n\n# 컨테이너 내의 작업 경로 설정. 이어지는 작업들은 모두 해당 작업 경로 안에서 이루어진다.\nWORKDIR /fastAPI\n\n# poetry로 패키지 의존성을 관리. dockerfile과 같은 경로에 있는 toml 파일과 lock 파일을 복사한다.\nCOPY pyproject.toml poetry.lock ./\n\n# pip 업데이트, 컨테이너 내 의존성 관리를 위한 poetry 설치.\nRUN pip3 install --upgrade pip && pip3 install poetry\n\n# poetry에서 가상환경을 생성하지 않고, 컨테이너 내 system-wide 환경에 패키지들을 바로 설치.\nRUN poetry config virtualenvs.create false\n\n# poetry를 통해 명시된 패키지들을 설치.\n# --no-root : pyproject.toml 파일에 `package-mode=false`를 설정하지 않으면, poetry는 프로젝트 자체를 하나의 패키지로 취급한다.\n# 그러면 매번 프로젝트를 재설치하게 된다. --no-root를 붙이면, root package, 즉 프로젝트 자체를 설치하는 과정을 실행하지 않는다.\n# --no-interaction : 상호작용을 하지 않음 (Y/N 선택 등). CI/CD 환경에서 작동해야 할 때 유용함.\nRUN poetry install --no-root --no-interaction\n\n# dockerfile이 위치하는 로컬 fastAPI 폴더 내의 모든 내용을, 현재 컨테이너의 작업 경로로 복사함\nCOPY . .\n\n# 포트 오픈\nEXPOSE 8000\n\n# ENTRYPOINT는 컨테이너가 시작할 때 실행되는 명령어\n# 아래 명령어는, 터미널에서 main:app 모듈을 서빙하는 uvicorn을 실행시킨다. (포트 8000 오픈)\n# main.py가 WORKDIR의 가장 외부에 존재할 경우에는 이렇게 실행하면 된다.\nENTRYPOINT [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
  },
  {
    "objectID": "posts/2025-02-02__FastAPI_01_Docker 세팅과 Hello World/index.html#docker-compose.yml",
    "href": "posts/2025-02-02__FastAPI_01_Docker 세팅과 Hello World/index.html#docker-compose.yml",
    "title": "FastAPI_01 Docker 세팅과 Hello World",
    "section": "2.2 docker-compose.yml",
    "text": "2.2 docker-compose.yml\nservices:                           # 하위에 여러 개의 서비스를 지정할 수 있음\n  fastapi_sample:                   # 서비스 이름\n    build:                          # 이제부터 Docker가 어떻게 이미지를 빌드할 것인지 세팅함\n      context: .                    # 이미지 빌드 시에, 현재 디렉토리에 있는 모든 요소를 Docker daemon에 보낸다\n      dockerfile: dockerfile        # 어떤 dockerfile을 사용할지 지정\n    container_name: fastapi_sample  # 컨테이너 이름\n    ports:                          # `host의 포트 : 컨테이너의 포트`를 매핑함.\n      - 8000:8000"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html",
    "title": "Pandas_07_데이터 집계",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display_html, display\ndef display_multiple_dfs(dfs:list, styles, margin=10):\n    display_target = ''\n    for each_df in dfs:\n        each_df_html = each_df[0].style.set_caption(f'&lt;b&gt;{each_df[1]}&lt;/b&gt;').set_table_styles(styles).set_table_attributes(f\"style='display:inline;margin:{margin}px'\")._repr_html_()\n        display_target += each_df_html\n    display_html(display_target, raw = True)\nstyles = [\n    {\"selector\" : \"caption\", \"props\" : \"text-align:center; font-size:16px\"}\n]"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#by에-아무-컬럼도-할당-안-하고-싶으면-어떻게-해야-할까-전체총합",
    "href": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#by에-아무-컬럼도-할당-안-하고-싶으면-어떻게-해야-할까-전체총합",
    "title": "Pandas_07_데이터 집계",
    "section": "1.1 by에 아무 컬럼도 할당 안 하고 싶으면 어떻게 해야 할까? (전체총합)",
    "text": "1.1 by에 아무 컬럼도 할당 안 하고 싶으면 어떻게 해야 할까? (전체총합)\n\ndf.groupby(lambda x: 'total').agg({'quantity':'sum'})\n\n\n\n\n\n\n\n\nquantity\n\n\n\n\ntotal\n28"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#그룹-별로-랜덤-샘플-추출하기",
    "href": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#그룹-별로-랜덤-샘플-추출하기",
    "title": "Pandas_07_데이터 집계",
    "section": "1.2 그룹 별로 랜덤 샘플 추출하기",
    "text": "1.2 그룹 별로 랜덤 샘플 추출하기\nDataFrameGroupBy.sample(n=None, frac=None, replace=False, weights=None, random_state=None)[source] - n : int, optional. 각 그룹 별로 몇 개씩 뽑을지. frac과 동시에 사용할 수 없음. replace가 True가 아니라면, 가장 작은 그룹의 크기보다 클 수 없음. - frac : float, optional. 각 그룹 별로 추출할 비율. 0 ~ 1 사이의 값을 넣는다. - replace : bool, default False. 같은 행을 다시 뽑을 수 있는지. True or False - weights : list-like, optional. 가중치. 기본값 None이면 확률 가중은 모두 같다. 대상 Dataframe의 길이와 같은 길이의 list-like 객체를 할당하면, 각 그룹을 정규화 한 후 샘플링 확률로 사용한다. 각 값들은 음수이면 안 되며, 각 그룹마다 최소 하나의 양수가 있어야 한다. - random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional. int, 배열형 또는 BitGenerator인 경우 난수 생성용 시드로 쓴다. np.random.RandomState 또는 np.random.Generator인 경우, 그대로 사용한다.\n\ndf_sample = pd.DataFrame({\"a\": [\"red\"] * 2 + [\"blue\"] * 2 + [\"black\"] * 2, \"b\": range(6)})\ndf_sample\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\nred\n0\n\n\n1\nred\n1\n\n\n2\nblue\n2\n\n\n3\nblue\n3\n\n\n4\nblack\n4\n\n\n5\nblack\n5"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#같은-비율로-추출",
    "href": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#같은-비율로-추출",
    "title": "Pandas_07_데이터 집계",
    "section": "1.3 같은 비율로 추출",
    "text": "1.3 같은 비율로 추출\n\ndf_sample.groupby(\"a\").sample(frac=0.5, random_state=42)\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n5\nblack\n5\n\n\n2\nblue\n2\n\n\n1\nred\n1"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#같은-수를-추출",
    "href": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#같은-수를-추출",
    "title": "Pandas_07_데이터 집계",
    "section": "1.4 같은 수를 추출",
    "text": "1.4 같은 수를 추출\n\ndf_sample.groupby(\"a\").sample(n=1, random_state=1)\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n4\nblack\n4\n\n\n2\nblue\n2\n\n\n1\nred\n1"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#가중치-사용",
    "href": "posts/2021-11-05__pandas_cheatsheet_07_데이터 집계/index.html#가중치-사용",
    "title": "Pandas_07_데이터 집계",
    "section": "1.5 가중치 사용",
    "text": "1.5 가중치 사용\n\ndf_sample.groupby(\"a\").sample(\n    n=1,\n    weights=[1, 1, 1, 0, 0, 1],\n    random_state=99,\n)\n# black과 blue에서는, 무조건 5와 2가 나오게 된다. 가중치를 그렇게 설정하였기 때문.\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n5\nblack\n5\n\n\n2\nblue\n2\n\n\n1\nred\n1"
  },
  {
    "objectID": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html",
    "href": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html",
    "title": "Ubuntu 새 유저 SSH key 추가",
    "section": "",
    "text": "Oracle Free tier에서 Ubuntu instance를 만들면, 기본 계정명이 ubuntu다.\n\n계정을 새로 만들면, 처음에 생성했던 SSH key로는 접속이 되지 않는다.\n\nkey를 새로 만든 후에, instance에 등록해보자."
  },
  {
    "objectID": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#배경",
    "href": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#배경",
    "title": "Ubuntu 새 유저 SSH key 추가",
    "section": "",
    "text": "Oracle Free tier에서 Ubuntu instance를 만들면, 기본 계정명이 ubuntu다.\n\n계정을 새로 만들면, 처음에 생성했던 SSH key로는 접속이 되지 않는다.\n\nkey를 새로 만든 후에, instance에 등록해보자."
  },
  {
    "objectID": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#새-계정-생성",
    "href": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#새-계정-생성",
    "title": "Ubuntu 새 유저 SSH key 추가",
    "section": "2 2. 새 계정 생성",
    "text": "2 2. 새 계정 생성\n\nsudo adduser limyj0708 : limyj0708 계정 생성\n\npassword 설정 진행\n몇 가지 정보 적당히 씀 (Full_name 등)\n\nsudo usermod -aG sudo limyj0708 : sudo 그룹을 limyj0708에 추가하여 sudo 명령어를 사용 가능하게 세팅"
  },
  {
    "objectID": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#ssh-key-생성",
    "href": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#ssh-key-생성",
    "title": "Ubuntu 새 유저 SSH key 추가",
    "section": "3 3. SSH key 생성",
    "text": "3 3. SSH key 생성\n ssh-keygen -t rsa -N \"원하는 password\" -b 2048 -C \"원하는 comment\" -f \"원하는 file path\"\n\nbyte는 최소 2048로 진행\nfile path에 지정한 경로, 이름으로 공개키와 비밀키가 생성된다.\n기존에 사용하던 key를 그대로 사용해도 되지만, 계정이 다르면 다른 key를 사용하려고 한다."
  },
  {
    "objectID": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#instance에-ssh-key-등록",
    "href": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#instance에-ssh-key-등록",
    "title": "Ubuntu 새 유저 SSH key 추가",
    "section": "4 4. instance에 SSH key 등록",
    "text": "4 4. instance에 SSH key 등록\n\nlocal이 리눅스면 ssh-copy-id를 쓰고, 윈도우에서도 해당 명령어에 대응하는 powershell 명령어가 있던데, 솔직히 잘 안 되었다. 권한 문제 뜨고.\n그래서 수동으로 추가하기로 한다.\n\n\n새로 생성한 계정에서는 처음에 /.ssh 폴더가 없다. 생성해줘야 한다.\nubuntu 계정으로 접속\n\nsudo su : root 계정으로 변경\nmkdir /home/limyj0708/.ssh : .ssh 폴더 생성\nnano /home/limyj0708/.ssh/authorized_keys : authorized_keys 파일도 없어서 새로 생성된다.\n\n이제 위에서 생성했던 공개키의 내용을 붙여넣고 저장한다."
  },
  {
    "objectID": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#instance에-접속",
    "href": "posts/2022-07-05__Ubuntu에 새 유저 SSH key 추가/index.html#instance에-접속",
    "title": "Ubuntu 새 유저 SSH key 추가",
    "section": "5 5. instance에 접속",
    "text": "5 5. instance에 접속\n\nOpenssh 윈도우에서도 잘 되니까, Powershell에서 아래 명령어로 접속한다.\n\nssh -i \"비밀키 경로\" limyj0708@서버ip\n\nProfit!"
  },
  {
    "objectID": "posts/2019-10-12__Map vs List Comprehension/index.html",
    "href": "posts/2019-10-12__Map vs List Comprehension/index.html",
    "title": "Map vs List Comprehension",
    "section": "",
    "text": "List comprehension vs Map\n위의 Stack Overflow 질문에 아주 좋은 답변들이 달려 있어서, Upvote 상위 두 개 답변을 살펴보았다.\n\n\n0.1 첫 번째 답변 :\nMap이 몇몇 경우에 아주 약간 더 빠르다. (lambda 안 쓰고, 같은 기능을 하는 함수를 사용할 경우) List Comprehension은 나머지 경우에서 더 빠르며, 대부분의 파이썬 사용자들은 List Comprehension이 더 직관적이고 명확하다고 생각한다.\n# 터미널에서 아래와 같이 실행해보자\n\n$ python -mtimeit -s'xs=range(10)' 'map(hex, xs)'\n100000 loops, best of 3: 4.86 usec per loop\n# hex() -&gt; 16진수로 변경\n\n$ python -mtimeit -s'xs=range(10)' '[hex(x) for x in xs]'\n100000 loops, best of 3: 5.58 usec per loop\n# 그냥 함수를 사용했더니, map이 근소하게 더 빠르다\n하지만 lambda를 쓰면 어떨까?\n$ python -mtimeit -s'xs=range(10)' 'map(lambda x: x+2, xs)'\n100000 loops, best of 3: 4.24 usec per loop\n$ python -mtimeit -s'xs=range(10)' '[x+2 for x in xs]'\n100000 loops, best of 3: 2.32 usec per loop\n\n# 속도가 정 반대가 되었다.\n\n\n0.2 두 번째 답변의 일부 발췌 :\nLaziness\nPython에서 Map은 게으르다. 무슨 말인고 하니, 계산 결과 전체를 반환하는 것이 아니라, 계산 로직을 보관하고 있다가 값 요청이 왔을 때 계산하여 값을 제공해준다는 것이다.\n&gt;&gt;&gt; map(str, range(10**100))\n&lt;map object at 0x2201d50&gt;\n# 리스트가 아니다\nList Comprehension이라면 전체 계산결과 리스트를 반환한다. (Not lazy)\n&gt;&gt;&gt; [str(n) for n in range(10**100)]\n# 이런 짓 하지 말라는 것이다.\n# DO NOT TRY THIS AT HOME OR YOU WILL BE SAD #\n‘게으른’ List Comprehension도 Generator expression의 형태로 지원한다.\n&gt;&gt;&gt; (str(n) for n in range(10**100))\n&lt;generator object &lt;genexpr&gt; at 0xacbdef&gt;"
  },
  {
    "objectID": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html",
    "href": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html",
    "title": "로컬 머신에서 AWS Redshift에 접근하기",
    "section": "",
    "text": "Redshift 공식 메뉴얼에서 명료하게 설명하지 않았거나, 없는 내용에 대한 정리이다."
  },
  {
    "objectID": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#virtual-private-cloudvpc-보안-그룹-설정",
    "href": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#virtual-private-cloudvpc-보안-그룹-설정",
    "title": "로컬 머신에서 AWS Redshift에 접근하기",
    "section": "1 1. Virtual Private Cloud(VPC) 보안 그룹 설정",
    "text": "1 1. Virtual Private Cloud(VPC) 보안 그룹 설정\n\nVPC의 보안 그룹 설정이 필요하다.\n클러스터 선택 -&gt; 속성 -&gt; 네트워크 및 보안 -&gt; VPC 보안 그룹 메뉴로\nInbound 설정에서, 유형 Redshift, 연결을 원하는 머신의 IP를 Source로 설정하자."
  },
  {
    "objectID": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#공개적으로-액세스-할-수-있음-설정",
    "href": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#공개적으로-액세스-할-수-있음-설정",
    "title": "로컬 머신에서 AWS Redshift에 접근하기",
    "section": "2 2. “공개적으로 액세스 할 수 있음” 설정",
    "text": "2 2. “공개적으로 액세스 할 수 있음” 설정\n\n너무 간단한 내용이지만, 메뉴얼에 없었다…\n클러스터 선택 -&gt; 속성 -&gt; 네트워크 및 보안 -&gt; 공개적으로 액세스 할 수 있음 메뉴에서 ’예’로 바꿔주면 된다."
  },
  {
    "objectID": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#tableplus에서-연결하기",
    "href": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#tableplus에서-연결하기",
    "title": "로컬 머신에서 AWS Redshift에 접근하기",
    "section": "3 3. TablePlus에서 연결하기",
    "text": "3 3. TablePlus에서 연결하기\n\nMac용 SQL 클라이언트 중에서는 TablePlus가 제일 좋은 것 같다.\n클러스터 Endpoint는 이런 구조다.\n\nCLUSTER-NAME.CLUSTER-KEY.CLUSTER-REGION.redshift.amazonaws.com:PORT/DATABASE-NAME\n\nHost에 입력할 값\n\nCLUSTER-NAME.CLUSTER-KEY.CLUSTER-REGION.redshift.amazonaws.com\n\nPort, User, Password, Database는 설정했던 값을 입력\n나머지 옵션은 조절하지 않아도 됨"
  },
  {
    "objectID": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#psycopg2에서-연결하기",
    "href": "posts/2020-02-06__로컬 머신에서 AWS Redshift에 접근하기/index.html#psycopg2에서-연결하기",
    "title": "로컬 머신에서 AWS Redshift에 접근하기",
    "section": "4 4. psycopg2에서 연결하기",
    "text": "4 4. psycopg2에서 연결하기\n\n간단해서 코드로 대신함\n\nimport psycopg2\ndbname='YOUR-DB-NAME' # 최초의 기본 db명은 dev\nhost='CLUSTER-NAME.CLUESTER-KEY.CLUESTER-REGION.redshift.amazonaws.com'\nport=5439\nuser='USER-NAME'\npassword='********'\ncon=psycopg2.connect(dbname=dbname, host=host, port=port, user=user, password=password)\ncur = con.cursor()\n\n매번 connect, cursor를 닫기 번거로우니 with 구문을 사용하자.\n\ndbname='YOUR-DB-NAME' # 최초의 기본 db명은 dev\nhost='CLUSTER-NAME.CLUESTER-KEY.CLUESTER-REGION.redshift.amazonaws.com'\nport=5439\nuser='USER-NAME'\npassword='********'\nconnect_param = dict({'dbname':dbname, 'host':host, 'port':port, 'user':user, 'password':password})\n\nwith psycopg2.connect(**connect_param) as con:\n    with con.cursor() as cur:\n        do something"
  },
  {
    "objectID": "posts/2021-11-05__pandas_cheatsheet_06_데이터 타입/index.html",
    "href": "posts/2021-11-05__pandas_cheatsheet_06_데이터 타입/index.html",
    "title": "Pandas_06_데이터 타입",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport copy\nfrom IPython.display import display_html, display\n\n\ndef display_multiple_dfs(dfs:list, styles, margin=10):\n    display_target = ''\n    for each_df in dfs:\n        each_df_html = each_df[0].style.set_caption(f'&lt;b&gt;{each_df[1]}&lt;/b&gt;').set_table_styles(styles).set_table_attributes(f\"style='display:inline;margin:{margin}px'\")._repr_html_()\n        display_target += each_df_html\n    display_html(display_target, raw = True)\n\n\nstyles = [\n    {\"selector\" : \"caption\", \"props\" : \"text-align:center; font-size:16px\"}\n]\n\n\n1 dtypes : 컬럼들의 type 출력\n\ndf = pd.DataFrame({'float': [1.0],\n                   'int': [1],\n                   'datetime': [pd.Timestamp('20180310')],\n                   'string': ['foo']})\ndf.dtypes\n# 더 이상의 설명은 필요 없다!\n\nfloat              float64\nint                  int64\ndatetime    datetime64[ns]\nstring              object\ndtype: object\n\n\n\n\n2 select_dtypes : 특정 타입의 컬럼을 선택, 혹은 배제\nDataFrame.select_dtypes(include=None, exclude=None)\n\nTo select all numeric types, use np.number or ‘number’\nTo select strings you must use the object dtype, but note that this will return all object dtype columns See the numpy dtype hierarchy\nTo select datetimes, use np.datetime64, ‘datetime’ or ‘datetime64’\nTo select timedeltas, use np.timedelta64, ‘timedelta’ or ‘timedelta64’\nTo select Pandas categorical dtypes, use ‘category’\nTo select Pandas datetimetz dtypes, use ‘datetimetz’ (new in 0.20.0) or ‘datetime64[ns, tz]’\n\n\ndf = pd.DataFrame({'a': [1, 2] * 3,\n                   'b': [True, False] * 3,\n                   'c': [1.0, 2.0] * 3})\ndf\n\n\n\n\n\n\n\n\na\nb\nc\n\n\n\n\n0\n1\nTrue\n1.0\n\n\n1\n2\nFalse\n2.0\n\n\n2\n1\nTrue\n1.0\n\n\n3\n2\nFalse\n2.0\n\n\n4\n1\nTrue\n1.0\n\n\n5\n2\nFalse\n2.0\n\n\n\n\n\n\n\n\ndf.select_dtypes(include='bool')\n\n\n\n\n\n\n\n\nb\n\n\n\n\n0\nTrue\n\n\n1\nFalse\n\n\n2\nTrue\n\n\n3\nFalse\n\n\n4\nTrue\n\n\n5\nFalse\n\n\n\n\n\n\n\n\ndf.select_dtypes(include=['float64'])\n\n\n\n\n\n\n\n\nc\n\n\n\n\n0\n1.0\n\n\n1\n2.0\n\n\n2\n1.0\n\n\n3\n2.0\n\n\n4\n1.0\n\n\n5\n2.0\n\n\n\n\n\n\n\n\ndf.select_dtypes(exclude=['int64'])\n\n\n\n\n\n\n\n\nb\nc\n\n\n\n\n0\nTrue\n1.0\n\n\n1\nFalse\n2.0\n\n\n2\nTrue\n1.0\n\n\n3\nFalse\n2.0\n\n\n4\nTrue\n1.0\n\n\n5\nFalse\n2.0\n\n\n\n\n\n\n\n\n\n3 astype : 타입 변경. Bigquery에 df 업로드 시 반드시 사용\nDataFrame.astype(dtype, copy=True, errors='raise')\n\ncopy : False를 하면, 복사를 하는 게 아니고 원본에 연결되므로 변경사항이 원본에까지 전파됨\nerrors : ignore로 세팅하면, 에러 발생 시 원본을 반환하고 끝냄\n\n\nd = {'col1': [1, 2], 'col2': [3, 4]}\ndf = pd.DataFrame(data=d)\ndf.dtypes\n\ncol1    int64\ncol2    int64\ndtype: object\n\n\n\ndf.astype({'col1': 'int32'}).dtypes\n# 잘 변경됐습니다~\n\ncol1    int32\ncol2    int64\ndtype: object"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lim's Code Archive",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\n2025-10-28\n\n\nAirflow_DockerOperator를 사용해 보자\n\n\nlimyj0708 \n\n\n\n\n\n\n2025-10-08\n\n\nuv init으로 시작하는 프로젝트 환경 세팅\n\n\nlimyj0708 \n\n\n\n\n\n\n2025-10-08\n\n\nCloud Compute Instance 사용 시 알아두면 좋은 사용법들\n\n\nlimyj0708 \n\n\n\n\n\n\n2025-10-08\n\n\nCIDR (Classless Inter-Domain Routing) 이란?\n\n\nlimyj0708 \n\n\n\n\n\n\n2025-02-02\n\n\nFastAPI_02 Routing, URL prefix 지정\n\n\nlimyj0708 \n\n\n\n\n\n\n2025-02-02\n\n\nUbuntu에서 메인 Python 버전 새로 설치하기 (with uv)\n\n\nlimyj0708 \n\n\n\n\n\n\n2025-02-02\n\n\nUnity - matchWidthOrHeight - 해상도 변경 시 UI 스케일링 기준을 조정\n\n\nlimyj0708 \n\n\n\n\n\n\n2025-02-02\n\n\nFastAPI_01 Docker 세팅과 Hello World\n\n\nlimyj0708 \n\n\n\n\n\n\n2024-01-21\n\n\nQuarto 101\n\n\nlimyj0708 \n\n\n\n\n\n\n2023-01-12\n\n\nBigquery_Window 함수의 window_frame_clause 정리\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-10-29\n\n\nBigquery_사분위수 구하기\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-10-29\n\n\nBigquery_Array, Struct 조합 사용과 Cartesian Product\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-10-29\n\n\nBigquery_사용자 정의 함수(UDF)\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-10-25\n\n\nBigquery_7일 연속 미접속 시작일 쉽게 추출하기\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-06-13\n\n\nGit CheatSheet (지속적으로 업데이트함)\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-05-26\n\n\nPython Google Drive API v3로 파일 업로드\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-05-26\n\n\nJupyter Lab Server 세팅\n\n\nlimyj0708 \n\n\n\n\n\n\n2022-03-19\n\n\n맥 OS pyenv 세팅 101\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-17\n\n\n리눅스 Shell 명령어 Python 스크립트에서 실행하기 + Crontab\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-08\n\n\nPython 스크립트 Console 유저 입력 받기\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_08_파일 입출력\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_07_데이터 집계\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_06_데이터 타입\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_05_데이터 구조 변경\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_04_Dataframe 결합\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_03_값 삭제, 대체\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_02_Indexing, 값 변경, 추가\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-11-05\n\n\nPandas_01_Dataframe 생성\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-09-07\n\n\nCrontab으로 Python 스크립트 주기적으로 실행하기\n\n\nlimyj0708 \n\n\n\n\n\n\n2021-09-06\n\n\nLinux_비밀번호 만료 안 되게 하기\n\n\nlimyj0708 \n\n\n\n\n\n\n2020-02-11\n\n\nRedshift에 데이터를 적재하는 과정에서 얻은 교훈 & psycopg2\n\n\nlimyj0708 \n\n\n\n\n\n\n2020-02-06\n\n\n로컬 머신에서 AWS Redshift에 접근하기\n\n\nlimyj0708 \n\n\n\n\n\n\n2019-11-11\n\n\nAsynchronous, Synchronous, Blocking, Non-Blocking\n\n\nlimyj0708 \n\n\n\n\n\n\n2019-10-30\n\n\nPython_Decorator가 뭐지? with Scope, Namespace\n\n\nlimyj0708 \n\n\n\n\n\n\n2019-10-12\n\n\nUbuntu 새 유저 SSH key 추가\n\n\nlimyj0708 \n\n\n\n\n\n\n2019-10-12\n\n\nMap vs List Comprehension\n\n\nlimyj0708 \n\n\n\n\n\n\n2019-10-11\n\n\nPython_Parameters, Arguments 정의와 차이점\n\n\nlimyj0708 \n\n\n\n\n\n\nNo matching items"
  }
]